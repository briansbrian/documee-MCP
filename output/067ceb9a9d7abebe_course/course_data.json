{
  "course_id": "466716c7-f2bd-43a3-a828-827b053c3450",
  "title": "Learn 067Ceb9A9D7Abebe",
  "description": "A comprehensive course with 5 modules covering 61 files and 86 patterns.",
  "author": "Documee Course Generator",
  "version": "1.0.0",
  "created_at": "2025-11-14T05:07:43.945600",
  "total_duration_hours": 15.7,
  "difficulty_distribution": {
    "beginner": 11,
    "intermediate": 8,
    "advanced": 0
  },
  "tags": [
    "global_password_hashing",
    "global_python_async_await",
    "global_python_context_managers",
    "global_oauth_authentication",
    "global_session_authentication",
    "global_database_migration",
    "global_python_generators",
    "global_jwt_authentication",
    "global_python_comprehensions",
    "global_python_decorators"
  ],
  "prerequisites": [],
  "modules": [
    {
      "module_id": "57e7788e-0a9d-41cd-a845-f3cb746513e0",
      "title": "Module 2: Python Async Await",
      "description": "This module covers: python_async_await, session_authentication, python_comprehensions, python_context_managers",
      "order": 1,
      "difficulty": "beginner",
      "duration_hours": 5.8,
      "learning_objectives": [
        "Master python async await patterns",
        "Master python comprehensions patterns",
        "Master python context managers patterns",
        "Build foundational programming skills",
        "Integrate multiple concepts into cohesive solutions"
      ],
      "lessons": [
        {
          "lesson_id": "2ab9b2be-ba3e-430b-94a8-17e3f21bda8a",
          "title": "Incremental Updater: Python Async Await",
          "description": "Excellent teaching value (score: 0.88). Well-documented (100% coverage). Ideal complexity (avg: 3.3) for teaching. Contains useful patterns. Well-structured code. Demonstrates: python_context_managers, python_async_await, python_comprehensions",
          "order": 0,
          "difficulty": "beginner",
          "duration_minutes": 60,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py",
          "teaching_value": 0.88,
          "learning_objectives": [
            "Understand python context managers pattern",
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "3439534b-3b3b-4985-8795-f86b12451582",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 4, Await statements: 5"
              ],
              "starter_code": "    \n    async def detect_file_changes(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Detect changes to source files since last course generation.\n        \n        \n            \n        \"\"\"\n        \n        # Get cached course structure to find previous files\n        \n            # No previous course, all files are new\n        \n        \n        # Detect added files\n        \n        # Detect deleted files\n        \n        # Detect modified files\n            \n            # Check if file has changed using cache\n            \n            # Update hash tracking\n        \n        \n    \n    def identify_lessons_to_update(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        \n            \n        \"\"\"\n        \n        # Build map of file_path -> lesson\n        \n        # Match file changes to lessons\n                \n                # Check if lesson has manual edits that should be preserved\n                \n        \n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \n            \n        \"\"\"\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \"\"\"\n        \n    \n    def preserve_manual_edits(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Create a copy of new content\n        \n        # Preserve manually edited sections\n        \n        \n        \n        \n        \n        # Note: code_example is always regenerated from source\n        \n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \"\"\"\n        \n        # Add archive metadata\n        \n        \n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n    \n    def create_version(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Create a new course version entry.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Add to version history\n        \n        \n        \n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \n            \n        \"\"\"\n        # Return in reverse order (newest first) since versions are appended chronologically\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n            \n            \n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n        \n        \n        # Serialize to JSON\n        \n        \n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n        \n            \n            # Deserialize from JSON\n            \n            \n\n\n    async def update_course_incrementally(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Update course incrementally based on file changes.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Identify lessons to update\n        \n        # Track updates\n        \n        # Process each lesson update\n                # Archive the lesson\n            \n                # Update lesson content\n        \n        # Remove archived lessons from course\n        \n        # Update course metadata\n        \n        # Create version entry\n        \n        # Save version history\n        \n        \n        # Verify performance requirement (Req 15.5)\n        \n    \n    async def _update_lesson_content(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Update content for a single lesson.\n        \n        \n            \n        \"\"\"\n        \n        # Get file analysis\n        \n        # Store old content if it exists\n        \n        # Generate new content\n        \n        # Preserve manual edits if any\n        \n        # Update lesson metadata\n        \n        # Update learning objectives if patterns changed\n        \n        \n        # Update complexity-based difficulty\n        \n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n    \n    def _remove_archived_lessons(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Remove archived lessons from course structure.\n        \n            \n        \"\"\"\n        \n        \n        # Remove archived lessons from modules\n            \n            # Update lesson order after removal\n            \n            # Update module duration\n        \n        # Remove empty modules\n        \n        # Update module order\n        \n        # Update course duration\n        \n        # Update difficulty distribution\n        \n        \n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n        \n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n    \n    def _generate_change_summary(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"Generate a human-readable summary of changes.\n        \n            \n        \"\"\"\n        \n        # Count change types\n        \n        \n        # Count update types\n        \n        \n    \n    async def check_for_updates(\n        # TODO: Implement python_async_await logic here\n        pass",
              "solution_code": "return 0.0\n    \n    async def detect_file_changes(\n        self,\n        codebase_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> List[FileChange]:\n        \"\"\"Detect changes to source files since last course generation.\n        \n        Implements Requirement 15.1: Detects which lessons need updates based on file changes.\n        \n        Args:\n            codebase_id: Unique codebase identifier\n            current_files: List of current file paths in the codebase\n            analysis: Current codebase analysis\n            \n        Returns:\n            List of FileChange objects representing detected changes\n        \"\"\"\n        changes = []\n        \n        # Get cached course structure to find previous files\n        cached_course = await self.cache.get_course_structure(codebase_id)\n        \n        if not cached_course or \"file_paths\" not in cached_course:\n            # No previous course, all files are new\n            for file_path in current_files:\n                file_hash = self._compute_file_hash(file_path)\n                changes.append(FileChange(\n                    file_path=file_path,\n                    change_type='added',\n                    new_hash=file_hash\n                ))\n            return changes\n        \n        previous_files = set(cached_course[\"file_paths\"])\n        current_files_set = set(current_files)\n        \n        # Detect added files\n        added_files = current_files_set - previous_files\n        for file_path in added_files:\n            file_hash = self._compute_file_hash(file_path)\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='added',\n                new_hash=file_hash\n            ))\n            logger.info(f\"Detected added file: {file_path}\")\n        \n        # Detect deleted files\n        deleted_files = previous_files - current_files_set\n        for file_path in deleted_files:\n            old_hash = self.file_hashes.get(file_path, \"\")\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='deleted',\n                old_hash=old_hash\n            ))\n            logger.info(f\"Detected deleted file: {file_path}\")\n        \n        # Detect modified files\n        for file_path in current_files_set & previous_files:\n            current_hash = self._compute_file_hash(file_path)\n            \n            # Check if file has changed using cache\n            if await self.cache._is_file_changed(file_path):\n                old_hash = self.file_hashes.get(file_path, \"\")\n                if current_hash != old_hash:\n                    changes.append(FileChange(\n                        file_path=file_path,\n                        change_type='modified',\n                        old_hash=old_hash,\n                        new_hash=current_hash\n                    ))\n                    logger.info(f\"Detected modified file: {file_path}\")\n            \n            # Update hash tracking\n            self.file_hashes[file_path] = current_hash\n        \n        logger.info(\n            f\"Detected {len(changes)} file changes: \"\n            f\"{len(added_files)} added, {len(deleted_files)} deleted, \"\n            f\"{len([c for c in changes if c.change_type == 'modified'])} modified\"\n        )\n        \n        return changes\n    \n    def identify_lessons_to_update(\n        self,\n        course: CourseOutline,\n        file_changes: List[FileChange]\n    ) -> List[Tuple[Lesson, FileChange]]:\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        Implements Requirement 15.1: Detects which lessons need updates.\n        \n        Args:\n            course: Current course outline\n            file_changes: List of detected file changes\n            \n        Returns:\n            List of (Lesson, FileChange) tuples for lessons that need updates\n        \"\"\"\n        lessons_to_update = []\n        \n        # Build map of file_path -> lesson\n        file_to_lesson: Dict[str, Lesson] = {}\n        for module in course.modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n        \n        # Match file changes to lessons\n        for change in file_changes:\n            if change.file_path in file_to_lesson:\n                lesson = file_to_lesson[change.file_path]\n                \n                # Check if lesson has manual edits that should be preserved\n                if self._has_manual_edits(lesson.lesson_id):\n                    logger.info(\n                        f\"Lesson {lesson.lesson_id} has manual edits, \"\n                        f\"will preserve during update\"\n                    )\n                \n                lessons_to_update.append((lesson, change))\n        \n        logger.info(f\"Identified {len(lessons_to_update)} lessons to update\")\n        return lessons_to_update\n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        Implements Requirement 15.2: Preserves manual edits.\n        \n        Args:\n            lesson_id: Lesson identifier\n            \n        Returns:\n            True if lesson has manual edits, False otherwise\n        \"\"\"\n        return lesson_id in self.manual_edits and len(self.manual_edits[lesson_id]) > 0\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        Implements Requirement 15.2: Tracks manual edits to preserve them.\n        \n        Args:\n            lesson_id: Lesson identifier\n            section: Section name that was edited (e.g., 'introduction', 'explanation')\n        \"\"\"\n        if lesson_id not in self.manual_edits:\n            self.manual_edits[lesson_id] = set()\n        \n        self.manual_edits[lesson_id].add(section)\n        logger.info(f\"Marked manual edit: {lesson_id}.{section}\")\n    \n    def preserve_manual_edits(\n        self,\n        lesson_id: str,\n        old_content: LessonContent,\n        new_content: LessonContent\n    ) -> LessonContent:\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        Implements Requirement 15.2: Preserves manual edits to lesson content.\n        \n        Args:\n            lesson_id: Lesson identifier\n            old_content: Previous lesson content (may have manual edits)\n            new_content: Newly generated lesson content\n            \n        Returns:\n            Merged lesson content with manual edits preserved\n        \"\"\"\n        if not self._has_manual_edits(lesson_id):\n            return new_content\n        \n        edited_sections = self.manual_edits[lesson_id]\n        \n        # Create a copy of new content\n        merged_content = LessonContent(\n            introduction=new_content.introduction,\n            explanation=new_content.explanation,\n            code_example=new_content.code_example,\n            walkthrough=new_content.walkthrough,\n            summary=new_content.summary,\n            further_reading=new_content.further_reading\n        )\n        \n        # Preserve manually edited sections\n        if 'introduction' in edited_sections:\n            merged_content.introduction = old_content.introduction\n            logger.info(f\"Preserved manual edit: {lesson_id}.introduction\")\n        \n        if 'explanation' in edited_sections:\n            merged_content.explanation = old_content.explanation\n            logger.info(f\"Preserved manual edit: {lesson_id}.explanation\")\n        \n        if 'walkthrough' in edited_sections:\n            merged_content.walkthrough = old_content.walkthrough\n            logger.info(f\"Preserved manual edit: {lesson_id}.walkthrough\")\n        \n        if 'summary' in edited_sections:\n            merged_content.summary = old_content.summary\n            logger.info(f\"Preserved manual edit: {lesson_id}.summary\")\n        \n        if 'further_reading' in edited_sections:\n            merged_content.further_reading = old_content.further_reading\n            logger.info(f\"Preserved manual edit: {lesson_id}.further_reading\")\n        \n        # Note: code_example is always regenerated from source\n        \n        return merged_content\n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\n        \n        Args:\n            course_id: Course identifier\n            lesson: Lesson to archive\n            reason: Reason for archiving\n        \"\"\"\n        if course_id not in self.archived_lessons:\n            self.archived_lessons[course_id] = []\n        \n        # Add archive metadata\n        lesson.tags.append(f\"archived:{reason}\")\n        lesson.tags.append(f\"archived_at:{datetime.now().isoformat()}\")\n        \n        self.archived_lessons[course_id].append(lesson)\n        \n        logger.info(\n            f\"Archived lesson {lesson.lesson_id} ({lesson.title}) \"\n            f\"from course {course_id}: {reason}\"\n        )\n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of archived lessons\n        \"\"\"\n        return self.archived_lessons.get(course_id, [])\n    \n    def create_version(\n        self,\n        course_id: str,\n        version: str,\n        change_summary: str,\n        lesson_updates: List[LessonUpdate],\n        file_changes: List[FileChange],\n        total_lessons: int\n    ) -> CourseVersion:\n        \"\"\"Create a new course version entry.\n        \n        Implements Requirement 15.4: Tracks course version history.\n        \n        Args:\n            course_id: Course identifier\n            version: Version string (e.g., \"1.0.1\")\n            change_summary: Summary of changes\n            lesson_updates: List of lesson updates\n            file_changes: List of file changes\n            total_lessons: Total number of lessons in course\n            \n        Returns:\n            CourseVersion object\n        \"\"\"\n        now = datetime.now()\n        \n        course_version = CourseVersion(\n            version=version,\n            created_at=now,\n            updated_at=now,\n            change_summary=change_summary,\n            lesson_updates=lesson_updates,\n            file_changes=file_changes,\n            total_lessons=total_lessons,\n            updated_lessons=len(lesson_updates),\n            archived_lessons=len([u for u in lesson_updates if u.update_type == 'archived'])\n        )\n        \n        # Add to version history\n        if course_id not in self.version_history:\n            self.version_history[course_id] = []\n        \n        self.version_history[course_id].append(course_version)\n        \n        logger.info(\n            f\"Created course version {version} for {course_id}: \"\n            f\"{course_version.updated_lessons} lessons updated, \"\n            f\"{course_version.archived_lessons} lessons archived\"\n        )\n        \n        return course_version\n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        Implements Requirement 15.4: Provides access to course version history.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of CourseVersion objects, newest first (in reverse order of creation)\n        \"\"\"\n        history = self.version_history.get(course_id, [])\n        # Return in reverse order (newest first) since versions are appended chronologically\n        return list(reversed(history))\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Latest CourseVersion or None if no versions exist\n        \"\"\"\n        history = self.get_version_history(course_id)\n        return history[0] if history else None\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        Args:\n            current_version: Current version string (e.g., \"1.0.0\")\n            change_type: Type of change ('major', 'minor', 'patch')\n            \n        Returns:\n            New version string\n        \"\"\"\n        try:\n            parts = current_version.split('.')\n            major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])\n            \n            if change_type == 'major':\n                major += 1\n                minor = 0\n                patch = 0\n            elif change_type == 'minor':\n                minor += 1\n                patch = 0\n            else:  # patch\n                patch += 1\n            \n            return f\"{major}.{minor}.{patch}\"\n        except Exception as e:\n            logger.warning(f\"Failed to increment version {current_version}: {e}\")\n            return current_version\n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        Args:\n            course_id: Course identifier\n            output_path: Optional custom output path\n        \"\"\"\n        if output_path is None:\n            output_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        history = self.get_version_history(course_id)\n        \n        # Serialize to JSON\n        history_data = []\n        for version in history:\n            history_data.append({\n                \"version\": version.version,\n                \"created_at\": version.created_at.isoformat(),\n                \"updated_at\": version.updated_at.isoformat(),\n                \"change_summary\": version.change_summary,\n                \"total_lessons\": version.total_lessons,\n                \"updated_lessons\": version.updated_lessons,\n                \"archived_lessons\": version.archived_lessons,\n                \"lesson_updates\": [\n                    {\n                        \"lesson_id\": u.lesson_id,\n                        \"file_path\": u.file_path,\n                        \"update_type\": u.update_type,\n                        \"changes\": u.changes,\n                        \"timestamp\": u.timestamp.isoformat()\n                    }\n                    for u in version.lesson_updates\n                ],\n                \"file_changes\": [\n                    {\n                        \"file_path\": c.file_path,\n                        \"change_type\": c.change_type,\n                        \"old_hash\": c.old_hash,\n                        \"new_hash\": c.new_hash,\n                        \"detected_at\": c.detected_at.isoformat()\n                    }\n                    for c in version.file_changes\n                ]\n            })\n        \n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(history_data, f, indent=2)\n        \n        logger.info(f\"Saved version history to {output_path}\")\n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        Args:\n            course_id: Course identifier\n            input_path: Optional custom input path\n        \"\"\"\n        if input_path is None:\n            input_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        if not os.path.exists(input_path):\n            logger.debug(f\"No version history file found at {input_path}\")\n            return\n        \n        try:\n            with open(input_path, 'r', encoding='utf-8') as f:\n                history_data = json.load(f)\n            \n            # Deserialize from JSON\n            versions = []\n            for data in history_data:\n                version = CourseVersion(\n                    version=data[\"version\"],\n                    created_at=datetime.fromisoformat(data[\"created_at\"]),\n                    updated_at=datetime.fromisoformat(data[\"updated_at\"]),\n                    change_summary=data[\"change_summary\"],\n                    total_lessons=data[\"total_lessons\"],\n                    updated_lessons=data[\"updated_lessons\"],\n                    archived_lessons=data[\"archived_lessons\"],\n                    lesson_updates=[\n                        LessonUpdate(\n                            lesson_id=u[\"lesson_id\"],\n                            file_path=u[\"file_path\"],\n                            update_type=u[\"update_type\"],\n                            changes=u[\"changes\"],\n                            timestamp=datetime.fromisoformat(u[\"timestamp\"])\n                        )\n                        for u in data[\"lesson_updates\"]\n                    ],\n                    file_changes=[\n                        FileChange(\n                            file_path=c[\"file_path\"],\n                            change_type=c[\"change_type\"],\n                            old_hash=c.get(\"old_hash\"),\n                            new_hash=c.get(\"new_hash\"),\n                            detected_at=datetime.fromisoformat(c[\"detected_at\"])\n                        )\n                        for c in data[\"file_changes\"]\n                    ]\n                )\n                versions.append(version)\n            \n            self.version_history[course_id] = versions\n            logger.info(f\"Loaded {len(versions)} versions from {input_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to load version history from {input_path}: {e}\")\n\n\n    async def update_course_incrementally(\n        self,\n        course: CourseOutline,\n        analysis: CodebaseAnalysis,\n        file_changes: List[FileChange],\n        content_generator,\n        structure_generator\n    ) -> Tuple[CourseOutline, CourseVersion]:\n        \"\"\"Update course incrementally based on file changes.\n        \n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\n        - Updates only changed lessons\n        - Preserves manual edits\n        - Archives deleted lessons\n        - Completes updates in <3s for <5 changes\n        \n        Args:\n            course: Current course outline\n            analysis: Current codebase analysis\n            file_changes: List of detected file changes\n            content_generator: LessonContentGenerator instance\n            structure_generator: CourseStructureGenerator instance\n            \n        Returns:\n            Tuple of (updated CourseOutline, CourseVersion)\n        \"\"\"\n        start_time = time.time()\n        \n        logger.info(\n            f\"Starting incremental update for course {course.course_id} \"\n            f\"with {len(file_changes)} file changes\"\n        )\n        \n        # Identify lessons to update\n        lessons_to_update = self.identify_lessons_to_update(course, file_changes)\n        \n        # Track updates\n        lesson_updates: List[LessonUpdate] = []\n        \n        # Process each lesson update\n        for lesson, change in lessons_to_update:\n            if change.change_type == 'deleted':\n                # Archive the lesson\n                self.archive_lesson(course.course_id, lesson, \"file_deleted\")\n                lesson_updates.append(LessonUpdate(\n                    lesson_id=lesson.lesson_id,\n                    file_path=lesson.file_path,\n                    update_type='archived',\n                    changes=['File deleted, lesson archived']\n                ))\n            \n            elif change.change_type in ['added', 'modified']:\n                # Update lesson content\n                update = await self._update_lesson_content(\n                    lesson,\n                    analysis,\n                    content_generator\n                )\n                lesson_updates.append(update)\n        \n        # Remove archived lessons from course\n        course = self._remove_archived_lessons(course, lesson_updates)\n        \n        # Update course metadata\n        course.version = self.increment_version(\n            course.version,\n            'minor' if len(file_changes) > 5 else 'patch'\n        )\n        course.created_at = datetime.now()  # Update timestamp\n        \n        # Create version entry\n        change_summary = self._generate_change_summary(file_changes, lesson_updates)\n        version = self.create_version(\n            course.course_id,\n            course.version,\n            change_summary,\n            lesson_updates,\n            file_changes,\n            self._count_total_lessons(course)\n        )\n        \n        # Save version history\n        self.save_version_history(course.course_id)\n        \n        elapsed_time = time.time() - start_time\n        logger.info(\n            f\"Incremental update completed in {elapsed_time:.2f}s: \"\n            f\"{len(lesson_updates)} lessons updated\"\n        )\n        \n        # Verify performance requirement (Req 15.5)\n        if len(file_changes) < 5 and elapsed_time > 3.0:\n            logger.warning(\n                f\"Update took {elapsed_time:.2f}s for {len(file_changes)} changes, \"\n                f\"exceeding 3s target\"\n            )\n        \n        return course, version\n    \n    async def _update_lesson_content(\n        self,\n        lesson: Lesson,\n        analysis: CodebaseAnalysis,\n        content_generator\n    ) -> LessonUpdate:\n        \"\"\"Update content for a single lesson.\n        \n        Implements Requirement 15.2: Preserves manual edits during update.\n        \n        Args:\n            lesson: Lesson to update\n            analysis: Current codebase analysis\n            content_generator: LessonContentGenerator instance\n            \n        Returns:\n            LessonUpdate describing the changes\n        \"\"\"\n        changes = []\n        \n        # Get file analysis\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            logger.warning(f\"No analysis found for {lesson.file_path}\")\n            return LessonUpdate(\n                lesson_id=lesson.lesson_id,\n                file_path=lesson.file_path,\n                update_type='content',\n                changes=['No analysis available']\n            )\n        \n        # Store old content if it exists\n        old_content = lesson.content\n        \n        # Generate new content\n        new_content = await content_generator.generate_lesson_content(file_analysis)\n        \n        # Preserve manual edits if any\n        if old_content and self._has_manual_edits(lesson.lesson_id):\n            merged_content = self.preserve_manual_edits(\n                lesson.lesson_id,\n                old_content,\n                new_content\n            )\n            lesson.content = merged_content\n            changes.append(\"Preserved manual edits\")\n        else:\n            lesson.content = new_content\n            changes.append(\"Regenerated content\")\n        \n        # Update lesson metadata\n        lesson.teaching_value = file_analysis.teaching_value.score\n        \n        # Update learning objectives if patterns changed\n        old_patterns = set(lesson.concepts)\n        new_patterns = set(p.pattern_type for p in file_analysis.patterns)\n        \n        if old_patterns != new_patterns:\n            lesson.concepts = list(new_patterns)\n            lesson.tags = list(new_patterns)\n            changes.append(f\"Updated patterns: {new_patterns - old_patterns}\")\n        \n        # Update complexity-based difficulty\n        new_difficulty = self._calculate_difficulty(file_analysis)\n        if new_difficulty != lesson.difficulty:\n            old_diff = lesson.difficulty\n            lesson.difficulty = new_difficulty\n            changes.append(f\"Difficulty changed: {old_diff} -> {new_difficulty}\")\n        \n        return LessonUpdate(\n            lesson_id=lesson.lesson_id,\n            file_path=lesson.file_path,\n            update_type='content',\n            changes=changes\n        )\n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        Args:\n            file_analysis: FileAnalysis object\n            \n        Returns:\n            Difficulty level string\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n    \n    def _remove_archived_lessons(\n        self,\n        course: CourseOutline,\n        lesson_updates: List[LessonUpdate]\n    ) -> CourseOutline:\n        \"\"\"Remove archived lessons from course structure.\n        \n        Args:\n            course: Course outline\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Updated course outline\n        \"\"\"\n        archived_ids = {\n            u.lesson_id for u in lesson_updates\n            if u.update_type == 'archived'\n        }\n        \n        if not archived_ids:\n            return course\n        \n        # Remove archived lessons from modules\n        for module in course.modules:\n            module.lessons = [\n                lesson for lesson in module.lessons\n                if lesson.lesson_id not in archived_ids\n            ]\n            \n            # Update lesson order after removal\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n            \n            # Update module duration\n            module.duration_hours = sum(l.duration_minutes for l in module.lessons) / 60.0\n        \n        # Remove empty modules\n        course.modules = [m for m in course.modules if len(m.lessons) > 0]\n        \n        # Update module order\n        for idx, module in enumerate(course.modules):\n            module.order = idx\n        \n        # Update course duration\n        course.total_duration_hours = sum(m.duration_hours for m in course.modules)\n        \n        # Update difficulty distribution\n        course.difficulty_distribution = self._calculate_difficulty_distribution(course)\n        \n        logger.info(f\"Removed {len(archived_ids)} archived lessons from course\")\n        \n        return course\n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Dictionary mapping difficulty levels to counts\n        \"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        \n        for module in course.modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n        \n        return distribution\n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Total number of lessons\n        \"\"\"\n        return sum(len(module.lessons) for module in course.modules)\n    \n    def _generate_change_summary(\n        self,\n        file_changes: List[FileChange],\n        lesson_updates: List[LessonUpdate]\n    ) -> str:\n        \"\"\"Generate a human-readable summary of changes.\n        \n        Args:\n            file_changes: List of file changes\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Change summary string\n        \"\"\"\n        parts = []\n        \n        # Count change types\n        added = len([c for c in file_changes if c.change_type == 'added'])\n        modified = len([c for c in file_changes if c.change_type == 'modified'])\n        deleted = len([c for c in file_changes if c.change_type == 'deleted'])\n        \n        if added > 0:\n            parts.append(f\"{added} file(s) added\")\n        if modified > 0:\n            parts.append(f\"{modified} file(s) modified\")\n        if deleted > 0:\n            parts.append(f\"{deleted} file(s) deleted\")\n        \n        # Count update types\n        content_updates = len([u for u in lesson_updates if u.update_type == 'content'])\n        archived = len([u for u in lesson_updates if u.update_type == 'archived'])\n        \n        if content_updates > 0:\n            parts.append(f\"{content_updates} lesson(s) updated\")\n        if archived > 0:\n            parts.append(f\"{archived} lesson(s) archived\")\n        \n        return \", \".join(parts) if parts else \"No changes\"\n    \n    async def check_for_updates(\n        self,\n        course_id: str,",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 45 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 4 in your implementation",
                "Apply Await statements: 5 in your implementation"
              ]
            },
            {
              "exercise_id": "0017d8cc-80c6-4353-bb12-d68e535e5fcf",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (10 occurrences)"
              ],
              "starter_code": "        \n    \n    def identify_lessons_to_update(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        \n            \n        \"\"\"\n        \n        # Build map of file_path -> lesson\n        \n        # Match file changes to lessons\n                \n                # Check if lesson has manual edits that should be preserved\n                \n        \n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \"\"\"\n        \n    \n    def preserve_manual_edits(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Create a copy of new content\n        \n        # Preserve manually edited sections\n        \n        \n        \n        \n        \n        # Note: code_example is always regenerated from source\n        \n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \"\"\"\n        \n        # Add archive metadata\n        \n        \n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n    \n    def create_version(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Create a new course version entry.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Add to version history\n        \n        \n        \n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        # Return in reverse order (newest first) since versions are appended chronologically\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n            \n            \n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \n        # Serialize to JSON\n        \n        \n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n            \n            # Deserialize from JSON\n            \n            \n\n\n    async def update_course_incrementally(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Update course incrementally based on file changes.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Identify lessons to update\n        \n        # Track updates\n        \n        # Process each lesson update\n                # Archive the lesson\n            \n                # Update lesson content\n        \n        # Remove archived lessons from course\n        \n        # Update course metadata\n        \n        # Create version entry\n        \n        # Save version history\n        \n        \n        # Verify performance requirement (Req 15.5)\n        \n    \n    async def _update_lesson_content(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Update content for a single lesson.\n        \n        \n            \n        \"\"\"\n        \n        # Get file analysis\n        \n        # Store old content if it exists\n        \n        # Generate new content\n        \n        # Preserve manual edits if any\n        \n        # Update lesson metadata\n        \n        # Update learning objectives if patterns changed\n        \n        \n        # Update complexity-based difficulty\n        \n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n        \n    \n    def _remove_archived_lessons(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Remove archived lessons from course structure.\n        \n            \n        \"\"\"\n        \n        \n        # Remove archived lessons from modules\n            \n            # Update lesson order after removal\n            \n            # Update module duration\n        \n        # Remove empty modules\n        \n        # Update module order\n        \n        # Update course duration\n        \n        # Update difficulty distribution\n        \n        \n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n        \n        \n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n    \n    def _generate_change_summary(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate a human-readable summary of changes.\n        \n            \n        \"\"\"\n        \n        # Count change types\n        \n        \n        # Count update types\n        ",
              "solution_code": "f\"Detected {len(changes)} file changes: \"\n            f\"{len(added_files)} added, {len(deleted_files)} deleted, \"\n            f\"{len([c for c in changes if c.change_type == 'modified'])} modified\"\n        )\n        \n        return changes\n    \n    def identify_lessons_to_update(\n        self,\n        course: CourseOutline,\n        file_changes: List[FileChange]\n    ) -> List[Tuple[Lesson, FileChange]]:\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        Implements Requirement 15.1: Detects which lessons need updates.\n        \n        Args:\n            course: Current course outline\n            file_changes: List of detected file changes\n            \n        Returns:\n            List of (Lesson, FileChange) tuples for lessons that need updates\n        \"\"\"\n        lessons_to_update = []\n        \n        # Build map of file_path -> lesson\n        file_to_lesson: Dict[str, Lesson] = {}\n        for module in course.modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n        \n        # Match file changes to lessons\n        for change in file_changes:\n            if change.file_path in file_to_lesson:\n                lesson = file_to_lesson[change.file_path]\n                \n                # Check if lesson has manual edits that should be preserved\n                if self._has_manual_edits(lesson.lesson_id):\n                    logger.info(\n                        f\"Lesson {lesson.lesson_id} has manual edits, \"\n                        f\"will preserve during update\"\n                    )\n                \n                lessons_to_update.append((lesson, change))\n        \n        logger.info(f\"Identified {len(lessons_to_update)} lessons to update\")\n        return lessons_to_update\n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        Implements Requirement 15.2: Preserves manual edits.\n        \n        Args:\n            lesson_id: Lesson identifier\n            \n        Returns:\n            True if lesson has manual edits, False otherwise\n        \"\"\"\n        return lesson_id in self.manual_edits and len(self.manual_edits[lesson_id]) > 0\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        Implements Requirement 15.2: Tracks manual edits to preserve them.\n        \n        Args:\n            lesson_id: Lesson identifier\n            section: Section name that was edited (e.g., 'introduction', 'explanation')\n        \"\"\"\n        if lesson_id not in self.manual_edits:\n            self.manual_edits[lesson_id] = set()\n        \n        self.manual_edits[lesson_id].add(section)\n        logger.info(f\"Marked manual edit: {lesson_id}.{section}\")\n    \n    def preserve_manual_edits(\n        self,\n        lesson_id: str,\n        old_content: LessonContent,\n        new_content: LessonContent\n    ) -> LessonContent:\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        Implements Requirement 15.2: Preserves manual edits to lesson content.\n        \n        Args:\n            lesson_id: Lesson identifier\n            old_content: Previous lesson content (may have manual edits)\n            new_content: Newly generated lesson content\n            \n        Returns:\n            Merged lesson content with manual edits preserved\n        \"\"\"\n        if not self._has_manual_edits(lesson_id):\n            return new_content\n        \n        edited_sections = self.manual_edits[lesson_id]\n        \n        # Create a copy of new content\n        merged_content = LessonContent(\n            introduction=new_content.introduction,\n            explanation=new_content.explanation,\n            code_example=new_content.code_example,\n            walkthrough=new_content.walkthrough,\n            summary=new_content.summary,\n            further_reading=new_content.further_reading\n        )\n        \n        # Preserve manually edited sections\n        if 'introduction' in edited_sections:\n            merged_content.introduction = old_content.introduction\n            logger.info(f\"Preserved manual edit: {lesson_id}.introduction\")\n        \n        if 'explanation' in edited_sections:\n            merged_content.explanation = old_content.explanation\n            logger.info(f\"Preserved manual edit: {lesson_id}.explanation\")\n        \n        if 'walkthrough' in edited_sections:\n            merged_content.walkthrough = old_content.walkthrough\n            logger.info(f\"Preserved manual edit: {lesson_id}.walkthrough\")\n        \n        if 'summary' in edited_sections:\n            merged_content.summary = old_content.summary\n            logger.info(f\"Preserved manual edit: {lesson_id}.summary\")\n        \n        if 'further_reading' in edited_sections:\n            merged_content.further_reading = old_content.further_reading\n            logger.info(f\"Preserved manual edit: {lesson_id}.further_reading\")\n        \n        # Note: code_example is always regenerated from source\n        \n        return merged_content\n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\n        \n        Args:\n            course_id: Course identifier\n            lesson: Lesson to archive\n            reason: Reason for archiving\n        \"\"\"\n        if course_id not in self.archived_lessons:\n            self.archived_lessons[course_id] = []\n        \n        # Add archive metadata\n        lesson.tags.append(f\"archived:{reason}\")\n        lesson.tags.append(f\"archived_at:{datetime.now().isoformat()}\")\n        \n        self.archived_lessons[course_id].append(lesson)\n        \n        logger.info(\n            f\"Archived lesson {lesson.lesson_id} ({lesson.title}) \"\n            f\"from course {course_id}: {reason}\"\n        )\n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of archived lessons\n        \"\"\"\n        return self.archived_lessons.get(course_id, [])\n    \n    def create_version(\n        self,\n        course_id: str,\n        version: str,\n        change_summary: str,\n        lesson_updates: List[LessonUpdate],\n        file_changes: List[FileChange],\n        total_lessons: int\n    ) -> CourseVersion:\n        \"\"\"Create a new course version entry.\n        \n        Implements Requirement 15.4: Tracks course version history.\n        \n        Args:\n            course_id: Course identifier\n            version: Version string (e.g., \"1.0.1\")\n            change_summary: Summary of changes\n            lesson_updates: List of lesson updates\n            file_changes: List of file changes\n            total_lessons: Total number of lessons in course\n            \n        Returns:\n            CourseVersion object\n        \"\"\"\n        now = datetime.now()\n        \n        course_version = CourseVersion(\n            version=version,\n            created_at=now,\n            updated_at=now,\n            change_summary=change_summary,\n            lesson_updates=lesson_updates,\n            file_changes=file_changes,\n            total_lessons=total_lessons,\n            updated_lessons=len(lesson_updates),\n            archived_lessons=len([u for u in lesson_updates if u.update_type == 'archived'])\n        )\n        \n        # Add to version history\n        if course_id not in self.version_history:\n            self.version_history[course_id] = []\n        \n        self.version_history[course_id].append(course_version)\n        \n        logger.info(\n            f\"Created course version {version} for {course_id}: \"\n            f\"{course_version.updated_lessons} lessons updated, \"\n            f\"{course_version.archived_lessons} lessons archived\"\n        )\n        \n        return course_version\n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        Implements Requirement 15.4: Provides access to course version history.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of CourseVersion objects, newest first (in reverse order of creation)\n        \"\"\"\n        history = self.version_history.get(course_id, [])\n        # Return in reverse order (newest first) since versions are appended chronologically\n        return list(reversed(history))\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Latest CourseVersion or None if no versions exist\n        \"\"\"\n        history = self.get_version_history(course_id)\n        return history[0] if history else None\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        Args:\n            current_version: Current version string (e.g., \"1.0.0\")\n            change_type: Type of change ('major', 'minor', 'patch')\n            \n        Returns:\n            New version string\n        \"\"\"\n        try:\n            parts = current_version.split('.')\n            major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])\n            \n            if change_type == 'major':\n                major += 1\n                minor = 0\n                patch = 0\n            elif change_type == 'minor':\n                minor += 1\n                patch = 0\n            else:  # patch\n                patch += 1\n            \n            return f\"{major}.{minor}.{patch}\"\n        except Exception as e:\n            logger.warning(f\"Failed to increment version {current_version}: {e}\")\n            return current_version\n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        Args:\n            course_id: Course identifier\n            output_path: Optional custom output path\n        \"\"\"\n        if output_path is None:\n            output_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        history = self.get_version_history(course_id)\n        \n        # Serialize to JSON\n        history_data = []\n        for version in history:\n            history_data.append({\n                \"version\": version.version,\n                \"created_at\": version.created_at.isoformat(),\n                \"updated_at\": version.updated_at.isoformat(),\n                \"change_summary\": version.change_summary,\n                \"total_lessons\": version.total_lessons,\n                \"updated_lessons\": version.updated_lessons,\n                \"archived_lessons\": version.archived_lessons,\n                \"lesson_updates\": [\n                    {\n                        \"lesson_id\": u.lesson_id,\n                        \"file_path\": u.file_path,\n                        \"update_type\": u.update_type,\n                        \"changes\": u.changes,\n                        \"timestamp\": u.timestamp.isoformat()\n                    }\n                    for u in version.lesson_updates\n                ],\n                \"file_changes\": [\n                    {\n                        \"file_path\": c.file_path,\n                        \"change_type\": c.change_type,\n                        \"old_hash\": c.old_hash,\n                        \"new_hash\": c.new_hash,\n                        \"detected_at\": c.detected_at.isoformat()\n                    }\n                    for c in version.file_changes\n                ]\n            })\n        \n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(history_data, f, indent=2)\n        \n        logger.info(f\"Saved version history to {output_path}\")\n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        Args:\n            course_id: Course identifier\n            input_path: Optional custom input path\n        \"\"\"\n        if input_path is None:\n            input_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        if not os.path.exists(input_path):\n            logger.debug(f\"No version history file found at {input_path}\")\n            return\n        \n        try:\n            with open(input_path, 'r', encoding='utf-8') as f:\n                history_data = json.load(f)\n            \n            # Deserialize from JSON\n            versions = []\n            for data in history_data:\n                version = CourseVersion(\n                    version=data[\"version\"],\n                    created_at=datetime.fromisoformat(data[\"created_at\"]),\n                    updated_at=datetime.fromisoformat(data[\"updated_at\"]),\n                    change_summary=data[\"change_summary\"],\n                    total_lessons=data[\"total_lessons\"],\n                    updated_lessons=data[\"updated_lessons\"],\n                    archived_lessons=data[\"archived_lessons\"],\n                    lesson_updates=[\n                        LessonUpdate(\n                            lesson_id=u[\"lesson_id\"],\n                            file_path=u[\"file_path\"],\n                            update_type=u[\"update_type\"],\n                            changes=u[\"changes\"],\n                            timestamp=datetime.fromisoformat(u[\"timestamp\"])\n                        )\n                        for u in data[\"lesson_updates\"]\n                    ],\n                    file_changes=[\n                        FileChange(\n                            file_path=c[\"file_path\"],\n                            change_type=c[\"change_type\"],\n                            old_hash=c.get(\"old_hash\"),\n                            new_hash=c.get(\"new_hash\"),\n                            detected_at=datetime.fromisoformat(c[\"detected_at\"])\n                        )\n                        for c in data[\"file_changes\"]\n                    ]\n                )\n                versions.append(version)\n            \n            self.version_history[course_id] = versions\n            logger.info(f\"Loaded {len(versions)} versions from {input_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to load version history from {input_path}: {e}\")\n\n\n    async def update_course_incrementally(\n        self,\n        course: CourseOutline,\n        analysis: CodebaseAnalysis,\n        file_changes: List[FileChange],\n        content_generator,\n        structure_generator\n    ) -> Tuple[CourseOutline, CourseVersion]:\n        \"\"\"Update course incrementally based on file changes.\n        \n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\n        - Updates only changed lessons\n        - Preserves manual edits\n        - Archives deleted lessons\n        - Completes updates in <3s for <5 changes\n        \n        Args:\n            course: Current course outline\n            analysis: Current codebase analysis\n            file_changes: List of detected file changes\n            content_generator: LessonContentGenerator instance\n            structure_generator: CourseStructureGenerator instance\n            \n        Returns:\n            Tuple of (updated CourseOutline, CourseVersion)\n        \"\"\"\n        start_time = time.time()\n        \n        logger.info(\n            f\"Starting incremental update for course {course.course_id} \"\n            f\"with {len(file_changes)} file changes\"\n        )\n        \n        # Identify lessons to update\n        lessons_to_update = self.identify_lessons_to_update(course, file_changes)\n        \n        # Track updates\n        lesson_updates: List[LessonUpdate] = []\n        \n        # Process each lesson update\n        for lesson, change in lessons_to_update:\n            if change.change_type == 'deleted':\n                # Archive the lesson\n                self.archive_lesson(course.course_id, lesson, \"file_deleted\")\n                lesson_updates.append(LessonUpdate(\n                    lesson_id=lesson.lesson_id,\n                    file_path=lesson.file_path,\n                    update_type='archived',\n                    changes=['File deleted, lesson archived']\n                ))\n            \n            elif change.change_type in ['added', 'modified']:\n                # Update lesson content\n                update = await self._update_lesson_content(\n                    lesson,\n                    analysis,\n                    content_generator\n                )\n                lesson_updates.append(update)\n        \n        # Remove archived lessons from course\n        course = self._remove_archived_lessons(course, lesson_updates)\n        \n        # Update course metadata\n        course.version = self.increment_version(\n            course.version,\n            'minor' if len(file_changes) > 5 else 'patch'\n        )\n        course.created_at = datetime.now()  # Update timestamp\n        \n        # Create version entry\n        change_summary = self._generate_change_summary(file_changes, lesson_updates)\n        version = self.create_version(\n            course.course_id,\n            course.version,\n            change_summary,\n            lesson_updates,\n            file_changes,\n            self._count_total_lessons(course)\n        )\n        \n        # Save version history\n        self.save_version_history(course.course_id)\n        \n        elapsed_time = time.time() - start_time\n        logger.info(\n            f\"Incremental update completed in {elapsed_time:.2f}s: \"\n            f\"{len(lesson_updates)} lessons updated\"\n        )\n        \n        # Verify performance requirement (Req 15.5)\n        if len(file_changes) < 5 and elapsed_time > 3.0:\n            logger.warning(\n                f\"Update took {elapsed_time:.2f}s for {len(file_changes)} changes, \"\n                f\"exceeding 3s target\"\n            )\n        \n        return course, version\n    \n    async def _update_lesson_content(\n        self,\n        lesson: Lesson,\n        analysis: CodebaseAnalysis,\n        content_generator\n    ) -> LessonUpdate:\n        \"\"\"Update content for a single lesson.\n        \n        Implements Requirement 15.2: Preserves manual edits during update.\n        \n        Args:\n            lesson: Lesson to update\n            analysis: Current codebase analysis\n            content_generator: LessonContentGenerator instance\n            \n        Returns:\n            LessonUpdate describing the changes\n        \"\"\"\n        changes = []\n        \n        # Get file analysis\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            logger.warning(f\"No analysis found for {lesson.file_path}\")\n            return LessonUpdate(\n                lesson_id=lesson.lesson_id,\n                file_path=lesson.file_path,\n                update_type='content',\n                changes=['No analysis available']\n            )\n        \n        # Store old content if it exists\n        old_content = lesson.content\n        \n        # Generate new content\n        new_content = await content_generator.generate_lesson_content(file_analysis)\n        \n        # Preserve manual edits if any\n        if old_content and self._has_manual_edits(lesson.lesson_id):\n            merged_content = self.preserve_manual_edits(\n                lesson.lesson_id,\n                old_content,\n                new_content\n            )\n            lesson.content = merged_content\n            changes.append(\"Preserved manual edits\")\n        else:\n            lesson.content = new_content\n            changes.append(\"Regenerated content\")\n        \n        # Update lesson metadata\n        lesson.teaching_value = file_analysis.teaching_value.score\n        \n        # Update learning objectives if patterns changed\n        old_patterns = set(lesson.concepts)\n        new_patterns = set(p.pattern_type for p in file_analysis.patterns)\n        \n        if old_patterns != new_patterns:\n            lesson.concepts = list(new_patterns)\n            lesson.tags = list(new_patterns)\n            changes.append(f\"Updated patterns: {new_patterns - old_patterns}\")\n        \n        # Update complexity-based difficulty\n        new_difficulty = self._calculate_difficulty(file_analysis)\n        if new_difficulty != lesson.difficulty:\n            old_diff = lesson.difficulty\n            lesson.difficulty = new_difficulty\n            changes.append(f\"Difficulty changed: {old_diff} -> {new_difficulty}\")\n        \n        return LessonUpdate(\n            lesson_id=lesson.lesson_id,\n            file_path=lesson.file_path,\n            update_type='content',\n            changes=changes\n        )\n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        Args:\n            file_analysis: FileAnalysis object\n            \n        Returns:\n            Difficulty level string\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n    \n    def _remove_archived_lessons(\n        self,\n        course: CourseOutline,\n        lesson_updates: List[LessonUpdate]\n    ) -> CourseOutline:\n        \"\"\"Remove archived lessons from course structure.\n        \n        Args:\n            course: Course outline\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Updated course outline\n        \"\"\"\n        archived_ids = {\n            u.lesson_id for u in lesson_updates\n            if u.update_type == 'archived'\n        }\n        \n        if not archived_ids:\n            return course\n        \n        # Remove archived lessons from modules\n        for module in course.modules:\n            module.lessons = [\n                lesson for lesson in module.lessons\n                if lesson.lesson_id not in archived_ids\n            ]\n            \n            # Update lesson order after removal\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n            \n            # Update module duration\n            module.duration_hours = sum(l.duration_minutes for l in module.lessons) / 60.0\n        \n        # Remove empty modules\n        course.modules = [m for m in course.modules if len(m.lessons) > 0]\n        \n        # Update module order\n        for idx, module in enumerate(course.modules):\n            module.order = idx\n        \n        # Update course duration\n        course.total_duration_hours = sum(m.duration_hours for m in course.modules)\n        \n        # Update difficulty distribution\n        course.difficulty_distribution = self._calculate_difficulty_distribution(course)\n        \n        logger.info(f\"Removed {len(archived_ids)} archived lessons from course\")\n        \n        return course\n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Dictionary mapping difficulty levels to counts\n        \"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        \n        for module in course.modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n        \n        return distribution\n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Total number of lessons\n        \"\"\"\n        return sum(len(module.lessons) for module in course.modules)\n    \n    def _generate_change_summary(\n        self,\n        file_changes: List[FileChange],\n        lesson_updates: List[LessonUpdate]\n    ) -> str:\n        \"\"\"Generate a human-readable summary of changes.\n        \n        Args:\n            file_changes: List of file changes\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Change summary string\n        \"\"\"\n        parts = []\n        \n        # Count change types\n        added = len([c for c in file_changes if c.change_type == 'added'])\n        modified = len([c for c in file_changes if c.change_type == 'modified'])\n        deleted = len([c for c in file_changes if c.change_type == 'deleted'])\n        \n        if added > 0:\n            parts.append(f\"{added} file(s) added\")\n        if modified > 0:\n            parts.append(f\"{modified} file(s) modified\")\n        if deleted > 0:\n            parts.append(f\"{deleted} file(s) deleted\")\n        \n        # Count update types\n        content_updates = len([u for u in lesson_updates if u.update_type == 'content'])\n        archived = len([u for u in lesson_updates if u.update_type == 'archived'])\n        \n        if content_updates > 0:",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 40 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (10 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "03be03fd-65dd-48fc-9acd-495cbf870b3e",
          "title": "Exercise Generator: Python Async Await",
          "description": "Excellent teaching value (score: 0.84). Well-documented (100% coverage). Ideal complexity (avg: 4.8) for teaching. Contains useful patterns. Well-structured code. Demonstrates: python_context_managers, python_async_await, python_comprehensions",
          "order": 1,
          "difficulty": "beginner",
          "duration_minutes": 48,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\exercise_generator.py",
          "teaching_value": 0.84,
          "learning_objectives": [
            "Understand python context managers pattern",
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "2c0ff45e-8d46-4644-8b93-14e2e590812d",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\exercise_generator.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 2, Await statements: 4"
              ],
              "starter_code": "    \n    async def generate_exercise(self, pattern: DetectedPattern, file_analysis: FileAnalysis) -> Exercise:\n        \"\"\"Generate a coding exercise from a detected pattern.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n            # Check cache first\n                    import logging\n            \n            # Extract solution code from the pattern\n        \n        # Create starter code with TODOs\n        \n        # Generate step-by-step instructions\n        \n        # Generate hints\n        \n        # Generate test cases\n        \n        # Determine difficulty based on complexity\n        \n        # Estimate time based on complexity\n        \n        # Generate learning objectives\n        \n        \n        # Cache the result\n        \n    \n    def _extract_pattern_code(self, pattern: DetectedPattern, file_analysis: FileAnalysis) -> str:\n        \"\"\"Extract relevant code demonstrating the pattern.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        # Read the source file\n            \n            # If pattern has line numbers, extract those lines\n                \n                # Expand to include context (up to 10 lines before/after)\n                \n            \n            # Otherwise, try to find relevant function or class\n            \n                    # Limit to 50 lines\n            \n            # Fallback: return first 30 lines\n            \n            # Fallback to a simple template\n    \n    def _create_starter_code(self, solution_code: str, pattern_type: str) -> str:\n        \"\"\"Create starter code with TODO comments.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n            \n            # Keep imports, class definitions, function signatures\n                \n            \n            # Keep docstrings\n            if '\"\"\"' in stripped or \"'''\" in stripped:\n            \n            # Keep decorators\n            \n            # Replace function body with TODO\n                # Add TODO on first line of implementation\n                # Keep empty lines and comments\n        \n    \n    def _generate_instructions(self, pattern: DetectedPattern, file_analysis: FileAnalysis) -> List[str]:\n        \"\"\"Generate step-by-step instructions for the exercise.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n        # Generic instructions based on pattern type\n            # Generic instructions\n        \n        # Add pattern-specific evidence as hints\n        \n    \n    def _generate_hints(self, solution_code: str, pattern_type: str) -> List[str]:\n        \"\"\"Generate progressive hints for the exercise.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n        # Hint 1: High-level approach\n        \n        # Hint 2: Key implementation details\n        \n        # Hint 3: Specific guidance\n        \n    \n    def _generate_test_cases(self, pattern: DetectedPattern, solution_code: str) -> List[TestCase]:\n        \"\"\"Generate test cases for validating the exercise solution.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n        # Generate basic test cases based on pattern type\n            # Generic test case\n        \n    \n    def _determine_difficulty(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Determine exercise difficulty based on file complexity.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n    \n    def _estimate_time(self, difficulty: str, instruction_count: int) -> int:\n        \"\"\"Estimate time to complete exercise in minutes.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n        # Add 5 minutes per instruction step\n        \n    \n    def _generate_learning_objectives(self, pattern: DetectedPattern) -> List[str]:\n        \"\"\"Generate learning objectives for the exercise.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        \n        # Format pattern name for readability\n        \n        \n        # Add objectives based on evidence\n        \n    \n    def _format_pattern_name(self, pattern_type: str) -> str:\n        \"\"\"Format pattern type name for display.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n        # Convert snake_case or camelCase to Title Case\n    \n    async def generate_exercises_for_lesson(\n        # TODO: Implement python_async_await logic here\n        pass",
              "solution_code": "self.course_cache = course_cache\n    \n    async def generate_exercise(self, pattern: DetectedPattern, file_analysis: FileAnalysis) -> Exercise:\n        \"\"\"Generate a coding exercise from a detected pattern.\n        \n        Args:\n            pattern: Detected pattern to create exercise from\n            file_analysis: File analysis containing the pattern\n            \n        Returns:\n            Exercise with starter code, solution, hints, and test cases\n        \"\"\"\n        monitor = get_monitor()\n        \n        with monitor.measure(\"exercise_generation\", pattern_type=pattern.pattern_type):\n            # Check cache first\n            if self.course_cache:\n                cached = await self.course_cache.get_exercise(\n                    file_analysis.file_path,\n                    pattern.pattern_type\n                )\n                if cached and \"data\" in cached:\n                    import logging\n                    logging.getLogger(__name__).info(\n                        f\"Using cached exercise for {file_analysis.file_path}:{pattern.pattern_type}\"\n                    )\n                    return self._deserialize_exercise(cached[\"data\"])\n            \n            # Extract solution code from the pattern\n            solution_code = self._extract_pattern_code(pattern, file_analysis)\n        \n        # Create starter code with TODOs\n        starter_code = self._create_starter_code(solution_code, pattern.pattern_type)\n        \n        # Generate step-by-step instructions\n        instructions = self._generate_instructions(pattern, file_analysis)\n        \n        # Generate hints\n        hints = self._generate_hints(solution_code, pattern.pattern_type)\n        \n        # Generate test cases\n        test_cases = self._generate_test_cases(pattern, solution_code)\n        \n        # Determine difficulty based on complexity\n        difficulty = self._determine_difficulty(file_analysis)\n        \n        # Estimate time based on complexity\n        estimated_minutes = self._estimate_time(difficulty, len(instructions))\n        \n        # Generate learning objectives\n        learning_objectives = self._generate_learning_objectives(pattern)\n        \n        exercise = Exercise(\n            exercise_id=str(uuid.uuid4()),\n            title=f\"Practice: {self._format_pattern_name(pattern.pattern_type)}\",\n            description=f\"Implement a {pattern.pattern_type} based on the example from {file_analysis.file_path}\",\n            difficulty=difficulty,\n            estimated_minutes=estimated_minutes,\n            instructions=instructions,\n            starter_code=starter_code,\n            solution_code=solution_code,\n            hints=hints,\n            test_cases=test_cases,\n            learning_objectives=learning_objectives\n        )\n        \n        # Cache the result\n        if self.course_cache:\n            serialized = self._serialize_exercise(exercise)\n            await self.course_cache.set_exercise(\n                file_analysis.file_path,\n                pattern.pattern_type,\n                serialized\n            )\n        \n        return exercise\n    \n    def _extract_pattern_code(self, pattern: DetectedPattern, file_analysis: FileAnalysis) -> str:\n        \"\"\"Extract relevant code demonstrating the pattern.\n        \n        Args:\n            pattern: Detected pattern\n            file_analysis: File analysis containing the pattern\n            \n        Returns:\n            Code snippet demonstrating the pattern\n        \"\"\"\n        # Read the source file\n        try:\n            with open(file_analysis.file_path, 'r', encoding='utf-8') as f:\n                lines = f.readlines()\n            \n            # If pattern has line numbers, extract those lines\n            if pattern.line_numbers:\n                start_line = min(pattern.line_numbers) - 1  # 0-indexed\n                end_line = max(pattern.line_numbers)\n                \n                # Expand to include context (up to 10 lines before/after)\n                start_line = max(0, start_line - 2)\n                end_line = min(len(lines), end_line + 2)\n                \n                code_lines = lines[start_line:end_line]\n                return ''.join(code_lines).strip()\n            \n            # Otherwise, try to find relevant function or class\n            for func in file_analysis.symbol_info.functions:\n                if any(evidence in func.name.lower() for evidence in pattern.evidence):\n                    func_lines = lines[func.start_line - 1:func.end_line]\n                    return ''.join(func_lines).strip()\n            \n            for cls in file_analysis.symbol_info.classes:\n                if any(evidence in cls.name.lower() for evidence in pattern.evidence):\n                    cls_lines = lines[cls.start_line - 1:cls.end_line]\n                    # Limit to 50 lines\n                    if len(cls_lines) > 50:\n                        cls_lines = cls_lines[:50]\n                        cls_lines.append(\"    # ... (truncated for brevity)\\n\")\n                    return ''.join(cls_lines).strip()\n            \n            # Fallback: return first 30 lines\n            return ''.join(lines[:30]).strip()\n            \n        except Exception as e:\n            # Fallback to a simple template\n            return f\"# Code example for {pattern.pattern_type}\\n# (Unable to extract: {str(e)})\"\n    \n    def _create_starter_code(self, solution_code: str, pattern_type: str) -> str:\n        \"\"\"Create starter code with TODO comments.\n        \n        Args:\n            solution_code: Complete solution code\n            pattern_type: Type of pattern\n            \n        Returns:\n            Starter code with TODOs replacing implementation\n        \"\"\"\n        lines = solution_code.split('\\n')\n        starter_lines = []\n        in_function = False\n        indent_level = 0\n        \n        for line in lines:\n            stripped = line.lstrip()\n            \n            # Keep imports, class definitions, function signatures\n            if (stripped.startswith('import ') or \n                stripped.startswith('from ') or\n                stripped.startswith('class ') or\n                stripped.startswith('def ') or\n                stripped.startswith('async def ')):\n                starter_lines.append(line)\n                \n                if stripped.startswith('def ') or stripped.startswith('async def '):\n                    in_function = True\n                    indent_level = len(line) - len(stripped) + 4\n                continue\n            \n            # Keep docstrings\n            if '\"\"\"' in stripped or \"'''\" in stripped:\n                starter_lines.append(line)\n                continue\n            \n            # Keep decorators\n            if stripped.startswith('@'):\n                starter_lines.append(line)\n                continue\n            \n            # Replace function body with TODO\n            if in_function and stripped and not stripped.startswith('#'):\n                # Add TODO on first line of implementation\n                todo_line = ' ' * indent_level + f\"# TODO: Implement {pattern_type} logic here\"\n                starter_lines.append(todo_line)\n                starter_lines.append(' ' * indent_level + \"pass\")\n                in_function = False\n            elif not stripped or stripped.startswith('#'):\n                # Keep empty lines and comments\n                starter_lines.append(line)\n        \n        return '\\n'.join(starter_lines)\n    \n    def _generate_instructions(self, pattern: DetectedPattern, file_analysis: FileAnalysis) -> List[str]:\n        \"\"\"Generate step-by-step instructions for the exercise.\n        \n        Args:\n            pattern: Detected pattern\n            file_analysis: File analysis\n            \n        Returns:\n            List of instruction steps\n        \"\"\"\n        instructions = []\n        pattern_type = pattern.pattern_type\n        \n        # Generic instructions based on pattern type\n        if 'component' in pattern_type.lower():\n            instructions.extend([\n                \"Create the component structure with proper imports\",\n                \"Define the component's props and state\",\n                \"Implement the component's render logic\",\n                \"Add any necessary event handlers\"\n            ])\n        elif 'api' in pattern_type.lower() or 'route' in pattern_type.lower():\n            instructions.extend([\n                \"Define the API endpoint with proper HTTP method\",\n                \"Implement request validation\",\n                \"Add the main business logic\",\n                \"Return appropriate response with status codes\"\n            ])\n        elif 'class' in pattern_type.lower():\n            instructions.extend([\n                \"Define the class with appropriate attributes\",\n                \"Implement the constructor/initializer\",\n                \"Add the required methods\",\n                \"Ensure proper encapsulation\"\n            ])\n        elif 'function' in pattern_type.lower():\n            instructions.extend([\n                \"Define the function signature with parameters\",\n                \"Add input validation if needed\",\n                \"Implement the core logic\",\n                \"Return the expected result\"\n            ])\n        else:\n            # Generic instructions\n            instructions.extend([\n                f\"Implement the {pattern_type} following the pattern shown\",\n                \"Ensure all required functionality is included\",\n                \"Test your implementation with the provided test cases\"\n            ])\n        \n        # Add pattern-specific evidence as hints\n        if pattern.evidence:\n            instructions.append(f\"Key concepts to include: {', '.join(pattern.evidence[:3])}\")\n        \n        return instructions\n    \n    def _generate_hints(self, solution_code: str, pattern_type: str) -> List[str]:\n        \"\"\"Generate progressive hints for the exercise.\n        \n        Args:\n            solution_code: Complete solution code\n            pattern_type: Type of pattern\n            \n        Returns:\n            List of hints with progressive revelation\n        \"\"\"\n        hints = []\n        \n        # Hint 1: High-level approach\n        hints.append(\n            f\"Start by understanding the structure of a {pattern_type}. \"\n            \"Look at the imports and main components needed.\"\n        )\n        \n        # Hint 2: Key implementation details\n        lines = solution_code.split('\\n')\n        key_lines = [line for line in lines if 'def ' in line or 'class ' in line or 'return ' in line]\n        if key_lines:\n            hints.append(\n                f\"Key elements to implement: {len(key_lines)} main components. \"\n                \"Focus on the function signatures and return values first.\"\n            )\n        \n        # Hint 3: Specific guidance\n        if 'import' in solution_code:\n            imports = [line for line in lines if line.strip().startswith('import') or line.strip().startswith('from')]\n            if imports:\n                hints.append(f\"You'll need these imports: {imports[0].strip()}\")\n        \n        return hints\n    \n    def _generate_test_cases(self, pattern: DetectedPattern, solution_code: str) -> List[TestCase]:\n        \"\"\"Generate test cases for validating the exercise solution.\n        \n        Args:\n            pattern: Detected pattern\n            solution_code: Complete solution code\n            \n        Returns:\n            List of test cases\n        \"\"\"\n        test_cases = []\n        pattern_type = pattern.pattern_type\n        \n        # Generate basic test cases based on pattern type\n        if 'function' in pattern_type.lower():\n            test_cases.append(TestCase(\n                input=\"Basic input\",\n                expected_output=\"Expected output based on function logic\",\n                description=\"Test basic functionality\"\n            ))\n            test_cases.append(TestCase(\n                input=\"Edge case input\",\n                expected_output=\"Expected edge case output\",\n                description=\"Test edge case handling\"\n            ))\n        elif 'class' in pattern_type.lower():\n            test_cases.append(TestCase(\n                input=\"Create instance with valid parameters\",\n                expected_output=\"Instance created successfully\",\n                description=\"Test class instantiation\"\n            ))\n            test_cases.append(TestCase(\n                input=\"Call main method\",\n                expected_output=\"Method returns expected result\",\n                description=\"Test main method functionality\"\n            ))\n        elif 'api' in pattern_type.lower():\n            test_cases.append(TestCase(\n                input=\"Valid request payload\",\n                expected_output=\"200 OK with expected response\",\n                description=\"Test successful API call\"\n            ))\n            test_cases.append(TestCase(\n                input=\"Invalid request payload\",\n                expected_output=\"400 Bad Request\",\n                description=\"Test error handling\"\n            ))\n        else:\n            # Generic test case\n            test_cases.append(TestCase(\n                input=\"Sample input\",\n                expected_output=\"Expected output\",\n                description=f\"Test {pattern_type} implementation\"\n            ))\n        \n        return test_cases\n    \n    def _determine_difficulty(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Determine exercise difficulty based on file complexity.\n        \n        Args:\n            file_analysis: File analysis with complexity metrics\n            \n        Returns:\n            Difficulty level: 'beginner', 'intermediate', or 'advanced'\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity < 5:\n            return 'beginner'\n        elif avg_complexity < 10:\n            return 'intermediate'\n        else:\n            return 'advanced'\n    \n    def _estimate_time(self, difficulty: str, instruction_count: int) -> int:\n        \"\"\"Estimate time to complete exercise in minutes.\n        \n        Args:\n            difficulty: Exercise difficulty level\n            instruction_count: Number of instruction steps\n            \n        Returns:\n            Estimated minutes to complete\n        \"\"\"\n        base_time = {\n            'beginner': 15,\n            'intermediate': 25,\n            'advanced': 40\n        }\n        \n        time = base_time.get(difficulty, 20)\n        # Add 5 minutes per instruction step\n        time += instruction_count * 5\n        \n        return min(time, 60)  # Cap at 60 minutes\n    \n    def _generate_learning_objectives(self, pattern: DetectedPattern) -> List[str]:\n        \"\"\"Generate learning objectives for the exercise.\n        \n        Args:\n            pattern: Detected pattern\n            \n        Returns:\n            List of learning objectives\n        \"\"\"\n        objectives = []\n        pattern_type = pattern.pattern_type\n        \n        # Format pattern name for readability\n        formatted_name = self._format_pattern_name(pattern_type)\n        \n        objectives.append(f\"Understand how to implement a {formatted_name}\")\n        objectives.append(f\"Practice writing clean, maintainable code for {formatted_name}\")\n        \n        # Add objectives based on evidence\n        if pattern.evidence:\n            for evidence in pattern.evidence[:2]:\n                objectives.append(f\"Apply {evidence} in your implementation\")\n        \n        return objectives\n    \n    def _format_pattern_name(self, pattern_type: str) -> str:\n        \"\"\"Format pattern type name for display.\n        \n        Args:\n            pattern_type: Raw pattern type string\n            \n        Returns:\n            Formatted, human-readable pattern name\n        \"\"\"\n        # Convert snake_case or camelCase to Title Case\n        formatted = re.sub(r'[_-]', ' ', pattern_type)\n        formatted = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', formatted)\n        return formatted.title()\n    \n    async def generate_exercises_for_lesson(\n        self, \n        file_analysis: FileAnalysis,",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 38 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: import logging"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 2 in your implementation",
                "Apply Await statements: 4 in your implementation"
              ]
            }
          ],
          "tags": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "bb68a1d1-b02c-4f83-9563-602c18630b17",
          "title": "Linter Integration: Python Async Await",
          "description": "Excellent teaching value (score: 0.83). Well-documented (100% coverage). Ideal complexity (avg: 3.3) for teaching. Contains useful patterns. Well-structured code. Demonstrates: python_async_await, python_comprehensions",
          "order": 2,
          "difficulty": "beginner",
          "duration_minutes": 42,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\linter_integration.py",
          "teaching_value": 0.83,
          "learning_objectives": [
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "4b2f2a83-51be-4784-9cba-587e9bd3cbb6",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\linter_integration.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 3, Await statements: 7, Uses asyncio library"
              ],
              "starter_code": "    \n    async def run_linters(self, file_path: str, language: str) -> List[LinterIssue]:\n        \"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \n        \n        \n        \"\"\"\n        \n        # Get the appropriate linter function\n        \n            # Graceful degradation: log warning but don't fail analysis\n    \n    async def _run_pylint(self, file_path: str) -> List[LinterIssue]:\n        \"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \n        \n        \"\"\"\n            # Run pylint with JSON output format\n            \n            \n            # Pylint exit codes:\n            # 0: No errors\n            # 1: Fatal message issued\n            # 2: Error message issued\n            # 4: Warning message issued\n            # 8: Refactor message issued\n            # 16: Convention message issued\n            # 32: Usage error\n            \n            # Parse JSON output\n                \n                \n            \n            \n    \n    async def _run_eslint(self, file_path: str) -> List[LinterIssue]:\n        \"\"\"\n        # TODO: Implement python_async_await logic here\n        pass",
              "solution_code": "}\n    \n    async def run_linters(self, file_path: str, language: str) -> List[LinterIssue]:\n        \"\"\"\n        Run appropriate linters for the given file.\n        \n        This method is non-blocking and gracefully handles linter failures.\n        If linters are disabled or the linter fails, an empty list is returned.\n        \n        Args:\n            file_path: Path to the file to lint\n            language: Programming language of the file\n        \n        Returns:\n            List of LinterIssue objects, or empty list if linting fails\n        \n        Example:\n            issues = await linter.run_linters(\"src/main.py\", \"python\")\n            for issue in issues:\n                print(f\"{issue.severity}: {issue.message} at line {issue.line}\")\n        \"\"\"\n        if not self.enabled:\n            logger.debug(\"Linters disabled in configuration\")\n            return []\n        \n        # Get the appropriate linter function\n        linter_func = self._linter_map.get(language)\n        if not linter_func:\n            logger.debug(f\"No linter available for language: {language}\")\n            return []\n        \n        try:\n            logger.info(f\"Running linter for {file_path}\")\n            issues = await linter_func(file_path)\n            logger.info(f\"Found {len(issues)} linter issues in {file_path}\")\n            return issues\n        except Exception as e:\n            # Graceful degradation: log warning but don't fail analysis\n            logger.warning(f\"Linter failed for {file_path}: {e}\")\n            return []\n    \n    async def _run_pylint(self, file_path: str) -> List[LinterIssue]:\n        \"\"\"\n        Run pylint on a Python file.\n        \n        Args:\n            file_path: Path to Python file\n        \n        Returns:\n            List of LinterIssue objects from pylint output\n        \n        Raises:\n            Exception: If pylint execution fails\n        \"\"\"\n        try:\n            # Run pylint with JSON output format\n            proc = await asyncio.create_subprocess_exec(\n                'pylint',\n                file_path,\n                '--output-format=json',\n                '--score=no',  # Don't include score in output\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE\n            )\n            \n            stdout, stderr = await proc.communicate()\n            \n            # Pylint exit codes:\n            # 0: No errors\n            # 1: Fatal message issued\n            # 2: Error message issued\n            # 4: Warning message issued\n            # 8: Refactor message issued\n            # 16: Convention message issued\n            # 32: Usage error\n            if proc.returncode == 32:\n                raise Exception(f\"Pylint usage error: {stderr.decode()}\")\n            \n            # Parse JSON output\n            if stdout:\n                issues_data = json.loads(stdout.decode())\n                issues = []\n                \n                for issue in issues_data:\n                    issues.append(LinterIssue(\n                        tool='pylint',\n                        severity=self._map_pylint_severity(issue.get('type', 'warning')),\n                        message=issue.get('message', ''),\n                        line=issue.get('line', 0),\n                        column=issue.get('column', 0),\n                        rule=issue.get('message-id', 'unknown')\n                    ))\n                \n                return issues\n            \n            return []\n            \n        except FileNotFoundError:\n            raise Exception(\"pylint not found. Install with: pip install pylint\")\n        except json.JSONDecodeError as e:\n            raise Exception(f\"Failed to parse pylint output: {e}\")\n    \n    async def _run_eslint(self, file_path: str) -> List[LinterIssue]:\n        \"\"\"\n        Run eslint on a JavaScript/TypeScript file.",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 9 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 3 in your implementation",
                "Apply Await statements: 7 in your implementation"
              ]
            }
          ],
          "tags": [
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "60ff7a4d-04e7-4bbb-83b5-c27b8511a4ef",
          "title": "Enrichment Guide Generator: Python Async Await",
          "description": "Excellent teaching value (score: 0.80). Well-documented (100% coverage). Ideal complexity (avg: 3.0) for teaching. Contains some patterns. Well-structured code. Demonstrates: python_async_await",
          "order": 3,
          "difficulty": "beginner",
          "duration_minutes": 42,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\enrichment_guide_generator.py",
          "teaching_value": 0.8,
          "learning_objectives": [
            "Understand python async await pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_async_await"
          ],
          "exercises": [
            {
              "exercise_id": "9bf8e36d-829c-44bf-bfc8-407a503b0907",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\enrichment_guide_generator.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 2, Await statements: 4"
              ],
              "starter_code": "    \n    async def generate_guide(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n        \n            \n        \"\"\"\n        \n            # Get file analysis if not provided\n            \n            # Phase 1: Feature Mapping\n            \n            # Phase 2: Evidence Collection\n            \n            # Enrich feature mapping with git/doc evidence\n            \n            # Phase 3: Validation\n            \n            # Phase 4: Teaching Value Assessment\n            \n            # Phase 5: Systematic Investigation\n            \n            # Phase 6: Code Section Guides\n            \n            # Phase 7: Narrative Structure\n            \n            # Phase 8: Architecture Context\n            \n            # Phase 9: Real-World Context\n            \n            # Phase 10: Exercise Generation\n            \n            # Phase 11: Anti-Hallucination Rules\n            \n            # Phase 12: Enrichment Instructions\n            \n            # Create complete enrichment guide\n            \n            \n            \n    \n    async def _collect_evidence(\n        # TODO: Implement python_async_await logic here\n        pass",
              "solution_code": "logger.info(f\"Initialized EnrichmentGuideGenerator for: {self.repo_path}\")\n    \n    async def generate_guide(\n        self,\n        codebase_id: str,\n        lesson: Lesson,\n        file_analysis: Optional[FileAnalysis] = None\n    ) -> EnrichmentGuide:\n        \"\"\"\n        Generate a comprehensive enrichment guide for a lesson.\n        \n        This is the main entry point that orchestrates all enrichment components\n        to create a complete, evidence-based guide for AI content enrichment.\n        \n        Args:\n            codebase_id: Identifier for the codebase\n            lesson: Lesson object containing file path and metadata\n            file_analysis: Optional pre-computed FileAnalysis (will analyze if not provided)\n            \n        Returns:\n            Complete EnrichmentGuide with all components\n        \"\"\"\n        logger.info(\n            f\"Generating enrichment guide for lesson '{lesson.lesson_id}' \"\n            f\"in codebase '{codebase_id}'\"\n        )\n        \n        try:\n            # Get file analysis if not provided\n            if not file_analysis:\n                logger.info(f\"Analyzing file: {lesson.file_path}\")\n                file_analysis = await self.analysis_engine.analyze_file(\n                    lesson.file_path,\n                    use_cache=True\n                )\n            \n            # Phase 1: Feature Mapping\n            logger.info(\"Phase 1: Feature Mapping\")\n            feature_mapping = self.feature_mapper.identify_feature_from_code(\n                lesson,\n                file_analysis\n            )\n            \n            # Phase 2: Evidence Collection\n            logger.info(\"Phase 2: Evidence Collection\")\n            evidence_bundle = await self._collect_evidence(lesson, file_analysis)\n            \n            # Enrich feature mapping with git/doc evidence\n            feature_mapping.business_value = self.feature_mapper.extract_business_value(\n                feature_mapping,\n                {\n                    'git_commits': evidence_bundle.git_commits,\n                    'documentation': evidence_bundle.documentation\n                }\n            )\n            \n            # Phase 3: Validation\n            logger.info(\"Phase 3: Validation\")\n            validation_checklist = self._validate_understanding(evidence_bundle)\n            \n            # Phase 4: Teaching Value Assessment\n            logger.info(\"Phase 4: Teaching Value Assessment\")\n            teaching_value_assessment = self.teaching_value_assessor.assess_teaching_value(\n                feature_mapping,\n                evidence_bundle,\n                file_analysis\n            )\n            \n            # Phase 5: Systematic Investigation\n            logger.info(\"Phase 5: Systematic Investigation\")\n            systematic_investigation = self.investigation_engine.investigate(\n                feature_mapping,\n                evidence_bundle,\n                validation_checklist\n            )\n            \n            # Phase 6: Code Section Guides\n            logger.info(\"Phase 6: Code Section Guides\")\n            code_sections = self._generate_code_section_guides(\n                lesson,\n                evidence_bundle\n            )\n            \n            # Phase 7: Narrative Structure\n            logger.info(\"Phase 7: Narrative Structure\")\n            narrative_structure = self.narrative_builder.build_narrative(\n                systematic_investigation,\n                teaching_value_assessment,\n                code_sections,\n                lesson_context=self._get_lesson_context(lesson),\n                course_outline=None  # Could be passed in if available\n            )\n            \n            # Phase 8: Architecture Context\n            logger.info(\"Phase 8: Architecture Context\")\n            architecture_context = self._extract_architecture_context(\n                file_analysis\n            )\n            \n            # Phase 9: Real-World Context\n            logger.info(\"Phase 9: Real-World Context\")\n            real_world_context = self.real_world_suggester.generate_context(\n                feature_mapping,\n                file_analysis.patterns,\n                evidence_bundle,\n                skill_level=\"beginner\"\n            )\n            \n            # Phase 10: Exercise Generation\n            logger.info(\"Phase 10: Exercise Generation\")\n            exercise_generation = self.exercise_generator.generate_exercises(\n                feature_mapping,\n                evidence_bundle\n            )\n            \n            # Phase 11: Anti-Hallucination Rules\n            anti_hallucination_rules = self._get_anti_hallucination_rules()\n            \n            # Phase 12: Enrichment Instructions\n            enrichment_instructions = self._get_enrichment_instructions(\n                teaching_value_assessment\n            )\n            \n            # Create complete enrichment guide\n            enrichment_guide = EnrichmentGuide(\n                lesson_id=lesson.lesson_id,\n                feature_mapping=feature_mapping,\n                evidence_bundle=evidence_bundle,\n                validation_checklist=validation_checklist,\n                teaching_value_assessment=teaching_value_assessment,\n                systematic_investigation=systematic_investigation,\n                narrative_structure=narrative_structure,\n                code_sections=code_sections,\n                architecture_context=architecture_context,\n                real_world_context=real_world_context,\n                exercise_generation=exercise_generation,\n                anti_hallucination_rules=anti_hallucination_rules,\n                enrichment_instructions=enrichment_instructions\n            )\n            \n            logger.info(\n                f\"Successfully generated enrichment guide for lesson '{lesson.lesson_id}': \"\n                f\"teaching_value={teaching_value_assessment.total_score}/14, \"\n                f\"should_teach={teaching_value_assessment.should_teach}, \"\n                f\"{len(code_sections)} code sections, \"\n                f\"{len(evidence_bundle.test_files)} test files, \"\n                f\"{len(evidence_bundle.git_commits)} git commits\"\n            )\n            \n            return enrichment_guide\n            \n        except Exception as e:\n            logger.error(\n                f\"Error generating enrichment guide for lesson '{lesson.lesson_id}': {e}\",\n                exc_info=True\n            )\n            raise\n    \n    async def _collect_evidence(\n        self,\n        lesson: Lesson,",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 3 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 2 in your implementation",
                "Apply Await statements: 4 in your implementation"
              ]
            }
          ],
          "tags": [
            "python_async_await"
          ]
        },
        {
          "lesson_id": "7b9417c2-c5fa-44d9-af20-9cfdb1d7f7ac",
          "title": "Unified Cache: Python Async Await",
          "description": "Excellent teaching value (score: 0.77). Well-documented (100% coverage). Ideal complexity (avg: 3.5) for teaching. Contains useful patterns. Reasonable structure. Demonstrates: session_authentication, python_async_await",
          "order": 4,
          "difficulty": "beginner",
          "duration_minutes": 42,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\cache\\unified_cache.py",
          "teaching_value": 0.77,
          "learning_objectives": [
            "Understand session authentication pattern",
            "Understand python async await pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "session_authentication",
            "python_async_await"
          ],
          "exercises": [
            {
              "exercise_id": "cb603fc5-7953-4790-918e-1376e4605e54",
              "title": "Practice: Session Authentication",
              "description": "Implement a session_authentication based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\cache\\unified_cache.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the session_authentication following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Session feature: session, Session feature: Session, Session feature: set_session"
              ],
              "starter_code": "\n\"\"\"\n\nimport json\nimport logging\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import datetime\nfrom typing import Any, Optional\n\nimport aiosqlite\n\n\n\n\nclass UnifiedCacheManager:\n    \"\"\"3-Tier cache manager with Memory, SQLite, and optional Redis support.\n    \n    \"\"\"\n    \n    def __init__(\n        # TODO: Implement session_authentication logic here\n        pass\n        \"\"\"Initialize the cache manager.\n        \n        \"\"\"\n        # Memory cache (Tier 1) - LRU using OrderedDict\n        \n        # SQLite cache (Tier 2)\n        \n        # Redis cache (Tier 3) - optional\n        \n        # Session state storage\n        \n        # Resource storage (for MCP resources)\n        \n        # Statistics tracking\n        \n        # Initialization flag\n    \n    async def initialize(self):\n        \"\"\"Initialize cache connections and create database tables.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n        \"\"\"\n        \n        \n        # Initialize SQLite\n        \n        # Initialize Redis if URL provided\n                # Import redis only if needed\n                import redis.asyncio as aioredis\n                # Test connection\n        \n    \n    async def close(self):\n        \"\"\"Close all cache connections and cleanup resources.\"\"\"\n        # TODO: Implement session_authentication logic here\n        pass\n        \n        \n        # Close SQLite connection\n        \n        # Close Redis connection\n        \n        # Clear memory cache\n        \n    \n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        # TODO: Implement session_authentication logic here\n        pass\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        # TODO: Implement session_authentication logic here\n        pass\n    \n    async def _create_tables(self):\n        \"\"\"Create SQLite database tables if they don't exist.\"\"\"\n        # TODO: Implement session_authentication logic here\n        pass\n        \n        # File cache table\n        await self.sqlite_conn.execute(\"\"\"\n        \"\"\")\n        \n        # Analysis cache table\n        await self.sqlite_conn.execute(\"\"\"\n        \"\"\")\n        \n        # Session state table\n        await self.sqlite_conn.execute(\"\"\"\n        \"\"\")\n        \n\n    \n    def _get_size(self, data: Any) -> int:\n        \"\"\"Estimate the size of data in bytes.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n            \n        \"\"\"\n            # Serialize to JSON and measure the actual string length\n            # Use len() to get actual string size, not Python object overhead\n            # Fallback to sys.getsizeof\n    \n    def _evict_lru(self):\n        \"\"\"Evict least recently used item from memory cache.\"\"\"\n        # TODO: Implement session_authentication logic here\n        pass\n        \n        # Remove oldest item (first item in OrderedDict)\n    \n    def _ensure_memory_space(self, required_size: int):\n        \"\"\"Ensure enough memory space by evicting LRU items if needed.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n        \"\"\"\n    \n    async def get_analysis(self, key: str) -> Optional[dict]:\n        \"\"\"Get analysis result from cache with tier promotion.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Check memory cache (Tier 1)\n            # Move to end (most recently used)\n        \n        \n        # Check SQLite cache (Tier 2)\n                        \n                        # Check if expired\n                        \n                        \n                        # Promote to memory cache\n                        \n        \n        \n        # Check Redis cache (Tier 3)\n                    \n                    # Promote to memory and SQLite\n                    \n        \n    \n    async def _promote_to_memory(self, key: str, data: dict):\n        \"\"\"Promote data to memory cache.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n        \"\"\"\n        \n    \n    async def _promote_to_sqlite(self, key: str, data: dict, ttl: int):\n        \"\"\"Promote data to SQLite cache.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n        \"\"\"\n        \n                \"\"\"\n                \"\"\",\n    \n    async def set_analysis(self, key: str, data: dict, ttl: int = 3600):\n        \"\"\"Store analysis result in all cache tiers.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n        \"\"\"\n        # Store in memory cache (Tier 1)\n        \n        \n        # Store in SQLite cache (Tier 2)\n                    \"\"\"\n                    \"\"\",\n        \n        # Store in Redis cache (Tier 3)\n    \n    async def get_session(self, codebase_id: str) -> Optional[dict]:\n        \"\"\"Get session state for a codebase.\n        \n        # TODO: Implement session_authentication logic here\n        pass\n            \n        \"\"\"\n        # Check memory first\n        \n        # Check SQLite\n                        # Cache in memory\n        \n    \n    async def set_session(self, codebase_id: str, state: dict):\n        \"\"\"Store session state for a codebase.",
              "solution_code": "- Tier 3: Optional Redis distributed cache (<0.2s access)\n\nThe cache manager supports cache promotion, statistics tracking, and session state management.\n\"\"\"\n\nimport json\nimport logging\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom datetime import datetime\nfrom typing import Any, Optional\n\nimport aiosqlite\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass UnifiedCacheManager:\n    \"\"\"3-Tier cache manager with Memory, SQLite, and optional Redis support.\n    \n    Provides high-performance caching with automatic promotion between tiers,\n    LRU eviction, and comprehensive statistics tracking.\n    \"\"\"\n    \n    def __init__(\n        self,\n        max_memory_mb: int = 500,\n        sqlite_path: str = \"cache_db/cache.db\",\n        redis_url: Optional[str] = None\n    ):\n        \"\"\"Initialize the cache manager.\n        \n        Args:\n            max_memory_mb: Maximum memory cache size in MB (default: 500)\n            sqlite_path: Path to SQLite database file (default: \"cache_db/cache.db\")\n            redis_url: Optional Redis connection URL (default: None)\n        \"\"\"\n        # Memory cache (Tier 1) - LRU using OrderedDict\n        self.memory_cache: OrderedDict[str, dict] = OrderedDict()\n        self.current_memory_size = 0\n        self.max_memory_bytes = max_memory_mb * 1024 * 1024\n        \n        # SQLite cache (Tier 2)\n        self.sqlite_path = sqlite_path\n        self.sqlite_conn: Optional[aiosqlite.Connection] = None\n        \n        # Redis cache (Tier 3) - optional\n        self.redis_url = redis_url\n        self.redis_client = None\n        \n        # Session state storage\n        self.session_state: dict[str, dict] = {}\n        \n        # Resource storage (for MCP resources)\n        self.resources: dict[str, Any] = {}\n        \n        # Statistics tracking\n        self.stats = {\n            \"memory_hits\": 0,\n            \"memory_misses\": 0,\n            \"sqlite_hits\": 0,\n            \"sqlite_misses\": 0,\n            \"redis_hits\": 0,\n            \"redis_misses\": 0,\n            \"evictions\": 0,\n            \"total_requests\": 0,\n        }\n        \n        # Initialization flag\n        self._initialized = False\n    \n    async def initialize(self):\n        \"\"\"Initialize cache connections and create database tables.\n        \n        Creates SQLite database tables and establishes Redis connection if configured.\n        \"\"\"\n        if self._initialized:\n            logger.debug(\"Cache manager already initialized\")\n            return\n        \n        logger.info(f\"Initializing UnifiedCacheManager (max_memory: {self.max_memory_bytes / 1024 / 1024:.1f}MB)\")\n        \n        # Initialize SQLite\n        try:\n            self.sqlite_conn = await aiosqlite.connect(self.sqlite_path)\n            await self._create_tables()\n            logger.info(f\"SQLite cache initialized at {self.sqlite_path}\")\n        except Exception as e:\n            logger.error(f\"Failed to initialize SQLite cache: {e}\")\n            raise\n        \n        # Initialize Redis if URL provided\n        if self.redis_url:\n            try:\n                # Import redis only if needed\n                import redis.asyncio as aioredis\n                self.redis_client = await aioredis.from_url(\n                    self.redis_url,\n                    encoding=\"utf-8\",\n                    decode_responses=True\n                )\n                # Test connection\n                await self.redis_client.ping()\n                logger.info(f\"Redis cache initialized at {self.redis_url}\")\n            except ImportError:\n                logger.warning(\"redis package not installed, Redis cache disabled\")\n                self.redis_client = None\n            except Exception as e:\n                logger.warning(f\"Failed to initialize Redis cache: {e}. Continuing without Redis.\")\n                self.redis_client = None\n        \n        self._initialized = True\n        logger.info(\"UnifiedCacheManager initialization complete\")\n    \n    async def close(self):\n        \"\"\"Close all cache connections and cleanup resources.\"\"\"\n        if not self._initialized:\n            return\n        \n        logger.info(\"Closing UnifiedCacheManager\")\n        \n        # Close SQLite connection\n        if self.sqlite_conn:\n            try:\n                await self.sqlite_conn.close()\n                logger.debug(\"SQLite connection closed\")\n            except Exception as e:\n                logger.error(f\"Error closing SQLite connection: {e}\")\n        \n        # Close Redis connection\n        if self.redis_client:\n            try:\n                await self.redis_client.close()\n                logger.debug(\"Redis connection closed\")\n            except Exception as e:\n                logger.error(f\"Error closing Redis connection: {e}\")\n        \n        # Clear memory cache\n        self.memory_cache.clear()\n        self.current_memory_size = 0\n        self.session_state.clear()\n        self.resources.clear()\n        \n        self._initialized = False\n        logger.info(\"UnifiedCacheManager closed\")\n    \n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        await self.initialize()\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        await self.close()\n        return False\n    \n    async def _create_tables(self):\n        \"\"\"Create SQLite database tables if they don't exist.\"\"\"\n        if not self.sqlite_conn:\n            raise RuntimeError(\"SQLite connection not initialized\")\n        \n        # File cache table\n        await self.sqlite_conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS file_cache (\n                path TEXT PRIMARY KEY,\n                content TEXT,\n                hash TEXT,\n                language TEXT,\n                size INTEGER,\n                cached_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n        \n        # Analysis cache table\n        await self.sqlite_conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS analysis_cache (\n                key TEXT PRIMARY KEY,\n                data TEXT,\n                cached_at INTEGER,\n                ttl INTEGER\n            )\n        \"\"\")\n        \n        # Session state table\n        await self.sqlite_conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS session_state (\n                codebase_id TEXT PRIMARY KEY,\n                state TEXT,\n                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n        \n        await self.sqlite_conn.commit()\n        logger.debug(\"SQLite tables created/verified\")\n\n    \n    def _get_size(self, data: Any) -> int:\n        \"\"\"Estimate the size of data in bytes.\n        \n        Args:\n            data: Data to measure\n            \n        Returns:\n            Estimated size in bytes\n        \"\"\"\n        try:\n            # Serialize to JSON and measure the actual string length\n            json_str = json.dumps(data)\n            # Use len() to get actual string size, not Python object overhead\n            return len(json_str.encode('utf-8'))\n        except Exception:\n            # Fallback to sys.getsizeof\n            return sys.getsizeof(data)\n    \n    def _evict_lru(self):\n        \"\"\"Evict least recently used item from memory cache.\"\"\"\n        if not self.memory_cache:\n            return\n        \n        # Remove oldest item (first item in OrderedDict)\n        key, value = self.memory_cache.popitem(last=False)\n        size = self._get_size(value)\n        self.current_memory_size -= size\n        self.stats[\"evictions\"] += 1\n        logger.debug(f\"Evicted LRU item: {key} (freed {size} bytes)\")\n    \n    def _ensure_memory_space(self, required_size: int):\n        \"\"\"Ensure enough memory space by evicting LRU items if needed.\n        \n        Args:\n            required_size: Required space in bytes\n        \"\"\"\n        while (self.current_memory_size + required_size > self.max_memory_bytes \n               and self.memory_cache):\n            self._evict_lru()\n    \n    async def get_analysis(self, key: str) -> Optional[dict]:\n        \"\"\"Get analysis result from cache with tier promotion.\n        \n        Checks Memory  SQLite  Redis in order, promoting to faster tiers on hit.\n        \n        Args:\n            key: Cache key\n            \n        Returns:\n            Cached data or None if not found\n        \"\"\"\n        self.stats[\"total_requests\"] += 1\n        \n        # Check memory cache (Tier 1)\n        if key in self.memory_cache:\n            self.stats[\"memory_hits\"] += 1\n            # Move to end (most recently used)\n            self.memory_cache.move_to_end(key)\n            logger.debug(f\"Cache hit (memory): {key}\")\n            return self.memory_cache[key][\"data\"]\n        \n        self.stats[\"memory_misses\"] += 1\n        \n        # Check SQLite cache (Tier 2)\n        if self.sqlite_conn:\n            try:\n                async with self.sqlite_conn.execute(\n                    \"SELECT data, ttl, cached_at FROM analysis_cache WHERE key = ?\",\n                    (key,)\n                ) as cursor:\n                    row = await cursor.fetchone()\n                    if row:\n                        data_json, ttl, cached_at = row\n                        logger.debug(f\"SQLite row found for {key}: ttl={ttl}, cached_at={cached_at}\")\n                        \n                        # Check if expired\n                        if ttl > 0 and cached_at:\n                            current_time = time.time()\n                            age = current_time - cached_at\n                            logger.debug(f\"Cache age: {age:.2f}s, TTL: {ttl}s\")\n                            if age > ttl:\n                                logger.debug(f\"Cache expired (sqlite): {key}\")\n                                self.stats[\"sqlite_misses\"] += 1\n                                return None\n                        \n                        data = json.loads(data_json)\n                        self.stats[\"sqlite_hits\"] += 1\n                        logger.debug(f\"Cache hit (sqlite): {key}\")\n                        \n                        # Promote to memory cache\n                        await self._promote_to_memory(key, data)\n                        \n                        return data\n                    else:\n                        logger.debug(f\"No SQLite row found for {key}\")\n            except Exception as e:\n                logger.error(f\"Error reading from SQLite cache: {e}\", exc_info=True)\n        \n        self.stats[\"sqlite_misses\"] += 1\n        \n        # Check Redis cache (Tier 3)\n        if self.redis_client:\n            try:\n                data_json = await self.redis_client.get(f\"analysis:{key}\")\n                if data_json:\n                    data = json.loads(data_json)\n                    self.stats[\"redis_hits\"] += 1\n                    logger.debug(f\"Cache hit (redis): {key}\")\n                    \n                    # Promote to memory and SQLite\n                    await self._promote_to_memory(key, data)\n                    await self._promote_to_sqlite(key, data, ttl=3600)\n                    \n                    return data\n            except Exception as e:\n                logger.error(f\"Error reading from Redis cache: {e}\")\n        \n        self.stats[\"redis_misses\"] += 1\n        logger.debug(f\"Cache miss (all tiers): {key}\")\n        return None\n    \n    async def _promote_to_memory(self, key: str, data: dict):\n        \"\"\"Promote data to memory cache.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n        \"\"\"\n        size = self._get_size(data)\n        self._ensure_memory_space(size)\n        \n        self.memory_cache[key] = {\"data\": data, \"size\": size}\n        self.current_memory_size += size\n        logger.debug(f\"Promoted to memory: {key} ({size} bytes)\")\n    \n    async def _promote_to_sqlite(self, key: str, data: dict, ttl: int):\n        \"\"\"Promote data to SQLite cache.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n            ttl: Time to live in seconds\n        \"\"\"\n        if not self.sqlite_conn:\n            return\n        \n        try:\n            data_json = json.dumps(data)\n            cached_at = int(time.time())\n            await self.sqlite_conn.execute(\n                \"\"\"\n                INSERT OR REPLACE INTO analysis_cache (key, data, cached_at, ttl)\n                VALUES (?, ?, ?, ?)\n                \"\"\",\n                (key, data_json, cached_at, ttl)\n            )\n            await self.sqlite_conn.commit()\n            logger.debug(f\"Promoted to sqlite: {key}\")\n        except Exception as e:\n            logger.error(f\"Error promoting to SQLite: {e}\")\n    \n    async def set_analysis(self, key: str, data: dict, ttl: int = 3600):\n        \"\"\"Store analysis result in all cache tiers.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n            ttl: Time to live in seconds (default: 3600)\n        \"\"\"\n        # Store in memory cache (Tier 1)\n        size = self._get_size(data)\n        self._ensure_memory_space(size)\n        \n        self.memory_cache[key] = {\"data\": data, \"size\": size}\n        self.current_memory_size += size\n        logger.debug(f\"Stored in memory: {key} ({size} bytes)\")\n        \n        # Store in SQLite cache (Tier 2)\n        if self.sqlite_conn:\n            try:\n                data_json = json.dumps(data)\n                cached_at = int(time.time())\n                await self.sqlite_conn.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO analysis_cache (key, data, cached_at, ttl)\n                    VALUES (?, ?, ?, ?)\n                    \"\"\",\n                    (key, data_json, cached_at, ttl)\n                )\n                await self.sqlite_conn.commit()\n                logger.debug(f\"Stored in sqlite: {key}\")\n            except Exception as e:\n                logger.error(f\"Error storing in SQLite: {e}\")\n        \n        # Store in Redis cache (Tier 3)\n        if self.redis_client:\n            try:\n                data_json = json.dumps(data)\n                await self.redis_client.setex(\n                    f\"analysis:{key}\",\n                    ttl,\n                    data_json\n                )\n                logger.debug(f\"Stored in redis: {key}\")\n            except Exception as e:\n                logger.error(f\"Error storing in Redis: {e}\")\n    \n    async def get_session(self, codebase_id: str) -> Optional[dict]:\n        \"\"\"Get session state for a codebase.\n        \n        Args:\n            codebase_id: Unique codebase identifier\n            \n        Returns:\n            Session state or None if not found\n        \"\"\"\n        # Check memory first\n        if codebase_id in self.session_state:\n            logger.debug(f\"Session hit (memory): {codebase_id}\")\n            return self.session_state[codebase_id]\n        \n        # Check SQLite\n        if self.sqlite_conn:\n            try:\n                async with self.sqlite_conn.execute(\n                    \"SELECT state FROM session_state WHERE codebase_id = ?\",\n                    (codebase_id,)\n                ) as cursor:\n                    row = await cursor.fetchone()\n                    if row:\n                        state = json.loads(row[0])\n                        # Cache in memory\n                        self.session_state[codebase_id] = state\n                        logger.debug(f\"Session hit (sqlite): {codebase_id}\")\n                        return state\n            except Exception as e:\n                logger.error(f\"Error reading session from SQLite: {e}\")\n        \n        logger.debug(f\"Session miss: {codebase_id}\")\n        return None\n    \n    async def set_session(self, codebase_id: str, state: dict):\n        \"\"\"Store session state for a codebase.",
              "hints": [
                "Start by understanding the structure of a session_authentication. Look at the imports and main components needed.",
                "Key elements to implement: 28 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: import json"
              ],
              "learning_objectives": [
                "Understand how to implement a Session Authentication",
                "Practice writing clean, maintainable code for Session Authentication",
                "Apply Session feature: session in your implementation",
                "Apply Session feature: Session in your implementation"
              ]
            },
            {
              "exercise_id": "1df4c297-a850-4306-8186-bb53823fd014",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\cache\\unified_cache.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 14, Await statements: 31"
              ],
              "starter_code": "    \n    async def initialize(self):\n        \"\"\"Initialize cache connections and create database tables.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n        \n        # Initialize SQLite\n        \n        # Initialize Redis if URL provided\n                # Import redis only if needed\n                import redis.asyncio as aioredis\n                # Test connection\n        \n    \n    async def close(self):\n        \"\"\"Close all cache connections and cleanup resources.\"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \n        # Close SQLite connection\n        \n        # Close Redis connection\n        \n        # Clear memory cache\n        \n    \n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n    \n    async def _create_tables(self):\n        \"\"\"Create SQLite database tables if they don't exist.\"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        # File cache table\n        await self.sqlite_conn.execute(\"\"\"\n        \"\"\")\n        \n        # Analysis cache table\n        await self.sqlite_conn.execute(\"\"\"\n        \"\"\")\n        \n        # Session state table\n        await self.sqlite_conn.execute(\"\"\"\n        \"\"\")\n        \n\n    \n    def _get_size(self, data: Any) -> int:\n        \"\"\"Estimate the size of data in bytes.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n            \n        \"\"\"\n            # Serialize to JSON and measure the actual string length\n            # Use len() to get actual string size, not Python object overhead\n            # Fallback to sys.getsizeof\n    \n    def _evict_lru(self):\n        \"\"\"Evict least recently used item from memory cache.\"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        # Remove oldest item (first item in OrderedDict)\n    \n    def _ensure_memory_space(self, required_size: int):\n        \"\"\"Ensure enough memory space by evicting LRU items if needed.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n    \n    async def get_analysis(self, key: str) -> Optional[dict]:\n        \"\"\"Get analysis result from cache with tier promotion.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Check memory cache (Tier 1)\n            # Move to end (most recently used)\n        \n        \n        # Check SQLite cache (Tier 2)\n                        \n                        # Check if expired\n                        \n                        \n                        # Promote to memory cache\n                        \n        \n        \n        # Check Redis cache (Tier 3)\n                    \n                    # Promote to memory and SQLite\n                    \n        \n    \n    async def _promote_to_memory(self, key: str, data: dict):\n        \"\"\"Promote data to memory cache.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n    \n    async def _promote_to_sqlite(self, key: str, data: dict, ttl: int):\n        \"\"\"Promote data to SQLite cache.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n                \"\"\"\n                \"\"\",\n    \n    async def set_analysis(self, key: str, data: dict, ttl: int = 3600):\n        \"\"\"Store analysis result in all cache tiers.\n        \n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        # Store in memory cache (Tier 1)\n        \n        \n        # Store in SQLite cache (Tier 2)\n                    \"\"\"\n                    \"\"\",\n        \n        # Store in Redis cache (Tier 3)\n    \n    async def get_session(self, codebase_id: str) -> Optional[dict]:\n        \"\"\"Get session state for a codebase.",
              "solution_code": "self._initialized = False\n    \n    async def initialize(self):\n        \"\"\"Initialize cache connections and create database tables.\n        \n        Creates SQLite database tables and establishes Redis connection if configured.\n        \"\"\"\n        if self._initialized:\n            logger.debug(\"Cache manager already initialized\")\n            return\n        \n        logger.info(f\"Initializing UnifiedCacheManager (max_memory: {self.max_memory_bytes / 1024 / 1024:.1f}MB)\")\n        \n        # Initialize SQLite\n        try:\n            self.sqlite_conn = await aiosqlite.connect(self.sqlite_path)\n            await self._create_tables()\n            logger.info(f\"SQLite cache initialized at {self.sqlite_path}\")\n        except Exception as e:\n            logger.error(f\"Failed to initialize SQLite cache: {e}\")\n            raise\n        \n        # Initialize Redis if URL provided\n        if self.redis_url:\n            try:\n                # Import redis only if needed\n                import redis.asyncio as aioredis\n                self.redis_client = await aioredis.from_url(\n                    self.redis_url,\n                    encoding=\"utf-8\",\n                    decode_responses=True\n                )\n                # Test connection\n                await self.redis_client.ping()\n                logger.info(f\"Redis cache initialized at {self.redis_url}\")\n            except ImportError:\n                logger.warning(\"redis package not installed, Redis cache disabled\")\n                self.redis_client = None\n            except Exception as e:\n                logger.warning(f\"Failed to initialize Redis cache: {e}. Continuing without Redis.\")\n                self.redis_client = None\n        \n        self._initialized = True\n        logger.info(\"UnifiedCacheManager initialization complete\")\n    \n    async def close(self):\n        \"\"\"Close all cache connections and cleanup resources.\"\"\"\n        if not self._initialized:\n            return\n        \n        logger.info(\"Closing UnifiedCacheManager\")\n        \n        # Close SQLite connection\n        if self.sqlite_conn:\n            try:\n                await self.sqlite_conn.close()\n                logger.debug(\"SQLite connection closed\")\n            except Exception as e:\n                logger.error(f\"Error closing SQLite connection: {e}\")\n        \n        # Close Redis connection\n        if self.redis_client:\n            try:\n                await self.redis_client.close()\n                logger.debug(\"Redis connection closed\")\n            except Exception as e:\n                logger.error(f\"Error closing Redis connection: {e}\")\n        \n        # Clear memory cache\n        self.memory_cache.clear()\n        self.current_memory_size = 0\n        self.session_state.clear()\n        self.resources.clear()\n        \n        self._initialized = False\n        logger.info(\"UnifiedCacheManager closed\")\n    \n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        await self.initialize()\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        await self.close()\n        return False\n    \n    async def _create_tables(self):\n        \"\"\"Create SQLite database tables if they don't exist.\"\"\"\n        if not self.sqlite_conn:\n            raise RuntimeError(\"SQLite connection not initialized\")\n        \n        # File cache table\n        await self.sqlite_conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS file_cache (\n                path TEXT PRIMARY KEY,\n                content TEXT,\n                hash TEXT,\n                language TEXT,\n                size INTEGER,\n                cached_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n        \n        # Analysis cache table\n        await self.sqlite_conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS analysis_cache (\n                key TEXT PRIMARY KEY,\n                data TEXT,\n                cached_at INTEGER,\n                ttl INTEGER\n            )\n        \"\"\")\n        \n        # Session state table\n        await self.sqlite_conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS session_state (\n                codebase_id TEXT PRIMARY KEY,\n                state TEXT,\n                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n        \n        await self.sqlite_conn.commit()\n        logger.debug(\"SQLite tables created/verified\")\n\n    \n    def _get_size(self, data: Any) -> int:\n        \"\"\"Estimate the size of data in bytes.\n        \n        Args:\n            data: Data to measure\n            \n        Returns:\n            Estimated size in bytes\n        \"\"\"\n        try:\n            # Serialize to JSON and measure the actual string length\n            json_str = json.dumps(data)\n            # Use len() to get actual string size, not Python object overhead\n            return len(json_str.encode('utf-8'))\n        except Exception:\n            # Fallback to sys.getsizeof\n            return sys.getsizeof(data)\n    \n    def _evict_lru(self):\n        \"\"\"Evict least recently used item from memory cache.\"\"\"\n        if not self.memory_cache:\n            return\n        \n        # Remove oldest item (first item in OrderedDict)\n        key, value = self.memory_cache.popitem(last=False)\n        size = self._get_size(value)\n        self.current_memory_size -= size\n        self.stats[\"evictions\"] += 1\n        logger.debug(f\"Evicted LRU item: {key} (freed {size} bytes)\")\n    \n    def _ensure_memory_space(self, required_size: int):\n        \"\"\"Ensure enough memory space by evicting LRU items if needed.\n        \n        Args:\n            required_size: Required space in bytes\n        \"\"\"\n        while (self.current_memory_size + required_size > self.max_memory_bytes \n               and self.memory_cache):\n            self._evict_lru()\n    \n    async def get_analysis(self, key: str) -> Optional[dict]:\n        \"\"\"Get analysis result from cache with tier promotion.\n        \n        Checks Memory  SQLite  Redis in order, promoting to faster tiers on hit.\n        \n        Args:\n            key: Cache key\n            \n        Returns:\n            Cached data or None if not found\n        \"\"\"\n        self.stats[\"total_requests\"] += 1\n        \n        # Check memory cache (Tier 1)\n        if key in self.memory_cache:\n            self.stats[\"memory_hits\"] += 1\n            # Move to end (most recently used)\n            self.memory_cache.move_to_end(key)\n            logger.debug(f\"Cache hit (memory): {key}\")\n            return self.memory_cache[key][\"data\"]\n        \n        self.stats[\"memory_misses\"] += 1\n        \n        # Check SQLite cache (Tier 2)\n        if self.sqlite_conn:\n            try:\n                async with self.sqlite_conn.execute(\n                    \"SELECT data, ttl, cached_at FROM analysis_cache WHERE key = ?\",\n                    (key,)\n                ) as cursor:\n                    row = await cursor.fetchone()\n                    if row:\n                        data_json, ttl, cached_at = row\n                        logger.debug(f\"SQLite row found for {key}: ttl={ttl}, cached_at={cached_at}\")\n                        \n                        # Check if expired\n                        if ttl > 0 and cached_at:\n                            current_time = time.time()\n                            age = current_time - cached_at\n                            logger.debug(f\"Cache age: {age:.2f}s, TTL: {ttl}s\")\n                            if age > ttl:\n                                logger.debug(f\"Cache expired (sqlite): {key}\")\n                                self.stats[\"sqlite_misses\"] += 1\n                                return None\n                        \n                        data = json.loads(data_json)\n                        self.stats[\"sqlite_hits\"] += 1\n                        logger.debug(f\"Cache hit (sqlite): {key}\")\n                        \n                        # Promote to memory cache\n                        await self._promote_to_memory(key, data)\n                        \n                        return data\n                    else:\n                        logger.debug(f\"No SQLite row found for {key}\")\n            except Exception as e:\n                logger.error(f\"Error reading from SQLite cache: {e}\", exc_info=True)\n        \n        self.stats[\"sqlite_misses\"] += 1\n        \n        # Check Redis cache (Tier 3)\n        if self.redis_client:\n            try:\n                data_json = await self.redis_client.get(f\"analysis:{key}\")\n                if data_json:\n                    data = json.loads(data_json)\n                    self.stats[\"redis_hits\"] += 1\n                    logger.debug(f\"Cache hit (redis): {key}\")\n                    \n                    # Promote to memory and SQLite\n                    await self._promote_to_memory(key, data)\n                    await self._promote_to_sqlite(key, data, ttl=3600)\n                    \n                    return data\n            except Exception as e:\n                logger.error(f\"Error reading from Redis cache: {e}\")\n        \n        self.stats[\"redis_misses\"] += 1\n        logger.debug(f\"Cache miss (all tiers): {key}\")\n        return None\n    \n    async def _promote_to_memory(self, key: str, data: dict):\n        \"\"\"Promote data to memory cache.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n        \"\"\"\n        size = self._get_size(data)\n        self._ensure_memory_space(size)\n        \n        self.memory_cache[key] = {\"data\": data, \"size\": size}\n        self.current_memory_size += size\n        logger.debug(f\"Promoted to memory: {key} ({size} bytes)\")\n    \n    async def _promote_to_sqlite(self, key: str, data: dict, ttl: int):\n        \"\"\"Promote data to SQLite cache.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n            ttl: Time to live in seconds\n        \"\"\"\n        if not self.sqlite_conn:\n            return\n        \n        try:\n            data_json = json.dumps(data)\n            cached_at = int(time.time())\n            await self.sqlite_conn.execute(\n                \"\"\"\n                INSERT OR REPLACE INTO analysis_cache (key, data, cached_at, ttl)\n                VALUES (?, ?, ?, ?)\n                \"\"\",\n                (key, data_json, cached_at, ttl)\n            )\n            await self.sqlite_conn.commit()\n            logger.debug(f\"Promoted to sqlite: {key}\")\n        except Exception as e:\n            logger.error(f\"Error promoting to SQLite: {e}\")\n    \n    async def set_analysis(self, key: str, data: dict, ttl: int = 3600):\n        \"\"\"Store analysis result in all cache tiers.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n            ttl: Time to live in seconds (default: 3600)\n        \"\"\"\n        # Store in memory cache (Tier 1)\n        size = self._get_size(data)\n        self._ensure_memory_space(size)\n        \n        self.memory_cache[key] = {\"data\": data, \"size\": size}\n        self.current_memory_size += size\n        logger.debug(f\"Stored in memory: {key} ({size} bytes)\")\n        \n        # Store in SQLite cache (Tier 2)\n        if self.sqlite_conn:\n            try:\n                data_json = json.dumps(data)\n                cached_at = int(time.time())\n                await self.sqlite_conn.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO analysis_cache (key, data, cached_at, ttl)\n                    VALUES (?, ?, ?, ?)\n                    \"\"\",\n                    (key, data_json, cached_at, ttl)\n                )\n                await self.sqlite_conn.commit()\n                logger.debug(f\"Stored in sqlite: {key}\")\n            except Exception as e:\n                logger.error(f\"Error storing in SQLite: {e}\")\n        \n        # Store in Redis cache (Tier 3)\n        if self.redis_client:\n            try:\n                data_json = json.dumps(data)\n                await self.redis_client.setex(\n                    f\"analysis:{key}\",\n                    ttl,\n                    data_json\n                )\n                logger.debug(f\"Stored in redis: {key}\")\n            except Exception as e:\n                logger.error(f\"Error storing in Redis: {e}\")\n    \n    async def get_session(self, codebase_id: str) -> Optional[dict]:\n        \"\"\"Get session state for a codebase.",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 22 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: import redis.asyncio as aioredis"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 14 in your implementation",
                "Apply Await statements: 31 in your implementation"
              ]
            }
          ],
          "tags": [
            "session_authentication",
            "python_async_await"
          ]
        },
        {
          "lesson_id": "48d1967a-db29-4b13-a337-3cb18729f1a6",
          "title": "Engine: Python Async Await",
          "description": "Excellent teaching value (score: 0.89). Well-documented (100% coverage). Ideal complexity (avg: 6.8) for teaching. Contains useful patterns. Well-structured code. Demonstrates: session_authentication, python_context_managers, python_async_await, python_comprehensions",
          "order": 5,
          "difficulty": "intermediate",
          "duration_minutes": 54,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\engine.py",
          "teaching_value": 0.89,
          "learning_objectives": [
            "Understand session authentication pattern",
            "Understand python context managers pattern",
            "Understand python async await pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "session_authentication",
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "8cb3e902-c4e3-4a6d-aaf9-064fea5b333d",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\engine.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 4, Await statements: 10, Uses asyncio library"
              ],
              "starter_code": "    \n    async def _get_cached_analysis(self, file_path: str, file_hash: str) -> Optional[FileAnalysis]:\n        \"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \n        \"\"\"\n            \n                # Convert dict back to FileAnalysis\n        \n    \n    async def _cache_analysis(self, file_path: str, file_hash: str, analysis: FileAnalysis):\n        \"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \"\"\"\n            # Convert FileAnalysis to dict for caching\n    \n    async def analyze_file(self, file_path: str, force: bool = False) -> FileAnalysis:\n        \"\"\"\n        # TODO: Implement python_async_await logic here\n        pass\n        \n        \n        \n        \"\"\"\n        \n        # Calculate file hash for incremental analysis\n        \n        # Check cache if not forcing re-analysis\n        \n        \n        # Handle Jupyter notebooks\n                # Return error analysis\n        \n        # Parse file\n            \n        \n        # Extract symbols\n        \n        # Detect patterns\n        \n        # Calculate complexity metrics\n            \n            # Convert to model format\n        \n        # Calculate documentation coverage\n            from .documentation_coverage import DocumentationCoverage\n        \n        # Score teaching value\n            # Convert to model format\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n        \n        # Run linters asynchronously (non-blocking)\n        \n        # Convert symbol_info to model version for storage\n        \n        # Create analysis result\n        \n        # Cache results\n        \n        # Track performance metrics\n        \n        # Log slow operations (>1000ms)\n        \n        \n    \n    def _create_error_analysis(\n        # TODO: Implement python_async_await logic here\n        pass\n        \"\"\"\n        \n        \n        \"\"\"\n        from src.models.analysis_models import TeachingValueScore\n        \n    \n    async def analyze_codebase(\n        # TODO: Implement python_async_await logic here\n        pass",
              "solution_code": "return ext in ['.py', '.js', '.jsx', '.ts', '.tsx', '.ipynb']\n    \n    async def _get_cached_analysis(self, file_path: str, file_hash: str) -> Optional[FileAnalysis]:\n        \"\"\"\n        Retrieve cached analysis if available and hash matches.\n        \n        Args:\n            file_path: Path to file\n            file_hash: Current file hash\n        \n        Returns:\n            FileAnalysis if cached, None otherwise\n        \"\"\"\n        cache_key = f\"file:{file_hash}\"\n        try:\n            cached_dict = await self.cache.get_analysis(cache_key)\n            \n            if cached_dict:\n                logger.debug(f\"Cache hit for {file_path} (hash: {file_hash[:8]}...)\")\n                self.metrics['total_cache_hits'] += 1\n                # Convert dict back to FileAnalysis\n                return FileAnalysis.from_dict(cached_dict)\n            else:\n                logger.debug(f\"Cache miss for {file_path} (hash: {file_hash[:8]}...)\")\n                self.metrics['total_cache_misses'] += 1\n        except Exception as e:\n            logger.warning(f\"Error retrieving from cache for {file_path}: {e}\")\n            self.metrics['total_cache_misses'] += 1\n        \n        return None\n    \n    async def _cache_analysis(self, file_path: str, file_hash: str, analysis: FileAnalysis):\n        \"\"\"\n        Cache analysis results with file hash as key.\n        \n        Args:\n            file_path: Path to file\n            file_hash: File hash\n            analysis: Analysis result to cache\n        \"\"\"\n        cache_key = f\"file:{file_hash}\"\n        try:\n            # Convert FileAnalysis to dict for caching\n            analysis_dict = analysis.to_dict()\n            await self.cache.set_analysis(cache_key, analysis_dict, ttl=self.config.cache_ttl_seconds)\n            logger.debug(f\"Cached analysis for {file_path} (hash: {file_hash[:8]}...)\")\n        except Exception as e:\n            logger.warning(f\"Error caching analysis: {e}\")\n    \n    async def analyze_file(self, file_path: str, force: bool = False) -> FileAnalysis:\n        \"\"\"\n        Analyze single file with caching and incremental support.\n        \n        Args:\n            file_path: Path to file to analyze\n            force: If True, bypass cache and re-analyze\n        \n        Returns:\n            FileAnalysis with all extracted information\n        \n        Example:\n            >>> engine = AnalysisEngine(cache, config)\n            >>> analysis = await engine.analyze_file(\"src/main.py\")\n            >>> print(f\"Teaching value: {analysis.teaching_value.total_score}\")\n        \"\"\"\n        start_time = datetime.now()\n        logger.info(f\"Starting analysis for file: {file_path}\")\n        \n        # Calculate file hash for incremental analysis\n        file_hash = self._calculate_file_hash(file_path)\n        if not file_hash:\n            logger.error(f\"Failed to calculate file hash for {file_path}\")\n        \n        # Check cache if not forcing re-analysis\n        if not force and file_hash:\n            cached = await self._get_cached_analysis(file_path, file_hash)\n            if cached:\n                cached.cache_hit = True\n                elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000\n                logger.info(f\"Analysis complete for {file_path} (cached) in {elapsed_ms:.0f}ms\")\n                return cached\n        \n        logger.debug(f\"Performing full analysis for {file_path} (force={force})\")\n        \n        # Handle Jupyter notebooks\n        is_notebook = file_path.endswith('.ipynb')\n        if is_notebook:\n            logger.debug(f\"Detected Jupyter notebook: {file_path}\")\n            try:\n                notebook_code = self.notebook_analyzer.extract_code(file_path)\n                source_code = notebook_code.full_code.encode('utf-8')\n                logger.debug(f\"Extracted {notebook_code.total_cells} cells from notebook {file_path}\")\n            except Exception as e:\n                error_msg = f\"Failed to extract notebook code: {e}\"\n                logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n                self.metrics['errors'].append((file_path, error_msg))\n                # Return error analysis\n                return self._create_error_analysis(\n                    file_path, \n                    \"python\",\n                    error_msg,\n                    start_time\n                )\n        else:\n            try:\n                with open(file_path, 'rb') as f:\n                    source_code = f.read()\n                logger.debug(f\"Read {len(source_code)} bytes from {file_path}\")\n            except Exception as e:\n                error_msg = f\"Failed to read file: {e}\"\n                logger.error(f\"{error_msg} - {file_path}\\n{traceback.format_exc()}\")\n                self.metrics['errors'].append((file_path, error_msg))\n                return self._create_error_analysis(\n                    file_path,\n                    \"unknown\",\n                    error_msg,\n                    start_time\n                )\n        \n        # Parse file\n        try:\n            logger.debug(f\"Parsing file: {file_path}\")\n            parse_result = self.parser.parse_file(file_path)\n            logger.debug(f\"Parse complete for {file_path} (language: {parse_result.language}, has_errors: {parse_result.has_errors})\")\n            \n            if parse_result.has_errors:\n                logger.warning(f\"Parse errors detected in {file_path}: {len(parse_result.error_nodes)} error nodes\")\n        except Exception as e:\n            error_msg = f\"Parse error: {e}\"\n            logger.error(f\"Failed to parse {file_path}: {e}\\n{traceback.format_exc()}\")\n            self.metrics['errors'].append((file_path, error_msg))\n            return self._create_error_analysis(\n                file_path,\n                \"unknown\",\n                error_msg,\n                start_time\n            )\n        \n        # Extract symbols\n        try:\n            logger.debug(f\"Extracting symbols from {file_path}\")\n            symbol_info_extractor = self.symbol_extractor.extract_symbols(parse_result)\n            logger.debug(\n                f\"Symbol extraction complete for {file_path}: \"\n                f\"{len(symbol_info_extractor.functions)} functions, \"\n                f\"{len(symbol_info_extractor.classes)} classes, \"\n                f\"{len(symbol_info_extractor.imports)} imports\"\n            )\n        except Exception as e:\n            error_msg = f\"Symbol extraction error: {e}\"\n            logger.error(f\"Failed to extract symbols from {file_path}: {e}\\n{traceback.format_exc()}\")\n            self.metrics['errors'].append((file_path, error_msg))\n            return self._create_error_analysis(\n                file_path,\n                parse_result.language,\n                error_msg,\n                start_time\n            )\n        \n        # Detect patterns\n        try:\n            logger.debug(f\"Detecting patterns in {file_path}\")\n            file_content = source_code.decode('utf-8', errors='ignore')\n            patterns = self.pattern_detector.detect_patterns_in_file(\n                symbol_info_extractor,\n                file_content,\n                file_path\n            )\n            logger.debug(f\"Pattern detection complete for {file_path}: {len(patterns)} patterns detected\")\n        except Exception as e:\n            logger.warning(f\"Pattern detection failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            patterns = []\n        \n        # Calculate complexity metrics\n        try:\n            logger.debug(f\"Calculating complexity metrics for {file_path}\")\n            complexity_metrics = self.complexity_analyzer.analyze_file(symbol_info_extractor)\n            \n            # Convert to model format\n            complexity_metrics_model = ComplexityMetricsModel(\n                avg_complexity=complexity_metrics.avg_complexity,\n                max_complexity=complexity_metrics.max_complexity,\n                min_complexity=complexity_metrics.min_complexity,\n                high_complexity_functions=[\n                    func.name for func in symbol_info_extractor.functions \n                    if func.complexity > 10\n                ] + [\n                    f\"{cls.name}.{method.name}\" \n                    for cls in symbol_info_extractor.classes \n                    for method in cls.methods \n                    if method.complexity > 10\n                ],\n                trivial_functions=[\n                    func.name for func in symbol_info_extractor.functions \n                    if func.complexity < 2\n                ] + [\n                    f\"{cls.name}.{method.name}\" \n                    for cls in symbol_info_extractor.classes \n                    for method in cls.methods \n                    if method.complexity < 2\n                ],\n                avg_nesting_depth=complexity_metrics.avg_nesting_depth\n            )\n            logger.debug(\n                f\"Complexity analysis complete for {file_path}: \"\n                f\"avg={complexity_metrics.avg_complexity:.1f}, \"\n                f\"max={complexity_metrics.max_complexity}, \"\n                f\"high_complexity_count={len(complexity_metrics_model.high_complexity_functions)}\"\n            )\n        except Exception as e:\n            logger.warning(f\"Complexity analysis failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            complexity_metrics_model = ComplexityMetricsModel(\n                avg_complexity=0.0,\n                max_complexity=0,\n                min_complexity=0,\n                high_complexity_functions=[],\n                trivial_functions=[],\n                avg_nesting_depth=0.0\n            )\n        \n        # Calculate documentation coverage\n        try:\n            logger.debug(f\"Calculating documentation coverage for {file_path}\")\n            doc_coverage = self.doc_coverage_analyzer.calculate_coverage(\n                symbol_info_extractor,\n                file_content,\n                parse_result.language\n            )\n            logger.debug(f\"Documentation coverage for {file_path}: {doc_coverage.total_score:.2%}\")\n        except Exception as e:\n            logger.warning(f\"Documentation coverage analysis failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            from .documentation_coverage import DocumentationCoverage\n            doc_coverage = DocumentationCoverage()\n        \n        # Score teaching value\n        try:\n            logger.debug(f\"Scoring teaching value for {file_path}\")\n            teaching_value_result = self.teaching_value_scorer.score_file(\n                symbol_info_extractor,\n                patterns,\n                complexity_metrics,\n                doc_coverage\n            )\n            # Convert to model format\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n            teaching_value = TeachingValueScoreModel(\n                total_score=teaching_value_result.total_score,\n                documentation_score=teaching_value_result.documentation_score,\n                complexity_score=teaching_value_result.complexity_score,\n                pattern_score=teaching_value_result.pattern_score,\n                structure_score=teaching_value_result.structure_score,\n                explanation=teaching_value_result.explanation,\n                factors=teaching_value_result.factors\n            )\n            logger.debug(f\"Teaching value score for {file_path}: {teaching_value.total_score:.2f}\")\n        except Exception as e:\n            logger.warning(f\"Teaching value scoring failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n            teaching_value = TeachingValueScoreModel(\n                total_score=0.0,\n                documentation_score=0.0,\n                complexity_score=0.0,\n                pattern_score=0.0,\n                structure_score=0.0,\n                explanation=\"Scoring failed\",\n                factors={}\n            )\n        \n        # Run linters asynchronously (non-blocking)\n        try:\n            logger.debug(f\"Running linters for {file_path}\")\n            linter_issues = await self.linter.run_linters(\n                file_path,\n                parse_result.language\n            )\n            if linter_issues:\n                logger.debug(f\"Linter found {len(linter_issues)} issues in {file_path}\")\n        except Exception as e:\n            logger.warning(f\"Linter execution failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            linter_issues = []\n        \n        # Convert symbol_info to model version for storage\n        symbol_info_model = self._convert_symbol_info(symbol_info_extractor)\n        \n        # Create analysis result\n        analysis = FileAnalysis(\n            file_path=file_path,\n            language=parse_result.language,\n            symbol_info=symbol_info_model,\n            patterns=patterns,\n            teaching_value=teaching_value,\n            complexity_metrics=complexity_metrics_model,\n            documentation_coverage=doc_coverage.total_score,\n            linter_issues=linter_issues,\n            has_errors=parse_result.has_errors,\n            errors=[str(node) for node in parse_result.error_nodes] if parse_result.has_errors else [],\n            analyzed_at=datetime.now().isoformat(),\n            cache_hit=False,\n            is_notebook=is_notebook\n        )\n        \n        # Cache results\n        if file_hash:\n            await self._cache_analysis(file_path, file_hash, analysis)\n        \n        # Track performance metrics\n        elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000\n        self.metrics['total_files_analyzed'] += 1\n        self.metrics['total_analysis_time_ms'] += elapsed_ms\n        self.metrics['file_analysis_times'].append((file_path, elapsed_ms))\n        \n        # Log slow operations (>1000ms)\n        if elapsed_ms > 1000:\n            logger.warning(\n                f\"Slow operation detected: Analysis of {file_path} took {elapsed_ms:.0f}ms \"\n                f\"(threshold: 1000ms)\"\n            )\n            self.metrics['slow_operations'].append((file_path, elapsed_ms))\n        \n        logger.info(\n            f\"Analysis complete for {file_path} in {elapsed_ms:.0f}ms \"\n            f\"(teaching_value: {analysis.teaching_value.total_score:.2f}, \"\n            f\"functions: {len(analysis.symbol_info.functions)}, \"\n            f\"classes: {len(analysis.symbol_info.classes)})\"\n        )\n        \n        return analysis\n    \n    def _create_error_analysis(\n        self,\n        file_path: str,\n        language: str,\n        error_message: str,\n        start_time: datetime\n    ) -> FileAnalysis:\n        \"\"\"\n        Create an error analysis result when analysis fails.\n        \n        Args:\n            file_path: Path to file\n            language: Programming language\n            error_message: Error message\n            start_time: Analysis start time\n        \n        Returns:\n            FileAnalysis with error flag set\n        \"\"\"\n        from src.models.analysis_models import TeachingValueScore\n        \n        return FileAnalysis(\n            file_path=file_path,\n            language=language,\n            symbol_info=SymbolInfoModel(\n                functions=[],\n                classes=[],\n                imports=[],\n                exports=[]\n            ),\n            patterns=[],\n            teaching_value=TeachingValueScore(\n                total_score=0.0,\n                documentation_score=0.0,\n                complexity_score=0.0,\n                pattern_score=0.0,\n                structure_score=0.0,\n                explanation=\"Analysis failed\",\n                factors={}\n            ),\n            complexity_metrics=ComplexityMetricsModel(\n                avg_complexity=0.0,\n                max_complexity=0,\n                min_complexity=0,\n                high_complexity_functions=[],\n                trivial_functions=[],\n                avg_nesting_depth=0.0\n            ),\n            documentation_coverage=0.0,\n            linter_issues=[],\n            has_errors=True,\n            errors=[error_message],\n            analyzed_at=datetime.now().isoformat(),\n            cache_hit=False,\n            is_notebook=False\n        )\n    \n    async def analyze_codebase(\n        self,\n        codebase_id: str,",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 15 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: from .documentation_coverage import DocumentationCoverage"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 4 in your implementation",
                "Apply Await statements: 10 in your implementation"
              ]
            },
            {
              "exercise_id": "54a0a590-e2bb-47e8-9414-4bdeb764abff",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\engine.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (8 occurrences)"
              ],
              "starter_code": "        \n        \n        # Handle Jupyter notebooks\n                # Return error analysis\n        \n        # Parse file\n            \n        \n        # Extract symbols\n        \n        # Detect patterns\n        \n        # Calculate complexity metrics\n            \n            # Convert to model format\n        \n        # Calculate documentation coverage\n            from .documentation_coverage import DocumentationCoverage\n        \n        # Score teaching value\n            # Convert to model format\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n        \n        # Run linters asynchronously (non-blocking)\n        \n        # Convert symbol_info to model version for storage\n        \n        # Create analysis result\n        \n        # Cache results\n        \n        # Track performance metrics\n        \n        # Log slow operations (>1000ms)\n        \n        \n    \n    def _create_error_analysis(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \"\"\"\n        from src.models.analysis_models import TeachingValueScore\n        \n    \n    async def analyze_codebase(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \n        \"\"\"\n        \n        # Get scan results\n        \n        # Load previous analysis for incremental mode\n        \n        # Determine which files to analyze\n        \n        # Get file list from scan result\n        # scan_result contains 'path' which is the root directory\n        # We need to walk the directory to get all analyzable files\n        \n            \n            # Walk the directory to find all analyzable files\n            import os\n                # Filter out ignored directories\n                \n            \n        \n            \n            \n            \n            # In incremental mode, skip unchanged files\n            \n        \n        \n        # Initialize file analyses dict\n        \n        # Reuse previous analyses for unchanged files\n                    # File unchanged, reuse previous analysis\n            \n        \n        # Analyze new/changed files in parallel\n            \n            # Create analysis tasks\n            \n            # Run in parallel with asyncio.gather\n            \n            # Process results\n                    # Create error analysis\n            \n        \n        \n        # Build dependency graph\n            # Create empty dependency graph\n            from .dependency_analyzer import DependencyGraph\n        \n        # Detect global patterns\n        \n        # Rank files by teaching value\n        \n        # Calculate codebase metrics\n        \n        # Create codebase analysis\n        \n        # Persist to disk\n        \n        # Cache in memory\n        \n        # Calculate and log final metrics\n        \n        # Log batch analysis summary\n        \n        # Log cache statistics\n        \n        # Log slow operations\n        \n        # Log errors",
              "solution_code": "cached.cache_hit = True\n                elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000\n                logger.info(f\"Analysis complete for {file_path} (cached) in {elapsed_ms:.0f}ms\")\n                return cached\n        \n        logger.debug(f\"Performing full analysis for {file_path} (force={force})\")\n        \n        # Handle Jupyter notebooks\n        is_notebook = file_path.endswith('.ipynb')\n        if is_notebook:\n            logger.debug(f\"Detected Jupyter notebook: {file_path}\")\n            try:\n                notebook_code = self.notebook_analyzer.extract_code(file_path)\n                source_code = notebook_code.full_code.encode('utf-8')\n                logger.debug(f\"Extracted {notebook_code.total_cells} cells from notebook {file_path}\")\n            except Exception as e:\n                error_msg = f\"Failed to extract notebook code: {e}\"\n                logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n                self.metrics['errors'].append((file_path, error_msg))\n                # Return error analysis\n                return self._create_error_analysis(\n                    file_path, \n                    \"python\",\n                    error_msg,\n                    start_time\n                )\n        else:\n            try:\n                with open(file_path, 'rb') as f:\n                    source_code = f.read()\n                logger.debug(f\"Read {len(source_code)} bytes from {file_path}\")\n            except Exception as e:\n                error_msg = f\"Failed to read file: {e}\"\n                logger.error(f\"{error_msg} - {file_path}\\n{traceback.format_exc()}\")\n                self.metrics['errors'].append((file_path, error_msg))\n                return self._create_error_analysis(\n                    file_path,\n                    \"unknown\",\n                    error_msg,\n                    start_time\n                )\n        \n        # Parse file\n        try:\n            logger.debug(f\"Parsing file: {file_path}\")\n            parse_result = self.parser.parse_file(file_path)\n            logger.debug(f\"Parse complete for {file_path} (language: {parse_result.language}, has_errors: {parse_result.has_errors})\")\n            \n            if parse_result.has_errors:\n                logger.warning(f\"Parse errors detected in {file_path}: {len(parse_result.error_nodes)} error nodes\")\n        except Exception as e:\n            error_msg = f\"Parse error: {e}\"\n            logger.error(f\"Failed to parse {file_path}: {e}\\n{traceback.format_exc()}\")\n            self.metrics['errors'].append((file_path, error_msg))\n            return self._create_error_analysis(\n                file_path,\n                \"unknown\",\n                error_msg,\n                start_time\n            )\n        \n        # Extract symbols\n        try:\n            logger.debug(f\"Extracting symbols from {file_path}\")\n            symbol_info_extractor = self.symbol_extractor.extract_symbols(parse_result)\n            logger.debug(\n                f\"Symbol extraction complete for {file_path}: \"\n                f\"{len(symbol_info_extractor.functions)} functions, \"\n                f\"{len(symbol_info_extractor.classes)} classes, \"\n                f\"{len(symbol_info_extractor.imports)} imports\"\n            )\n        except Exception as e:\n            error_msg = f\"Symbol extraction error: {e}\"\n            logger.error(f\"Failed to extract symbols from {file_path}: {e}\\n{traceback.format_exc()}\")\n            self.metrics['errors'].append((file_path, error_msg))\n            return self._create_error_analysis(\n                file_path,\n                parse_result.language,\n                error_msg,\n                start_time\n            )\n        \n        # Detect patterns\n        try:\n            logger.debug(f\"Detecting patterns in {file_path}\")\n            file_content = source_code.decode('utf-8', errors='ignore')\n            patterns = self.pattern_detector.detect_patterns_in_file(\n                symbol_info_extractor,\n                file_content,\n                file_path\n            )\n            logger.debug(f\"Pattern detection complete for {file_path}: {len(patterns)} patterns detected\")\n        except Exception as e:\n            logger.warning(f\"Pattern detection failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            patterns = []\n        \n        # Calculate complexity metrics\n        try:\n            logger.debug(f\"Calculating complexity metrics for {file_path}\")\n            complexity_metrics = self.complexity_analyzer.analyze_file(symbol_info_extractor)\n            \n            # Convert to model format\n            complexity_metrics_model = ComplexityMetricsModel(\n                avg_complexity=complexity_metrics.avg_complexity,\n                max_complexity=complexity_metrics.max_complexity,\n                min_complexity=complexity_metrics.min_complexity,\n                high_complexity_functions=[\n                    func.name for func in symbol_info_extractor.functions \n                    if func.complexity > 10\n                ] + [\n                    f\"{cls.name}.{method.name}\" \n                    for cls in symbol_info_extractor.classes \n                    for method in cls.methods \n                    if method.complexity > 10\n                ],\n                trivial_functions=[\n                    func.name for func in symbol_info_extractor.functions \n                    if func.complexity < 2\n                ] + [\n                    f\"{cls.name}.{method.name}\" \n                    for cls in symbol_info_extractor.classes \n                    for method in cls.methods \n                    if method.complexity < 2\n                ],\n                avg_nesting_depth=complexity_metrics.avg_nesting_depth\n            )\n            logger.debug(\n                f\"Complexity analysis complete for {file_path}: \"\n                f\"avg={complexity_metrics.avg_complexity:.1f}, \"\n                f\"max={complexity_metrics.max_complexity}, \"\n                f\"high_complexity_count={len(complexity_metrics_model.high_complexity_functions)}\"\n            )\n        except Exception as e:\n            logger.warning(f\"Complexity analysis failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            complexity_metrics_model = ComplexityMetricsModel(\n                avg_complexity=0.0,\n                max_complexity=0,\n                min_complexity=0,\n                high_complexity_functions=[],\n                trivial_functions=[],\n                avg_nesting_depth=0.0\n            )\n        \n        # Calculate documentation coverage\n        try:\n            logger.debug(f\"Calculating documentation coverage for {file_path}\")\n            doc_coverage = self.doc_coverage_analyzer.calculate_coverage(\n                symbol_info_extractor,\n                file_content,\n                parse_result.language\n            )\n            logger.debug(f\"Documentation coverage for {file_path}: {doc_coverage.total_score:.2%}\")\n        except Exception as e:\n            logger.warning(f\"Documentation coverage analysis failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            from .documentation_coverage import DocumentationCoverage\n            doc_coverage = DocumentationCoverage()\n        \n        # Score teaching value\n        try:\n            logger.debug(f\"Scoring teaching value for {file_path}\")\n            teaching_value_result = self.teaching_value_scorer.score_file(\n                symbol_info_extractor,\n                patterns,\n                complexity_metrics,\n                doc_coverage\n            )\n            # Convert to model format\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n            teaching_value = TeachingValueScoreModel(\n                total_score=teaching_value_result.total_score,\n                documentation_score=teaching_value_result.documentation_score,\n                complexity_score=teaching_value_result.complexity_score,\n                pattern_score=teaching_value_result.pattern_score,\n                structure_score=teaching_value_result.structure_score,\n                explanation=teaching_value_result.explanation,\n                factors=teaching_value_result.factors\n            )\n            logger.debug(f\"Teaching value score for {file_path}: {teaching_value.total_score:.2f}\")\n        except Exception as e:\n            logger.warning(f\"Teaching value scoring failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            from src.models.analysis_models import TeachingValueScore as TeachingValueScoreModel\n            teaching_value = TeachingValueScoreModel(\n                total_score=0.0,\n                documentation_score=0.0,\n                complexity_score=0.0,\n                pattern_score=0.0,\n                structure_score=0.0,\n                explanation=\"Scoring failed\",\n                factors={}\n            )\n        \n        # Run linters asynchronously (non-blocking)\n        try:\n            logger.debug(f\"Running linters for {file_path}\")\n            linter_issues = await self.linter.run_linters(\n                file_path,\n                parse_result.language\n            )\n            if linter_issues:\n                logger.debug(f\"Linter found {len(linter_issues)} issues in {file_path}\")\n        except Exception as e:\n            logger.warning(f\"Linter execution failed for {file_path}: {e}\\n{traceback.format_exc()}\")\n            linter_issues = []\n        \n        # Convert symbol_info to model version for storage\n        symbol_info_model = self._convert_symbol_info(symbol_info_extractor)\n        \n        # Create analysis result\n        analysis = FileAnalysis(\n            file_path=file_path,\n            language=parse_result.language,\n            symbol_info=symbol_info_model,\n            patterns=patterns,\n            teaching_value=teaching_value,\n            complexity_metrics=complexity_metrics_model,\n            documentation_coverage=doc_coverage.total_score,\n            linter_issues=linter_issues,\n            has_errors=parse_result.has_errors,\n            errors=[str(node) for node in parse_result.error_nodes] if parse_result.has_errors else [],\n            analyzed_at=datetime.now().isoformat(),\n            cache_hit=False,\n            is_notebook=is_notebook\n        )\n        \n        # Cache results\n        if file_hash:\n            await self._cache_analysis(file_path, file_hash, analysis)\n        \n        # Track performance metrics\n        elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000\n        self.metrics['total_files_analyzed'] += 1\n        self.metrics['total_analysis_time_ms'] += elapsed_ms\n        self.metrics['file_analysis_times'].append((file_path, elapsed_ms))\n        \n        # Log slow operations (>1000ms)\n        if elapsed_ms > 1000:\n            logger.warning(\n                f\"Slow operation detected: Analysis of {file_path} took {elapsed_ms:.0f}ms \"\n                f\"(threshold: 1000ms)\"\n            )\n            self.metrics['slow_operations'].append((file_path, elapsed_ms))\n        \n        logger.info(\n            f\"Analysis complete for {file_path} in {elapsed_ms:.0f}ms \"\n            f\"(teaching_value: {analysis.teaching_value.total_score:.2f}, \"\n            f\"functions: {len(analysis.symbol_info.functions)}, \"\n            f\"classes: {len(analysis.symbol_info.classes)})\"\n        )\n        \n        return analysis\n    \n    def _create_error_analysis(\n        self,\n        file_path: str,\n        language: str,\n        error_message: str,\n        start_time: datetime\n    ) -> FileAnalysis:\n        \"\"\"\n        Create an error analysis result when analysis fails.\n        \n        Args:\n            file_path: Path to file\n            language: Programming language\n            error_message: Error message\n            start_time: Analysis start time\n        \n        Returns:\n            FileAnalysis with error flag set\n        \"\"\"\n        from src.models.analysis_models import TeachingValueScore\n        \n        return FileAnalysis(\n            file_path=file_path,\n            language=language,\n            symbol_info=SymbolInfoModel(\n                functions=[],\n                classes=[],\n                imports=[],\n                exports=[]\n            ),\n            patterns=[],\n            teaching_value=TeachingValueScore(\n                total_score=0.0,\n                documentation_score=0.0,\n                complexity_score=0.0,\n                pattern_score=0.0,\n                structure_score=0.0,\n                explanation=\"Analysis failed\",\n                factors={}\n            ),\n            complexity_metrics=ComplexityMetricsModel(\n                avg_complexity=0.0,\n                max_complexity=0,\n                min_complexity=0,\n                high_complexity_functions=[],\n                trivial_functions=[],\n                avg_nesting_depth=0.0\n            ),\n            documentation_coverage=0.0,\n            linter_issues=[],\n            has_errors=True,\n            errors=[error_message],\n            analyzed_at=datetime.now().isoformat(),\n            cache_hit=False,\n            is_notebook=False\n        )\n    \n    async def analyze_codebase(\n        self,\n        codebase_id: str,\n        incremental: bool = True\n    ) -> CodebaseAnalysis:\n        \"\"\"\n        Analyze entire codebase with parallel processing and incremental support.\n        \n        Args:\n            codebase_id: ID of codebase to analyze\n            incremental: If True, only analyze changed files\n        \n        Returns:\n            CodebaseAnalysis with all files analyzed\n        \n        Example:\n            >>> engine = AnalysisEngine(cache, config)\n            >>> analysis = await engine.analyze_codebase(\"my_project\", incremental=True)\n            >>> print(f\"Analyzed {analysis.metrics.total_files} files\")\n        \"\"\"\n        start_time = datetime.now()\n        logger.info(\n            f\"Starting codebase analysis: {codebase_id} \"\n            f\"(incremental={incremental}, enable_incremental={self.config.enable_incremental})\"\n        )\n        \n        # Get scan results\n        try:\n            scan_result = await self.cache.get_analysis(f\"scan:{codebase_id}\")\n            if not scan_result:\n                error_msg = f\"Codebase not scanned. Call scan_codebase first for codebase_id: {codebase_id}\"\n                logger.error(error_msg)\n                raise ValueError(error_msg)\n            logger.debug(f\"Retrieved scan results for {codebase_id}\")\n        except ValueError:\n            raise\n        except Exception as e:\n            error_msg = f\"Failed to retrieve scan results for {codebase_id}: {e}\"\n            logger.error(f\"{error_msg}\\n{traceback.format_exc()}\")\n            raise ValueError(error_msg)\n        \n        # Load previous analysis for incremental mode\n        previous_analysis = None\n        previous_hashes = {}\n        if incremental and self.config.enable_incremental:\n            try:\n                logger.debug(f\"Loading previous analysis for {codebase_id}\")\n                previous_analysis = self.persistence.load_analysis(codebase_id)\n                previous_hashes = self.persistence.get_file_hashes(codebase_id)\n                if previous_analysis:\n                    logger.info(\n                        f\"Loaded previous analysis for {codebase_id}: \"\n                        f\"{len(previous_analysis.file_analyses)} files, \"\n                        f\"{len(previous_hashes)} hashes\"\n                    )\n                else:\n                    logger.info(f\"No previous analysis found for {codebase_id}, performing full analysis\")\n            except Exception as e:\n                logger.warning(f\"Failed to load previous analysis for {codebase_id}: {e}\")\n                previous_analysis = None\n                previous_hashes = {}\n        \n        # Determine which files to analyze\n        files_to_analyze = []\n        current_hashes = {}\n        \n        # Get file list from scan result\n        # scan_result contains 'path' which is the root directory\n        # We need to walk the directory to get all analyzable files\n        file_list = []\n        \n        if isinstance(scan_result, dict) and 'path' in scan_result:\n            root_path = scan_result['path']\n            logger.debug(f\"Scanning directory for files: {root_path}\")\n            \n            # Walk the directory to find all analyzable files\n            import os\n            for dirpath, dirnames, filenames in os.walk(root_path):\n                # Filter out ignored directories\n                dirnames[:] = [d for d in dirnames if d not in [\n                    'node_modules', '.git', '__pycache__', 'venv', '.venv',\n                    'dist', 'build', '.next', '.cache'\n                ]]\n                \n                for filename in filenames:\n                    file_path = os.path.join(dirpath, filename)\n                    if self._is_analyzable(file_path):\n                        file_list.append(file_path)\n            \n            logger.info(f\"Found {len(file_list)} analyzable files\")\n        else:\n            logger.error(f\"Invalid scan result format for {codebase_id}: missing 'path' key\")\n            raise ValueError(\"Invalid scan result format: missing 'path' key\")\n        \n        for file_path in file_list:\n            if not self._is_analyzable(file_path):\n                continue\n            \n            file_hash = self._calculate_file_hash(file_path)\n            if not file_hash:\n                logger.warning(f\"Could not calculate hash for {file_path}, skipping\")\n                continue\n            \n            current_hashes[file_path] = file_hash\n            \n            # In incremental mode, skip unchanged files\n            if incremental and self.config.enable_incremental and file_path in previous_hashes:\n                if previous_hashes[file_path] == file_hash:\n                    logger.debug(f\"Skipping unchanged file: {file_path}\")\n                    continue\n                else:\n                    logger.debug(f\"File changed: {file_path}\")\n            \n            files_to_analyze.append(file_path)\n        \n        logger.info(\n            f\"Analyzing {len(files_to_analyze)} files \"\n            f\"(total: {len(current_hashes)}, incremental: {incremental})\"\n        )\n        \n        # Initialize file analyses dict\n        file_analyses = {}\n        reused_count = 0\n        \n        # Reuse previous analyses for unchanged files\n        if previous_analysis and incremental and self.config.enable_incremental:\n            for file_path, analysis in previous_analysis.file_analyses.items():\n                if file_path not in files_to_analyze and file_path in current_hashes:\n                    # File unchanged, reuse previous analysis\n                    file_analyses[file_path] = analysis\n                    reused_count += 1\n                    logger.debug(f\"Reusing previous analysis for {file_path}\")\n            \n            if reused_count > 0:\n                logger.info(f\"Reusing {reused_count} unchanged file analyses from previous run\")\n        \n        # Analyze new/changed files in parallel\n        if files_to_analyze:\n            logger.info(\n                f\"Analyzing {len(files_to_analyze)} files in parallel \"\n                f\"(max_workers: {self.config.max_parallel_files})...\"\n            )\n            \n            # Create analysis tasks\n            tasks = [self.analyze_file(fp) for fp in files_to_analyze]\n            \n            # Run in parallel with asyncio.gather\n            parallel_start = datetime.now()\n            results = await asyncio.gather(*tasks, return_exceptions=True)\n            parallel_elapsed_ms = (datetime.now() - parallel_start).total_seconds() * 1000\n            \n            # Process results\n            success_count = 0\n            error_count = 0\n            for file_path, result in zip(files_to_analyze, results):\n                if isinstance(result, Exception):\n                    error_count += 1\n                    error_msg = str(result)\n                    logger.error(f\"Failed to analyze {file_path}: {error_msg}\\n{traceback.format_exc()}\")\n                    self.metrics['errors'].append((file_path, error_msg))\n                    # Create error analysis\n                    file_analyses[file_path] = self._create_error_analysis(\n                        file_path,\n                        \"unknown\",\n                        error_msg,\n                        start_time\n                    )\n                else:\n                    success_count += 1\n                    file_analyses[file_path] = result\n            \n            logger.info(\n                f\"Parallel file analysis complete: {success_count} succeeded, {error_count} failed \"\n                f\"in {parallel_elapsed_ms:.0f}ms \"\n                f\"(avg: {parallel_elapsed_ms / len(files_to_analyze):.0f}ms per file)\"\n            )\n        \n        logger.info(f\"Total file analyses: {len(file_analyses)} files\")\n        \n        # Build dependency graph\n        try:\n            logger.info(\"Building dependency graph...\")\n            dep_start = datetime.now()\n            dependency_graph = self.dependency_analyzer.analyze_dependencies(\n                codebase_id,\n                file_analyses\n            )\n            dep_elapsed_ms = (datetime.now() - dep_start).total_seconds() * 1000\n            logger.info(\n                f\"Dependency graph built in {dep_elapsed_ms:.0f}ms: \"\n                f\"{len(dependency_graph.nodes)} nodes, \"\n                f\"{len(dependency_graph.edges)} edges, \"\n                f\"{len(dependency_graph.circular_dependencies)} circular dependencies\"\n            )\n        except Exception as e:\n            logger.error(f\"Failed to build dependency graph: {e}\\n{traceback.format_exc()}\")\n            # Create empty dependency graph\n            from .dependency_analyzer import DependencyGraph\n            dependency_graph = DependencyGraph()\n        \n        # Detect global patterns\n        try:\n            logger.info(\"Detecting global patterns...\")\n            pattern_start = datetime.now()\n            global_patterns = self.pattern_detector.detect_global_patterns(file_analyses)\n            pattern_elapsed_ms = (datetime.now() - pattern_start).total_seconds() * 1000\n            logger.info(f\"Global pattern detection complete in {pattern_elapsed_ms:.0f}ms: {len(global_patterns)} patterns\")\n        except Exception as e:\n            logger.error(f\"Failed to detect global patterns: {e}\\n{traceback.format_exc()}\")\n            global_patterns = []\n        \n        # Rank files by teaching value\n        try:\n            logger.debug(\"Ranking files by teaching value...\")\n            top_teaching_files = sorted(\n                [(fp, fa.teaching_value.total_score) for fp, fa in file_analyses.items()],\n                key=lambda x: x[1],\n                reverse=True\n            )[:20]  # Top 20 files\n            if top_teaching_files:\n                logger.info(\n                    f\"Top teaching file: {top_teaching_files[0][0]} \"\n                    f\"(score: {top_teaching_files[0][1]:.2f})\"\n                )\n        except Exception as e:\n            logger.error(f\"Failed to rank teaching files: {e}\\n{traceback.format_exc()}\")\n            top_teaching_files = []\n        \n        # Calculate codebase metrics\n        try:\n            logger.debug(\"Calculating codebase metrics...\")\n            metrics = self._calculate_codebase_metrics(file_analyses, start_time)\n            logger.info(\n                f\"Codebase metrics: {metrics.total_files} files, \"\n                f\"{metrics.total_functions} functions, \"\n                f\"{metrics.total_classes} classes, \"\n                f\"avg_complexity={metrics.avg_complexity:.1f}, \"\n                f\"avg_doc_coverage={metrics.avg_documentation_coverage:.2%}, \"\n                f\"cache_hit_rate={metrics.cache_hit_rate:.2%}\"\n            )\n        except Exception as e:\n            logger.error(f\"Failed to calculate metrics: {e}\\n{traceback.format_exc()}\")\n            metrics = CodebaseMetrics(\n                total_files=len(file_analyses),\n                total_functions=0,\n                total_classes=0,\n                avg_complexity=0.0,\n                avg_documentation_coverage=0.0,\n                total_patterns_detected=0,\n                analysis_time_ms=0.0,\n                cache_hit_rate=0.0\n            )\n        \n        # Create codebase analysis\n        analysis = CodebaseAnalysis(\n            codebase_id=codebase_id,\n            file_analyses=file_analyses,\n            dependency_graph=dependency_graph,\n            global_patterns=global_patterns,\n            top_teaching_files=top_teaching_files,\n            metrics=metrics,\n            analyzed_at=datetime.now().isoformat()\n        )\n        \n        # Persist to disk\n        try:\n            logger.info(f\"Persisting analysis to disk: {self.config.persistence_path}/{codebase_id}\")\n            persist_start = datetime.now()\n            self.persistence.save_analysis(codebase_id, analysis)\n            self.persistence.save_file_hashes(codebase_id, current_hashes)\n            persist_elapsed_ms = (datetime.now() - persist_start).total_seconds() * 1000\n            logger.info(f\"Analysis persisted to disk in {persist_elapsed_ms:.0f}ms\")\n        except Exception as e:\n            logger.error(f\"Failed to persist analysis: {e}\\n{traceback.format_exc()}\")\n        \n        # Cache in memory\n        try:\n            logger.debug(\"Caching analysis in memory...\")\n            await self.cache.set_analysis(\n                f\"codebase:{codebase_id}\",\n                analysis.to_dict(),\n                ttl=self.config.cache_ttl_seconds\n            )\n            logger.debug(f\"Analysis cached with TTL={self.config.cache_ttl_seconds}s\")\n        except Exception as e:\n            logger.error(f\"Failed to cache analysis: {e}\\n{traceback.format_exc()}\")\n        \n        # Calculate and log final metrics\n        elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000\n        \n        # Log batch analysis summary\n        logger.info(\"=\" * 80)\n        logger.info(f\"BATCH ANALYSIS SUMMARY - {codebase_id}\")\n        logger.info(\"=\" * 80)\n        logger.info(f\"Total files analyzed: {metrics.total_files}\")\n        logger.info(f\"Total functions: {metrics.total_functions}\")\n        logger.info(f\"Total classes: {metrics.total_classes}\")\n        logger.info(f\"Total patterns detected: {metrics.total_patterns_detected}\")\n        logger.info(f\"Average complexity: {metrics.avg_complexity:.2f}\")\n        logger.info(f\"Average documentation coverage: {metrics.avg_documentation_coverage:.2%}\")\n        logger.info(f\"Cache hit rate: {metrics.cache_hit_rate:.2%}\")\n        logger.info(f\"Total analysis time: {elapsed_ms:.0f}ms ({elapsed_ms/1000:.1f}s)\")\n        logger.info(f\"Average time per file: {metrics.analysis_time_ms / metrics.total_files:.0f}ms\")\n        \n        # Log cache statistics\n        total_cache_requests = self.metrics['total_cache_hits'] + self.metrics['total_cache_misses']\n        if total_cache_requests > 0:\n            cache_hit_rate = self.metrics['total_cache_hits'] / total_cache_requests\n            logger.info(f\"Cache hits: {self.metrics['total_cache_hits']}\")\n            logger.info(f\"Cache misses: {self.metrics['total_cache_misses']}\")\n            logger.info(f\"Session cache hit rate: {cache_hit_rate:.2%}\")\n        \n        # Log slow operations\n        if self.metrics['slow_operations']:\n            logger.warning(f\"Slow operations detected: {len(self.metrics['slow_operations'])}\")\n            for file_path, duration_ms in self.metrics['slow_operations'][:5]:  # Top 5 slowest\n                logger.warning(f\"  - {file_path}: {duration_ms:.0f}ms\")\n        \n        # Log errors\n        if self.metrics['errors']:\n            logger.error(f\"Errors encountered: {len(self.metrics['errors'])}\")\n            for file_path, error_msg in self.metrics['errors'][:5]:  # First 5 errors\n                logger.error(f\"  - {file_path}: {error_msg}\")",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 9 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: from .documentation_coverage import DocumentationCoverage"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (8 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "session_authentication",
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "e4d8d1d7-a160-40b3-9bff-a4e2dbd16209",
          "title": "Detect Frameworks: Python Async Await",
          "description": "Excellent teaching value (score: 0.81). Well-documented (100% coverage). Slightly complex (avg complexity: 9.3). Contains useful patterns. Well-structured code. Demonstrates: python_context_managers, python_async_await, python_comprehensions",
          "order": 6,
          "difficulty": "intermediate",
          "duration_minutes": 60,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\tools\\detect_frameworks.py",
          "teaching_value": 0.805,
          "learning_objectives": [
            "Understand python context managers pattern",
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "be825e12-d413-41c6-88a0-425d674b3f63",
              "title": "Practice: Python Async Await",
              "description": "Implement a python_async_await based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\tools\\detect_frameworks.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_async_await following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Async functions: 3, Await statements: 6"
              ],
              "starter_code": "async def detect_frameworks(\n    # TODO: Implement python_async_await logic here\n    pass\n    \"\"\"\n    \n    \n        \n            \n        \n    \"\"\"\n    \n    # Check cache if enabled\n            # Filter by confidence threshold if different from cached\n    \n    # Retrieve scan result from cache\n    \n    \n    \n    \n    # Detect frameworks\n    \n    # JavaScript/TypeScript detection\n    \n    # Python detection\n    \n    # Filter by confidence threshold\n    \n    # Sort by confidence score descending\n    \n    # Convert to dict format\n    \n    \n    \n    # Cache the result\n    \n\n\nasync def _detect_js_frameworks(codebase_path: str) -> List[Framework]:\n    \"\"\"\n    # TODO: Implement python_async_await logic here\n    pass\n    \n        \n    \"\"\"\n    \n    \n        \n        # Get dependencies and devDependencies\n        \n        \n        # Check for known frameworks\n        \n        # Continue without failing - graceful degradation\n        # Continue without failing\n        # Continue without failing\n    \n\n\nasync def _detect_python_frameworks(codebase_path: str) -> List[Framework]:\n    \"\"\"\n    # TODO: Implement python_async_await logic here\n    pass",
              "solution_code": "async def detect_frameworks(\n    codebase_id: str,\n    confidence_threshold: float = 0.7,\n    use_cache: bool = True,\n    cache_manager: Optional[UnifiedCacheManager] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Detect frameworks and libraries used in a codebase with confidence scores.\n    \n    This function analyzes package.json for JavaScript/TypeScript projects and\n    requirements.txt for Python projects, assigning confidence scores and evidence\n    for each detected framework. Results are cached for 1 hour.\n    \n    Args:\n        codebase_id: Unique identifier from scan_codebase\n        confidence_threshold: Minimum confidence score (0.0-1.0, default: 0.7)\n        use_cache: Whether to use cached results if available (default: True)\n        cache_manager: UnifiedCacheManager instance for caching\n        \n    Returns:\n        Dictionary containing:\n            - frameworks: List of Framework objects with name, version, confidence, evidence\n            - total_detected: Total number of frameworks detected\n            - confidence_threshold: The threshold used for filtering\n            - from_cache: Whether result was from cache\n            \n    Raises:\n        ValueError: If codebase has not been scanned first\n        \n    Examples:\n        >>> result = await detect_frameworks(\"a1b2c3d4e5f6g7h8\")\n        >>> print(result[\"frameworks\"][0][\"name\"])\n        \"React\"\n        >>> print(result[\"frameworks\"][0][\"confidence\"])\n        0.99\n    \"\"\"\n    logger.info(f\"Detecting frameworks for codebase: {codebase_id}\")\n    \n    # Check cache if enabled\n    if use_cache and cache_manager:\n        cached_result = await cache_manager.get_analysis(f\"frameworks:{codebase_id}\")\n        if cached_result:\n            logger.info(f\"Cache hit for frameworks:{codebase_id}\")\n            # Filter by confidence threshold if different from cached\n            if cached_result.get(\"confidence_threshold\") != confidence_threshold:\n                frameworks = [\n                    f for f in cached_result[\"frameworks\"]\n                    if f[\"confidence\"] >= confidence_threshold\n                ]\n                cached_result[\"frameworks\"] = frameworks\n                cached_result[\"total_detected\"] = len(frameworks)\n                cached_result[\"confidence_threshold\"] = confidence_threshold\n            cached_result[\"from_cache\"] = True\n            return cached_result\n    \n    # Retrieve scan result from cache\n    if not cache_manager:\n        raise ValueError(\"Cache manager is required for framework detection\")\n    \n    scan_result = await cache_manager.get_analysis(f\"scan:{codebase_id}\")\n    if not scan_result:\n        logger.error(f\"Codebase not scanned: {codebase_id}\")\n        raise ValueError(\"Codebase not scanned. Call scan_codebase first.\")\n    \n    codebase_path = scan_result.get(\"path\")\n    if not codebase_path:\n        logger.error(f\"Scan result missing path for codebase: {codebase_id}\")\n        raise ValueError(\"Codebase not scanned. Call scan_codebase first.\")\n    \n    languages = scan_result.get(\"structure\", {}).get(\"languages\", {})\n    \n    # Detect frameworks\n    frameworks: List[Framework] = []\n    \n    # JavaScript/TypeScript detection\n    if \"JavaScript\" in languages or \"TypeScript\" in languages:\n        logger.debug(\"Detecting JavaScript/TypeScript frameworks\")\n        js_frameworks = await _detect_js_frameworks(codebase_path)\n        frameworks.extend(js_frameworks)\n    \n    # Python detection\n    if \"Python\" in languages:\n        logger.debug(\"Detecting Python frameworks\")\n        py_frameworks = await _detect_python_frameworks(codebase_path)\n        frameworks.extend(py_frameworks)\n    \n    # Filter by confidence threshold\n    frameworks = [f for f in frameworks if f.confidence >= confidence_threshold]\n    \n    # Sort by confidence score descending\n    frameworks.sort(key=lambda x: x.confidence, reverse=True)\n    \n    # Convert to dict format\n    frameworks_dict = [f.to_dict() for f in frameworks]\n    \n    result = {\n        \"frameworks\": frameworks_dict,\n        \"total_detected\": len(frameworks_dict),\n        \"confidence_threshold\": confidence_threshold,\n        \"from_cache\": False\n    }\n    \n    logger.info(\n        f\"Framework detection complete: {len(frameworks_dict)} frameworks detected \"\n        f\"(threshold: {confidence_threshold})\"\n    )\n    \n    # Cache the result\n    if cache_manager:\n        await cache_manager.set_analysis(f\"frameworks:{codebase_id}\", result, ttl=3600)\n        logger.debug(f\"Cached framework detection result for {codebase_id}\")\n    \n    return result\n\n\nasync def _detect_js_frameworks(codebase_path: str) -> List[Framework]:\n    \"\"\"\n    Detect JavaScript/TypeScript frameworks from package.json.\n    \n    Args:\n        codebase_path: Root path of the codebase\n        \n    Returns:\n        List of Framework objects detected from package.json\n    \"\"\"\n    frameworks: List[Framework] = []\n    package_json_path = os.path.join(codebase_path, \"package.json\")\n    \n    if not os.path.exists(package_json_path):\n        logger.debug(f\"No package.json found at {package_json_path}\")\n        return frameworks\n    \n    try:\n        with open(package_json_path, \"r\", encoding=\"utf-8\") as f:\n            package_data = json.load(f)\n        \n        # Get dependencies and devDependencies\n        dependencies = package_data.get(\"dependencies\", {})\n        dev_dependencies = package_data.get(\"devDependencies\", {})\n        all_deps = {**dependencies, **dev_dependencies}\n        \n        logger.debug(f\"Found {len(all_deps)} dependencies in package.json\")\n        \n        # Check for known frameworks\n        for dep_name, dep_version in all_deps.items():\n            if dep_name in JS_FRAMEWORKS:\n                framework_info = JS_FRAMEWORKS[dep_name]\n                framework = Framework(\n                    name=framework_info[\"name\"],\n                    version=dep_version if dep_version else \"detected\",\n                    confidence=framework_info[\"confidence\"],\n                    evidence=[\"package.json dependency\"]\n                )\n                frameworks.append(framework)\n                logger.debug(f\"Detected {framework.name} v{framework.version}\")\n        \n    except json.JSONDecodeError as e:\n        logger.warning(f\"Failed to parse package.json: {e}\")\n        # Continue without failing - graceful degradation\n    except (OSError, IOError) as e:\n        logger.warning(f\"Failed to read package.json: {e}\")\n        # Continue without failing\n    except Exception as e:\n        logger.error(f\"Unexpected error reading package.json: {e}\", exc_info=True)\n        # Continue without failing\n    \n    return frameworks\n\n\nasync def _detect_python_frameworks(codebase_path: str) -> List[Framework]:\n    \"\"\"\n    Detect Python frameworks from requirements.txt.",
              "hints": [
                "Start by understanding the structure of a python_async_await. Look at the imports and main components needed.",
                "Key elements to implement: 7 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Async Await",
                "Practice writing clean, maintainable code for Python Async Await",
                "Apply Async functions: 3 in your implementation",
                "Apply Await statements: 6 in your implementation"
              ]
            }
          ],
          "tags": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ]
        }
      ]
    },
    {
      "module_id": "a463b47a-1ee9-45cc-ae56-0d4138112ec1",
      "title": "Module 4: Session Authentication",
      "description": "This module covers: session_authentication, python_context_managers",
      "order": 3,
      "difficulty": "beginner",
      "duration_hours": 0.7,
      "learning_objectives": [
        "Master session authentication patterns",
        "Master python context managers patterns",
        "Build foundational programming skills"
      ],
      "lessons": [
        {
          "lesson_id": "99129e48-9a5a-4c67-b429-e0ad0f0386b6",
          "title": "Persistence: Python Context Managers",
          "description": "Excellent teaching value (score: 0.83). Well-documented (100% coverage). Ideal complexity (avg: 3.0) for teaching. Contains useful patterns. Well-structured code. Demonstrates: session_authentication, python_context_managers",
          "order": 0,
          "difficulty": "beginner",
          "duration_minutes": 42,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\persistence.py",
          "teaching_value": 0.83,
          "learning_objectives": [
            "Understand session authentication pattern",
            "Understand python context managers pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "session_authentication",
            "python_context_managers"
          ],
          "exercises": [
            {
              "exercise_id": "117cf773-9e46-48d5-a90a-40134fc825e7",
              "title": "Practice: Python Context Managers",
              "description": "Implement a python_context_managers based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\persistence.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_context_managers following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses context managers (5 with statements), File handling with context managers"
              ],
              "starter_code": "# Save main analysis file\n            \n            \n            # Save individual file analyses for efficient partial loading\n                # Create safe filename from file path hash\n                \n            \n            \n    \n    def load_analysis(self, codebase_id: str) -> Optional[CodebaseAnalysis]:\n        \"\"\"\n        # TODO: Implement python_context_managers logic here\n        pass\n        \n        \n        \"\"\"\n            \n            \n            \n            \n            \n    \n    def get_file_hashes(self, codebase_id: str) -> Dict[str, str]:\n        \"\"\"\n        # TODO: Implement python_context_managers logic here\n        pass\n        \n        \n        \n        \"\"\"\n            \n            \n            \n            \n    \n    def save_file_hashes(self, codebase_id: str, hashes: Dict[str, str]) -> None:\n        \"\"\"\n        # TODO: Implement python_context_managers logic here\n        pass\n        \n        \n        \n        \"\"\"\n            # Create codebase-specific directory\n            \n            # Save file hashes",
              "solution_code": "# Save main analysis file\n            analysis_file = analysis_dir / \"analysis.json\"\n            with open(analysis_file, 'w', encoding='utf-8') as f:\n                json.dump(analysis.to_dict(), f, indent=2, ensure_ascii=False)\n            \n            logger.info(f\"Saved analysis for codebase {codebase_id} to {analysis_file}\")\n            \n            # Save individual file analyses for efficient partial loading\n            for file_path, file_analysis in analysis.file_analyses.items():\n                # Create safe filename from file path hash\n                safe_name = hashlib.sha256(file_path.encode()).hexdigest()[:16]\n                file_analysis_path = analysis_dir / f\"file_{safe_name}.json\"\n                \n                with open(file_analysis_path, 'w', encoding='utf-8') as f:\n                    json.dump(file_analysis.to_dict(), f, indent=2, ensure_ascii=False)\n            \n            logger.debug(f\"Saved {len(analysis.file_analyses)} individual file analyses\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to save analysis for {codebase_id}: {e}\")\n            raise IOError(f\"Failed to save analysis: {e}\") from e\n    \n    def load_analysis(self, codebase_id: str) -> Optional[CodebaseAnalysis]:\n        \"\"\"\n        Load complete codebase analysis from disk.\n        \n        Args:\n            codebase_id: Unique identifier for the codebase\n        \n        Returns:\n            CodebaseAnalysis object if found, None otherwise\n        \"\"\"\n        try:\n            analysis_file = self.base_path / codebase_id / \"analysis.json\"\n            \n            if not analysis_file.exists():\n                logger.debug(f\"No saved analysis found for codebase {codebase_id}\")\n                return None\n            \n            with open(analysis_file, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n            \n            analysis = CodebaseAnalysis.from_dict(data)\n            logger.info(f\"Loaded analysis for codebase {codebase_id} from {analysis_file}\")\n            \n            return analysis\n            \n        except Exception as e:\n            logger.error(f\"Failed to load analysis for {codebase_id}: {e}\")\n            return None\n    \n    def get_file_hashes(self, codebase_id: str) -> Dict[str, str]:\n        \"\"\"\n        Get stored file hashes for incremental analysis.\n        \n        File hashes are used to detect which files have changed since\n        the last analysis, enabling efficient incremental updates.\n        \n        Args:\n            codebase_id: Unique identifier for the codebase\n        \n        Returns:\n            Dictionary mapping file paths to their SHA-256 hashes\n        \"\"\"\n        try:\n            hash_file = self.base_path / codebase_id / \"file_hashes.json\"\n            \n            if not hash_file.exists():\n                logger.debug(f\"No file hashes found for codebase {codebase_id}\")\n                return {}\n            \n            with open(hash_file, 'r', encoding='utf-8') as f:\n                hashes = json.load(f)\n            \n            logger.debug(f\"Loaded {len(hashes)} file hashes for codebase {codebase_id}\")\n            return hashes\n            \n        except Exception as e:\n            logger.error(f\"Failed to load file hashes for {codebase_id}: {e}\")\n            return {}\n    \n    def save_file_hashes(self, codebase_id: str, hashes: Dict[str, str]) -> None:\n        \"\"\"\n        Save file hashes for incremental analysis.\n        \n        Stores a mapping of file paths to their SHA-256 hashes,\n        enabling detection of changed files in future analyses.\n        \n        Args:\n            codebase_id: Unique identifier for the codebase\n            hashes: Dictionary mapping file paths to SHA-256 hashes\n        \n        Raises:\n            IOError: If unable to write to disk\n        \"\"\"\n        try:\n            # Create codebase-specific directory\n            analysis_dir = self.base_path / codebase_id\n            analysis_dir.mkdir(parents=True, exist_ok=True)\n            \n            # Save file hashes\n            hash_file = analysis_dir / \"file_hashes.json\"\n            with open(hash_file, 'w', encoding='utf-8') as f:\n                json.dump(hashes, f, indent=2, ensure_ascii=False)",
              "hints": [
                "Start by understanding the structure of a python_context_managers. Look at the imports and main components needed.",
                "Key elements to implement: 9 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Context Managers",
                "Practice writing clean, maintainable code for Python Context Managers",
                "Apply Uses context managers (5 with statements) in your implementation",
                "Apply File handling with context managers in your implementation"
              ]
            }
          ],
          "tags": [
            "session_authentication",
            "python_context_managers"
          ]
        }
      ]
    },
    {
      "module_id": "1997feaa-f4d5-4010-9123-4de34955cee8",
      "title": "Module 5: Session Authentication",
      "description": "This module covers: session_authentication",
      "order": 4,
      "difficulty": "beginner",
      "duration_hours": 0.6,
      "learning_objectives": [
        "Master session authentication patterns",
        "Build foundational programming skills"
      ],
      "lessons": [
        {
          "lesson_id": "782c57c1-58c0-4592-a4ba-555e002ceb51",
          "title": "Teaching Value Assessor: Session Authentication",
          "description": "Excellent teaching value (score: 0.78). Well-documented (100% coverage). Ideal complexity (avg: 5.0) for teaching. Contains some patterns. Well-structured code. Demonstrates: session_authentication",
          "order": 0,
          "difficulty": "beginner",
          "duration_minutes": 36,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\teaching_value_assessor.py",
          "teaching_value": 0.78,
          "learning_objectives": [
            "Understand session authentication pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "session_authentication"
          ],
          "exercises": [],
          "tags": [
            "session_authentication"
          ]
        }
      ]
    },
    {
      "module_id": "ca072872-ed6a-4f2d-9ed5-5e0f1329e812",
      "title": "Module 1: Python Comprehensions",
      "description": "This module covers: python_async_await, python_context_managers, password_hashing, python_generators, python_comprehensions",
      "order": 0,
      "difficulty": "intermediate",
      "duration_hours": 7.6,
      "learning_objectives": [
        "Master python comprehensions patterns",
        "Master python async await patterns",
        "Master python context managers patterns",
        "Apply intermediate programming concepts",
        "Integrate multiple concepts into cohesive solutions"
      ],
      "lessons": [
        {
          "lesson_id": "a2cc34b1-b248-49e3-bd62-47a4e74570c7",
          "title": "Performance Monitor: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.82). Well-documented (100% coverage). Slightly simple (avg complexity: 2.1). Contains useful patterns. Well-structured code. Demonstrates: python_context_managers, python_generators, python_comprehensions",
          "order": 0,
          "difficulty": "beginner",
          "duration_minutes": 60,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\performance_monitor.py",
          "teaching_value": 0.825,
          "learning_objectives": [
            "Understand python context managers pattern",
            "Understand python generators pattern",
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_context_managers",
            "python_generators",
            "python_comprehensions"
          ],
          "exercises": [],
          "tags": [
            "python_context_managers",
            "python_generators",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "63db03e7-79de-4e7b-ac7d-f580585d41f3",
          "title": "Structure Generator: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.82). Well-documented (100% coverage). Ideal complexity (avg: 3.7) for teaching. Contains useful patterns. Reasonable structure. Demonstrates: python_context_managers, python_async_await, python_comprehensions",
          "order": 1,
          "difficulty": "beginner",
          "duration_minutes": 48,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\structure_generator.py",
          "teaching_value": 0.82,
          "learning_objectives": [
            "Understand python context managers pattern",
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "eee35292-74ad-4a2d-8230-7d445a3e0d04",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\structure_generator.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (17 occurrences)"
              ],
              "starter_code": "# Cache the result\n        \n    \n    def group_by_patterns(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Group files by detected patterns and concepts.\n        \n        \n            \n        \"\"\"\n        # Create pattern-based groups\n        \n            \n            # Find primary pattern for this file\n            \n        \n        # Convert to list of groups, sorted by group size (largest first)\n        \n        # Add ungrouped files as individual groups\n        \n    \n    def calculate_module_count(self, num_teachable_files: int) -> int:\n        \"\"\"Calculate optimal number of modules based on file count.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Aim for 3-5 lessons per module\n        \n    \n    def sort_by_difficulty(self, modules: List[Module]) -> List[Module]:\n        \"\"\"Sort modules by difficulty level (beginner  intermediate  advanced).\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n    \n    def _filter_teachable_files(self, analysis: CodebaseAnalysis) -> List[Tuple[str, float]]:\n        \"\"\"Filter files by teaching value threshold and sort by score.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        # Already sorted by teaching value in descending order\n    \n    def _get_primary_pattern(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Get the primary pattern type for a file.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Return the pattern with highest confidence\n    \n    def _create_modules(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Create modules from grouped files.\"\"\"\n        \n        # Distribute groups across modules\n        \n            \n            \n        \n    \n    def _create_single_module(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Create a single module from file groups.\n        \n        \"\"\"\n        # Flatten groups into single list\n        \n        # Create lessons with pattern grouping (Req 1.4)\n        \n        # Calculate module difficulty (Req 1.1)\n        \n        # Calculate module duration (Req 1.3)\n        \n        # Generate module title and description\n        \n        # Generate module learning objectives (Req 1.4)\n        \n    \n    def _generate_module_objectives(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate learning objectives for a module.\n        \n        \"\"\"\n        \n        # Collect all patterns from the module\n        \n        # Create objectives for top patterns\n        \n        # Add objective based on module difficulty\n        \n        # Add objective based on lesson count\n        \n    \n    def _create_basic_lesson(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Create a basic lesson structure (full implementation in Task 2.2).\"\"\"\n        # Calculate difficulty from complexity\n        \n        # Estimate duration based on complexity\n        \n        # Generate title from file path\n        \n        # Generate description\n        \n        # Extract concepts from patterns\n        \n        # Generate basic learning objectives\n        \n        \n        # Apply audience-based adjustments (Task 13.2)\n        \n    \n    def _calculate_module_difficulty(self, lessons: List[Lesson]) -> str:\n        \"\"\"Calculate overall module difficulty from lessons.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n        # Return the most common difficulty\n    \n    def _calculate_lesson_difficulty(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Calculate lesson difficulty from complexity metrics.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n    \n    def _estimate_lesson_duration(self, file_analysis: FileAnalysis) -> int:\n        \"\"\"Estimate lesson duration in minutes based on complexity.\"\"\"\n        # Base duration\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Add time based on number of functions/classes\n        \n        # Add time based on patterns\n        \n        \n        # Clamp to config range\n    \n    def _generate_lesson_title(self, file_path: str, file_analysis: FileAnalysis) -> str:\n        \"\"\"Generate a lesson title from file path and analysis.\"\"\"\n        # Get filename without extension\n        import os\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Convert snake_case or kebab-case to Title Case\n        \n        # Add pattern context if available\n        \n    \n    def _generate_lesson_description(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Generate a lesson description from analysis.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Add teaching value explanation\n        \n        # Add pattern information\n        \n    \n    def _generate_basic_objectives(self, file_analysis: FileAnalysis) -> List[str]:\n        \"\"\"Generate basic learning objectives from file analysis.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Add objectives based on patterns\n        \n        # Add objective based on complexity\n        \n        # Add objective based on documentation\n        \n    \n    def _generate_module_title(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate a module title from file groups.\"\"\"\n        # Get most common pattern across all files\n        \n        \n        \n    \n    def _generate_module_description(self, lessons: List[Lesson]) -> str:\n        \"\"\"Generate a module description from lessons.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Collect unique concepts\n        \n        \n    \n    def _calculate_difficulty_distribution(self, modules: List[Module]) -> Dict[str, int]:\n        \"\"\"Calculate distribution of difficulty levels across all lessons.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n    \n    def _generate_course_title(self, analysis: CodebaseAnalysis) -> str:\n        \"\"\"Generate a course title from codebase analysis.\"\"\"\n        # Use codebase_id as base\n        # TODO: Implement python_comprehensions logic here\n        pass\n    \n    def _generate_course_description(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate a course description.\"\"\"\n    \n    def _generate_course_tags(self, analysis: CodebaseAnalysis) -> List[str]:\n        \"\"\"Generate course tags from analysis.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Add pattern types as tags\n        \n    \n    # ========== Task 2.3: Learning Progression Logic ==========\n    \n    def _apply_learning_progression(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Apply learning progression logic to modules and lessons.\n        \n        \n            \n        \"\"\"\n        # Build a map of file_path -> lesson for quick lookup\n        \n        \n        # Detect prerequisites for each lesson (Req 6.2, 6.3)\n        \n        # Sort lessons within each module by prerequisites (Req 6.4)\n            # Update lesson order after sorting\n        \n    \n    def _detect_prerequisites(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Detect prerequisite lessons based on imports and dependencies.\n        \n        \n            \n        \"\"\"\n        \n        # Get file analysis for this lesson\n        \n        # Check imports to find dependencies\n            # Skip external imports\n                # Try to find the imported file in our lessons\n                \n                    # Only add if it's a different lesson and simpler\n        \n        # Also check dependency graph\n        \n    \n    def _is_internal_import(self, module: str, analysis: CodebaseAnalysis) -> bool:\n        \"\"\"Check if an import is internal to the codebase.\"\"\"\n        # Check if any file path contains the module name\n        # TODO: Implement python_comprehensions logic here\n        pass\n    \n    def _resolve_import_to_file(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Resolve an import statement to an actual file path.\"\"\"\n        # Try to find matching file in analysis\n        \n            # Check if file path ends with module path\n        \n    \n    def _is_simpler_lesson(self, lesson1: Lesson, lesson2: Lesson) -> bool:\n        \"\"\"Check if lesson1 is simpler than lesson2.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n            # If same difficulty, use teaching value (higher = simpler/better starting point)\n        \n    \n    def _sort_lessons_by_prerequisites(self, lessons: List[Lesson]) -> List[Lesson]:\n        \"\"\"Sort lessons so prerequisites appear before dependent lessons.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \"\"\"\n        # Build dependency graph\n        ",
              "solution_code": "# Cache the result\n        if self.course_cache:\n            file_paths = [f[0] for f in teachable_files]\n            serialized = self._serialize_course_outline(course_outline)\n            await self.course_cache.set_course_structure(\n                analysis.codebase_id,\n                serialized,\n                file_paths\n            )\n        \n        return course_outline\n    \n    def group_by_patterns(\n        self, \n        teachable_files: List[Tuple[str, float]], \n        analysis: CodebaseAnalysis\n    ) -> List[List[Tuple[str, float, FileAnalysis]]]:\n        \"\"\"Group files by detected patterns and concepts.\n        \n        This method implements Requirement 1.4: Groups lessons by related patterns.\n        \n        Args:\n            teachable_files: List of (file_path, teaching_value) tuples\n            analysis: Codebase analysis results\n            \n        Returns:\n            List of file groups, each containing (file_path, teaching_value, FileAnalysis)\n        \"\"\"\n        # Create pattern-based groups\n        pattern_groups: Dict[str, List[Tuple[str, float, FileAnalysis]]] = defaultdict(list)\n        ungrouped: List[Tuple[str, float, FileAnalysis]] = []\n        \n        for file_path, teaching_value in teachable_files:\n            file_analysis = analysis.file_analyses.get(file_path)\n            if not file_analysis:\n                continue\n            \n            # Find primary pattern for this file\n            primary_pattern = self._get_primary_pattern(file_analysis)\n            \n            if primary_pattern:\n                pattern_groups[primary_pattern].append((file_path, teaching_value, file_analysis))\n            else:\n                ungrouped.append((file_path, teaching_value, file_analysis))\n        \n        # Convert to list of groups, sorted by group size (largest first)\n        grouped = sorted(pattern_groups.values(), key=len, reverse=True)\n        \n        # Add ungrouped files as individual groups\n        if ungrouped:\n            grouped.extend([[item] for item in ungrouped])\n        \n        return grouped\n    \n    def calculate_module_count(self, num_teachable_files: int) -> int:\n        \"\"\"Calculate optimal number of modules based on file count.\n        \n        This method implements Requirement 1.3: Creates 3-8 modules based on teachable files.\n        \n        Args:\n            num_teachable_files: Number of files with sufficient teaching value\n            \n        Returns:\n            Number of modules to create (between min_modules and max_modules)\n        \"\"\"\n        if num_teachable_files == 0:\n            return self.config.min_modules\n        \n        # Aim for 3-5 lessons per module\n        ideal_lessons_per_module = 4\n        ideal_count = max(\n            self.config.min_modules,\n            min(\n                self.config.max_modules,\n                (num_teachable_files + ideal_lessons_per_module - 1) // ideal_lessons_per_module\n            )\n        )\n        \n        return ideal_count\n    \n    def sort_by_difficulty(self, modules: List[Module]) -> List[Module]:\n        \"\"\"Sort modules by difficulty level (beginner  intermediate  advanced).\n        \n        This method implements Requirement 1.1: Organizes modules by difficulty level.\n        \n        Args:\n            modules: List of modules to sort\n            \n        Returns:\n            Sorted list of modules\n        \"\"\"\n        difficulty_order = {\"beginner\": 0, \"intermediate\": 1, \"advanced\": 2}\n        \n        return sorted(\n            modules,\n            key=lambda m: (difficulty_order.get(m.difficulty, 1), m.order)\n        )\n    \n    def _filter_teachable_files(self, analysis: CodebaseAnalysis) -> List[Tuple[str, float]]:\n        \"\"\"Filter files by teaching value threshold and sort by score.\n        \n        Implements Requirement 1.2: Sorts lessons by teaching value score.\n        \"\"\"\n        teachable = [\n            (file_path, score)\n            for file_path, score in analysis.top_teaching_files\n            if score >= self.config.min_teaching_value\n        ]\n        \n        # Already sorted by teaching value in descending order\n        return teachable\n    \n    def _get_primary_pattern(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Get the primary pattern type for a file.\"\"\"\n        if not file_analysis.patterns:\n            return \"\"\n        \n        # Return the pattern with highest confidence\n        primary = max(file_analysis.patterns, key=lambda p: p.confidence)\n        return primary.pattern_type\n    \n    def _create_modules(\n        self,\n        grouped_files: List[List[Tuple[str, float, FileAnalysis]]],\n        module_count: int,\n        analysis: CodebaseAnalysis\n    ) -> List[Module]:\n        \"\"\"Create modules from grouped files.\"\"\"\n        modules = []\n        \n        # Distribute groups across modules\n        groups_per_module = max(1, len(grouped_files) // module_count)\n        \n        for i in range(module_count):\n            start_idx = i * groups_per_module\n            end_idx = start_idx + groups_per_module if i < module_count - 1 else len(grouped_files)\n            \n            if start_idx >= len(grouped_files):\n                break\n            \n            module_groups = grouped_files[start_idx:end_idx]\n            module = self._create_single_module(module_groups, i, analysis)\n            modules.append(module)\n        \n        return modules\n    \n    def _create_single_module(\n        self,\n        file_groups: List[List[Tuple[str, float, FileAnalysis]]],\n        order: int,\n        analysis: CodebaseAnalysis\n    ) -> Module:\n        \"\"\"Create a single module from file groups.\n        \n        This method implements Requirements 1.1, 1.2, 1.3, 1.4:\n        - Groups lessons by patterns\n        - Calculates module duration and difficulty\n        - Generates module learning objectives\n        \"\"\"\n        # Flatten groups into single list\n        all_files = [item for group in file_groups for item in group]\n        \n        # Create lessons with pattern grouping (Req 1.4)\n        lessons = []\n        for idx, (file_path, teaching_value, file_analysis) in enumerate(all_files):\n            lesson = self._create_basic_lesson(\n                file_path, teaching_value, file_analysis, idx\n            )\n            lessons.append(lesson)\n        \n        # Calculate module difficulty (Req 1.1)\n        difficulty = self._calculate_module_difficulty(lessons)\n        \n        # Calculate module duration (Req 1.3)\n        duration_hours = sum(l.duration_minutes for l in lessons) / 60.0\n        \n        # Generate module title and description\n        title = self._generate_module_title(file_groups, order)\n        description = self._generate_module_description(lessons)\n        \n        # Generate module learning objectives (Req 1.4)\n        learning_objectives = self._generate_module_objectives(lessons, file_groups)\n        \n        return Module(\n            module_id=str(uuid.uuid4()),\n            title=title,\n            description=description,\n            order=order,\n            lessons=lessons,\n            difficulty=difficulty,\n            duration_hours=duration_hours,\n            learning_objectives=learning_objectives\n        )\n    \n    def _generate_module_objectives(\n        self,\n        lessons: List[Lesson],\n        file_groups: List[List[Tuple[str, float, FileAnalysis]]]\n    ) -> List[str]:\n        \"\"\"Generate learning objectives for a module.\n        \n        Implements Requirement 1.4: Generate module learning objectives.\n        \"\"\"\n        objectives = []\n        \n        # Collect all patterns from the module\n        pattern_counts: Dict[str, int] = defaultdict(int)\n        for group in file_groups:\n            for _, _, file_analysis in group:\n                for pattern in file_analysis.patterns:\n                    pattern_counts[pattern.pattern_type] += 1\n        \n        # Create objectives for top patterns\n        top_patterns = sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n        for pattern_type, _ in top_patterns:\n            pattern_name = pattern_type.replace('_', ' ')\n            objectives.append(f\"Master {pattern_name} patterns\")\n        \n        # Add objective based on module difficulty\n        difficulty = self._calculate_module_difficulty(lessons)\n        if difficulty == \"beginner\":\n            objectives.append(\"Build foundational programming skills\")\n        elif difficulty == \"intermediate\":\n            objectives.append(\"Apply intermediate programming concepts\")\n        else:\n            objectives.append(\"Implement advanced programming techniques\")\n        \n        # Add objective based on lesson count\n        if len(lessons) > 5:\n            objectives.append(\"Integrate multiple concepts into cohesive solutions\")\n        \n        return objectives if objectives else [\"Learn core programming concepts\"]\n    \n    def _create_basic_lesson(\n        self,\n        file_path: str,\n        teaching_value: float,\n        file_analysis: FileAnalysis,\n        order: int\n    ) -> Lesson:\n        \"\"\"Create a basic lesson structure (full implementation in Task 2.2).\"\"\"\n        # Calculate difficulty from complexity\n        difficulty = self._calculate_lesson_difficulty(file_analysis)\n        \n        # Estimate duration based on complexity\n        duration = self._estimate_lesson_duration(file_analysis)\n        \n        # Generate title from file path\n        title = self._generate_lesson_title(file_path, file_analysis)\n        \n        # Generate description\n        description = self._generate_lesson_description(file_analysis)\n        \n        # Extract concepts from patterns\n        concepts = [p.pattern_type for p in file_analysis.patterns]\n        \n        # Generate basic learning objectives\n        learning_objectives = self._generate_basic_objectives(file_analysis)\n        \n        lesson = Lesson(\n            lesson_id=str(uuid.uuid4()),\n            title=title,\n            description=description,\n            order=order,\n            difficulty=difficulty,\n            duration_minutes=duration,\n            file_path=file_path,\n            teaching_value=teaching_value,\n            learning_objectives=learning_objectives,\n            prerequisites=[],  # Will be populated in Task 2.3\n            concepts=concepts,\n            content=None,  # Will be populated in Task 3\n            exercises=[],  # Will be populated in Task 4\n            tags=concepts\n        )\n        \n        # Apply audience-based adjustments (Task 13.2)\n        lesson = self.adjust_content_complexity(lesson)\n        \n        return lesson\n    \n    def _calculate_module_difficulty(self, lessons: List[Lesson]) -> str:\n        \"\"\"Calculate overall module difficulty from lessons.\"\"\"\n        if not lessons:\n            return \"beginner\"\n        \n        difficulty_counts = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        for lesson in lessons:\n            difficulty_counts[lesson.difficulty] += 1\n        \n        # Return the most common difficulty\n        return max(difficulty_counts.items(), key=lambda x: x[1])[0]\n    \n    def _calculate_lesson_difficulty(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Calculate lesson difficulty from complexity metrics.\"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n    \n    def _estimate_lesson_duration(self, file_analysis: FileAnalysis) -> int:\n        \"\"\"Estimate lesson duration in minutes based on complexity.\"\"\"\n        # Base duration\n        base_duration = 20\n        \n        # Add time based on number of functions/classes\n        num_symbols = (\n            len(file_analysis.symbol_info.functions) +\n            len(file_analysis.symbol_info.classes)\n        )\n        symbol_time = min(num_symbols * 5, 30)\n        \n        # Add time based on patterns\n        pattern_time = min(len(file_analysis.patterns) * 5, 20)\n        \n        total = base_duration + symbol_time + pattern_time\n        \n        # Clamp to config range\n        return max(\n            self.config.min_lesson_duration,\n            min(self.config.max_lesson_duration, total)\n        )\n    \n    def _generate_lesson_title(self, file_path: str, file_analysis: FileAnalysis) -> str:\n        \"\"\"Generate a lesson title from file path and analysis.\"\"\"\n        # Get filename without extension\n        import os\n        filename = os.path.splitext(os.path.basename(file_path))[0]\n        \n        # Convert snake_case or kebab-case to Title Case\n        title = filename.replace('_', ' ').replace('-', ' ').title()\n        \n        # Add pattern context if available\n        if file_analysis.patterns:\n            primary_pattern = max(file_analysis.patterns, key=lambda p: p.confidence)\n            pattern_name = primary_pattern.pattern_type.replace('_', ' ').title()\n            title = f\"{title}: {pattern_name}\"\n        \n        return title\n    \n    def _generate_lesson_description(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Generate a lesson description from analysis.\"\"\"\n        parts = []\n        \n        # Add teaching value explanation\n        if file_analysis.teaching_value.explanation:\n            parts.append(file_analysis.teaching_value.explanation)\n        \n        # Add pattern information\n        if file_analysis.patterns:\n            pattern_types = [p.pattern_type for p in file_analysis.patterns]\n            parts.append(f\"Demonstrates: {', '.join(pattern_types)}\")\n        \n        return \" \".join(parts) if parts else \"Learn from this code example.\"\n    \n    def _generate_basic_objectives(self, file_analysis: FileAnalysis) -> List[str]:\n        \"\"\"Generate basic learning objectives from file analysis.\"\"\"\n        objectives = []\n        \n        # Add objectives based on patterns\n        for pattern in file_analysis.patterns[:3]:  # Top 3 patterns\n            pattern_name = pattern.pattern_type.replace('_', ' ')\n            objectives.append(f\"Understand {pattern_name} pattern\")\n        \n        # Add objective based on complexity\n        if file_analysis.complexity_metrics.avg_complexity > 5:\n            objectives.append(\"Analyze complex code structure\")\n        \n        # Add objective based on documentation\n        if file_analysis.documentation_coverage > 0.7:\n            objectives.append(\"Learn documentation best practices\")\n        \n        return objectives if objectives else [\"Understand the code structure\"]\n    \n    def _generate_module_title(\n        self,\n        file_groups: List[List[Tuple[str, float, FileAnalysis]]],\n        order: int\n    ) -> str:\n        \"\"\"Generate a module title from file groups.\"\"\"\n        # Get most common pattern across all files\n        pattern_counts: Dict[str, int] = defaultdict(int)\n        \n        for group in file_groups:\n            for _, _, file_analysis in group:\n                for pattern in file_analysis.patterns:\n                    pattern_counts[pattern.pattern_type] += 1\n        \n        if pattern_counts:\n            primary_pattern = max(pattern_counts.items(), key=lambda x: x[1])[0]\n            pattern_name = primary_pattern.replace('_', ' ').title()\n            return f\"Module {order + 1}: {pattern_name}\"\n        \n        return f\"Module {order + 1}: Core Concepts\"\n    \n    def _generate_module_description(self, lessons: List[Lesson]) -> str:\n        \"\"\"Generate a module description from lessons.\"\"\"\n        if not lessons:\n            return \"Learn core programming concepts.\"\n        \n        # Collect unique concepts\n        concepts = set()\n        for lesson in lessons:\n            concepts.update(lesson.concepts)\n        \n        if concepts:\n            concept_list = ', '.join(list(concepts)[:5])\n            return f\"This module covers: {concept_list}\"\n        \n        return f\"This module contains {len(lessons)} lessons.\"\n    \n    def _calculate_difficulty_distribution(self, modules: List[Module]) -> Dict[str, int]:\n        \"\"\"Calculate distribution of difficulty levels across all lessons.\"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        \n        for module in modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n        \n        return distribution\n    \n    def _generate_course_title(self, analysis: CodebaseAnalysis) -> str:\n        \"\"\"Generate a course title from codebase analysis.\"\"\"\n        # Use codebase_id as base\n        base_name = analysis.codebase_id.replace('_', ' ').replace('-', ' ').title()\n        return f\"Learn {base_name}\"\n    \n    def _generate_course_description(\n        self,\n        analysis: CodebaseAnalysis,\n        modules: List[Module]\n    ) -> str:\n        \"\"\"Generate a course description.\"\"\"\n        parts = [\n            f\"A comprehensive course with {len(modules)} modules\",\n            f\"covering {analysis.metrics.total_files} files\",\n            f\"and {analysis.metrics.total_patterns_detected} patterns.\"\n        ]\n        return \" \".join(parts)\n    \n    def _generate_course_tags(self, analysis: CodebaseAnalysis) -> List[str]:\n        \"\"\"Generate course tags from analysis.\"\"\"\n        tags = set()\n        \n        # Add pattern types as tags\n        for pattern in analysis.global_patterns[:10]:  # Top 10 patterns\n            tags.add(pattern.pattern_type)\n        \n        return list(tags)\n    \n    # ========== Task 2.3: Learning Progression Logic ==========\n    \n    def _apply_learning_progression(\n        self,\n        modules: List[Module],\n        analysis: CodebaseAnalysis\n    ) -> List[Module]:\n        \"\"\"Apply learning progression logic to modules and lessons.\n        \n        This method implements Requirements 6.1, 6.2, 6.3, 6.4, 6.5:\n        - Places beginner lessons before intermediate and advanced\n        - Identifies prerequisites from imports\n        - Lists prerequisite lessons in metadata\n        - Ensures prerequisite lessons appear before dependent lessons\n        - Uses complexity metrics for difficulty calculation\n        \n        Args:\n            modules: List of modules with lessons\n            analysis: Codebase analysis results\n            \n        Returns:\n            Modules with updated lesson ordering and prerequisites\n        \"\"\"\n        # Build a map of file_path -> lesson for quick lookup\n        file_to_lesson: Dict[str, Lesson] = {}\n        all_lessons: List[Lesson] = []\n        \n        for module in modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n                all_lessons.append(lesson)\n        \n        # Detect prerequisites for each lesson (Req 6.2, 6.3)\n        for lesson in all_lessons:\n            prerequisites = self._detect_prerequisites(\n                lesson, file_to_lesson, analysis\n            )\n            lesson.prerequisites = prerequisites\n        \n        # Sort lessons within each module by prerequisites (Req 6.4)\n        for module in modules:\n            module.lessons = self._sort_lessons_by_prerequisites(module.lessons)\n            # Update lesson order after sorting\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n        \n        return modules\n    \n    def _detect_prerequisites(\n        self,\n        lesson: Lesson,\n        file_to_lesson: Dict[str, Lesson],\n        analysis: CodebaseAnalysis\n    ) -> List[str]:\n        \"\"\"Detect prerequisite lessons based on imports and dependencies.\n        \n        Implements Requirements 6.2, 6.3:\n        - Analyzes lesson dependencies based on code imports\n        - Lists prerequisite lessons in metadata\n        \n        Args:\n            lesson: The lesson to analyze\n            file_to_lesson: Map of file paths to lessons\n            analysis: Codebase analysis results\n            \n        Returns:\n            List of prerequisite lesson IDs\n        \"\"\"\n        prerequisites = []\n        \n        # Get file analysis for this lesson\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            return prerequisites\n        \n        # Check imports to find dependencies\n        for import_info in file_analysis.symbol_info.imports:\n            # Skip external imports\n            if import_info.is_relative or self._is_internal_import(\n                import_info.module, analysis\n            ):\n                # Try to find the imported file in our lessons\n                imported_file = self._resolve_import_to_file(\n                    import_info.module, lesson.file_path, analysis\n                )\n                \n                if imported_file and imported_file in file_to_lesson:\n                    prereq_lesson = file_to_lesson[imported_file]\n                    # Only add if it's a different lesson and simpler\n                    if (prereq_lesson.lesson_id != lesson.lesson_id and\n                        self._is_simpler_lesson(prereq_lesson, lesson)):\n                        prerequisites.append(prereq_lesson.lesson_id)\n        \n        # Also check dependency graph\n        if lesson.file_path in analysis.dependency_graph.nodes:\n            node = analysis.dependency_graph.nodes[lesson.file_path]\n            for imported_file in node.imports:\n                if imported_file in file_to_lesson:\n                    prereq_lesson = file_to_lesson[imported_file]\n                    if (prereq_lesson.lesson_id != lesson.lesson_id and\n                        prereq_lesson.lesson_id not in prerequisites and\n                        self._is_simpler_lesson(prereq_lesson, lesson)):\n                        prerequisites.append(prereq_lesson.lesson_id)\n        \n        return prerequisites\n    \n    def _is_internal_import(self, module: str, analysis: CodebaseAnalysis) -> bool:\n        \"\"\"Check if an import is internal to the codebase.\"\"\"\n        # Check if any file path contains the module name\n        for file_path in analysis.file_analyses.keys():\n            if module.replace('.', '/') in file_path or module.replace('.', '\\\\') in file_path:\n                return True\n        return False\n    \n    def _resolve_import_to_file(\n        self,\n        module: str,\n        current_file: str,\n        analysis: CodebaseAnalysis\n    ) -> str:\n        \"\"\"Resolve an import statement to an actual file path.\"\"\"\n        # Try to find matching file in analysis\n        module_parts = module.replace('.', '/').split('/')\n        \n        for file_path in analysis.file_analyses.keys():\n            # Check if file path ends with module path\n            for i in range(len(module_parts)):\n                partial_path = '/'.join(module_parts[i:])\n                if partial_path in file_path.replace('\\\\', '/'):\n                    return file_path\n        \n        return \"\"\n    \n    def _is_simpler_lesson(self, lesson1: Lesson, lesson2: Lesson) -> bool:\n        \"\"\"Check if lesson1 is simpler than lesson2.\n        \n        Implements Requirement 6.5: Uses complexity metrics for difficulty calculation.\n        \"\"\"\n        difficulty_order = {\"beginner\": 0, \"intermediate\": 1, \"advanced\": 2}\n        \n        diff1 = difficulty_order.get(lesson1.difficulty, 1)\n        diff2 = difficulty_order.get(lesson2.difficulty, 1)\n        \n        if diff1 < diff2:\n            return True\n        elif diff1 == diff2:\n            # If same difficulty, use teaching value (higher = simpler/better starting point)\n            return lesson1.teaching_value > lesson2.teaching_value\n        \n        return False\n    \n    def _sort_lessons_by_prerequisites(self, lessons: List[Lesson]) -> List[Lesson]:\n        \"\"\"Sort lessons so prerequisites appear before dependent lessons.\n        \n        Implements Requirements 6.1, 6.4:\n        - Places beginner lessons before intermediate and advanced\n        - Ensures prerequisite lessons appear before dependent lessons\n        \n        Uses topological sort to handle dependencies.\n        \"\"\"\n        # Build dependency graph\n        lesson_map = {lesson.lesson_id: lesson for lesson in lessons}\n        in_degree = {lesson.lesson_id: 0 for lesson in lessons}\n        adjacency = {lesson.lesson_id: [] for lesson in lessons}\n        \n        for lesson in lessons:",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 67 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: import os"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (17 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "68f9d7da-c11d-4b7b-9ad1-1208d8ae0727",
          "title": "Dependency Analyzer: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.78). Well-documented (100% coverage). Ideal complexity (avg: 3.4) for teaching. Contains some patterns. Well-structured code. Demonstrates: python_comprehensions",
          "order": 2,
          "difficulty": "beginner",
          "duration_minutes": 60,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\dependency_analyzer.py",
          "teaching_value": 0.78,
          "learning_objectives": [
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "d3f4178d-f612-46f1-9b20-c1c27fd92b85",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\dependency_analyzer.py",
              "difficulty": "beginner",
              "estimated_minutes": 35,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (8 occurrences)"
              ],
              "starter_code": "\"\"\"Convert to dictionary for JSON serialization.\"\"\"\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'DependencyGraph':\n        \"\"\"Create from dictionary.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n\n\nclass DependencyAnalyzer:\n    \"\"\"\n    \n    \"\"\"\n    \n    def __init__(self, project_root: Optional[str] = None):\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \"\"\"\n    \n    def analyze_dependencies(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \n        \"\"\"\n        \n        \n        # Build nodes and extract imports\n            \n            # Extract imports from symbol info\n                # Categorize as internal or external\n                \n                    # Internal dependency\n                    # External dependency\n                    \n                    # Track external dependency usage\n            \n        \n        # Build edges and reverse relationships\n                # Add edge\n                \n                # Update imported_by relationship\n        \n        # Detect circular dependencies\n        \n        \n    \n    def _resolve_import_path(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \"\"\"\n        \n        # Handle relative imports\n        \n        # Handle absolute imports\n    \n    def _resolve_relative_import(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \n        \"\"\"\n        \n        # Count leading dots\n        \n        # Remove leading dots\n        \n        # Go up directory tree based on dot count\n        \n        # Try to find the module file\n            # from .module import x\n            # from . import x (imports from __init__.py)\n        \n        # Check which path exists in file_analyses\n        \n    \n    def _resolve_absolute_import(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n        \n        \"\"\"\n        # Convert module path to file path\n        # e.g., \"src.utils.helpers\" -> \"src/utils/helpers.py\"\n        \n        # Try different file extensions and patterns\n        \n        # Check if any analyzed file matches\n            \n        \n        # Not found in analyzed files - likely external dependency\n    \n    def _get_package_name(self, module: str) -> str:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n        \n        \"\"\"\n        # Handle scoped packages (@org/package)\n        \n        # Regular packages\n    \n    def _detect_circular_dependencies(self, graph: DependencyGraph) -> List[CircularDependency]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n        \n        \"\"\"\n        \n        \n        def dfs(node_path: str) -> bool:\n            \"\"\"\n            # TODO: Implement python_comprehensions logic here\n            pass\n            \n            \"\"\"\n            \n            # Check all dependencies\n                        # Cycle detected!\n                        \n                        \n            \n        \n        # Run DFS from each unvisited node\n        \n        \n    \n    def get_dependency_metrics(self, graph: DependencyGraph) -> Dict[str, Any]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n        \"\"\"\n        \n        # Calculate average dependencies per file\n        \n        # Find most imported files\n        \n        # Find files with most imports",
              "solution_code": "\"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        return {\n            'nodes': {k: v.to_dict() for k, v in self.nodes.items()},\n            'edges': [e.to_dict() for e in self.edges],\n            'circular_dependencies': [c.to_dict() for c in self.circular_dependencies],\n            'external_dependencies': self.external_dependencies\n        }\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'DependencyGraph':\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            nodes={k: FileNode(**v) if isinstance(v, dict) else v \n                  for k, v in data.get('nodes', {}).items()},\n            edges=[DependencyEdge(**e) if isinstance(e, dict) else e \n                  for e in data.get('edges', [])],\n            circular_dependencies=[CircularDependency(**c) if isinstance(c, dict) else c \n                                  for c in data.get('circular_dependencies', [])],\n            external_dependencies=data.get('external_dependencies', {})\n        )\n\n\nclass DependencyAnalyzer:\n    \"\"\"\n    Analyzes dependencies between files and builds dependency graphs.\n    \n    Supports Python and JavaScript/TypeScript import statements.\n    Detects circular dependencies and categorizes internal vs external dependencies.\n    \"\"\"\n    \n    def __init__(self, project_root: Optional[str] = None):\n        \"\"\"\n        Initialize the Dependency Analyzer.\n        \n        Args:\n            project_root: Root directory of the project (for resolving relative imports)\n        \"\"\"\n        self.project_root = Path(project_root) if project_root else Path.cwd()\n        logger.debug(f\"DependencyAnalyzer initialized with project_root: {self.project_root}\")\n    \n    def analyze_dependencies(\n        self, \n        codebase_id: str, \n        file_analyses: Dict[str, Any]\n    ) -> DependencyGraph:\n        \"\"\"\n        Build dependency graph for entire codebase.\n        \n        Args:\n            codebase_id: Identifier for the codebase\n            file_analyses: Dictionary mapping file paths to FileAnalysis objects\n        \n        Returns:\n            DependencyGraph with all dependencies mapped\n        \n        Example:\n            >>> graph = analyzer.analyze_dependencies(\"my_project\", file_analyses)\n            >>> print(f\"Found {len(graph.circular_dependencies)} circular dependencies\")\n        \"\"\"\n        logger.info(f\"Analyzing dependencies for codebase: {codebase_id}\")\n        \n        graph = DependencyGraph()\n        \n        # Build nodes and extract imports\n        for file_path, file_analysis in file_analyses.items():\n            node = FileNode(file_path=file_path)\n            \n            # Extract imports from symbol info\n            symbol_info = file_analysis.symbol_info\n            for import_info in symbol_info.imports:\n                # Categorize as internal or external\n                resolved_path = self._resolve_import_path(\n                    import_info, \n                    file_path, \n                    file_analyses\n                )\n                \n                if resolved_path:\n                    # Internal dependency\n                    node.imports.append(resolved_path)\n                else:\n                    # External dependency\n                    node.external_imports.append(import_info.module)\n                    \n                    # Track external dependency usage\n                    package_name = self._get_package_name(import_info.module)\n                    graph.external_dependencies[package_name] = \\\n                        graph.external_dependencies.get(package_name, 0) + 1\n            \n            graph.nodes[file_path] = node\n        \n        # Build edges and reverse relationships\n        for file_path, node in graph.nodes.items():\n            for imported_file in node.imports:\n                # Add edge\n                edge = DependencyEdge(\n                    from_file=file_path,\n                    to_file=imported_file,\n                    import_count=1\n                )\n                graph.edges.append(edge)\n                \n                # Update imported_by relationship\n                if imported_file in graph.nodes:\n                    graph.nodes[imported_file].imported_by.append(file_path)\n        \n        # Detect circular dependencies\n        graph.circular_dependencies = self._detect_circular_dependencies(graph)\n        \n        logger.info(\n            f\"Dependency analysis complete: \"\n            f\"{len(graph.nodes)} files, \"\n            f\"{len(graph.edges)} edges, \"\n            f\"{len(graph.circular_dependencies)} circular dependencies, \"\n            f\"{len(graph.external_dependencies)} external packages\"\n        )\n        \n        return graph\n    \n    def _resolve_import_path(\n        self, \n        import_info: ImportInfo, \n        source_file: str,\n        file_analyses: Dict[str, Any]\n    ) -> Optional[str]:\n        \"\"\"\n        Resolve import statement to absolute file path.\n        \n        Args:\n            import_info: Import information\n            source_file: Path to file containing the import\n            file_analyses: Dictionary of all analyzed files\n        \n        Returns:\n            Absolute file path if internal import, None if external\n        \"\"\"\n        module = import_info.module\n        \n        # Handle relative imports\n        if import_info.is_relative:\n            return self._resolve_relative_import(module, source_file, file_analyses)\n        \n        # Handle absolute imports\n        return self._resolve_absolute_import(module, source_file, file_analyses)\n    \n    def _resolve_relative_import(\n        self, \n        module: str, \n        source_file: str,\n        file_analyses: Dict[str, Any]\n    ) -> Optional[str]:\n        \"\"\"\n        Resolve relative import to absolute path.\n        \n        Handles Python relative imports like:\n        - from . import module\n        - from .. import module\n        - from .submodule import function\n        \n        Args:\n            module: Module name (may start with dots)\n            source_file: Path to file containing the import\n            file_analyses: Dictionary of all analyzed files\n        \n        Returns:\n            Absolute file path if found, None otherwise\n        \"\"\"\n        source_dir = Path(source_file).parent\n        \n        # Count leading dots\n        dots = 0\n        for char in module:\n            if char == '.':\n                dots += 1\n            else:\n                break\n        \n        # Remove leading dots\n        module_name = module[dots:].strip('.')\n        \n        # Go up directory tree based on dot count\n        current_dir = source_dir\n        for _ in range(dots - 1):\n            current_dir = current_dir.parent\n        \n        # Try to find the module file\n        if module_name:\n            # from .module import x\n            possible_paths = [\n                current_dir / f\"{module_name}.py\",\n                current_dir / module_name / \"__init__.py\",\n            ]\n        else:\n            # from . import x (imports from __init__.py)\n            possible_paths = [\n                current_dir / \"__init__.py\",\n            ]\n        \n        # Check which path exists in file_analyses\n        for path in possible_paths:\n            normalized_path = str(path).replace('\\\\', '/')\n            for analyzed_file in file_analyses.keys():\n                if normalized_path in analyzed_file or analyzed_file in normalized_path:\n                    return analyzed_file\n        \n        return None\n    \n    def _resolve_absolute_import(\n        self, \n        module: str, \n        source_file: str,\n        file_analyses: Dict[str, Any]\n    ) -> Optional[str]:\n        \"\"\"\n        Resolve absolute import to file path.\n        \n        Handles imports like:\n        - import module\n        - from package.module import function\n        \n        Args:\n            module: Module name\n            source_file: Path to file containing the import\n            file_analyses: Dictionary of all analyzed files\n        \n        Returns:\n            Absolute file path if internal import, None if external\n        \"\"\"\n        # Convert module path to file path\n        # e.g., \"src.utils.helpers\" -> \"src/utils/helpers.py\"\n        module_path = module.replace('.', '/')\n        \n        # Try different file extensions and patterns\n        possible_paths = [\n            f\"{module_path}.py\",\n            f\"{module_path}.js\",\n            f\"{module_path}.ts\",\n            f\"{module_path}.tsx\",\n            f\"{module_path}.jsx\",\n            f\"{module_path}/__init__.py\",\n            f\"{module_path}/index.js\",\n            f\"{module_path}/index.ts\",\n        ]\n        \n        # Check if any analyzed file matches\n        for analyzed_file in file_analyses.keys():\n            normalized_analyzed = analyzed_file.replace('\\\\', '/')\n            \n            for possible_path in possible_paths:\n                if possible_path in normalized_analyzed or normalized_analyzed.endswith(possible_path):\n                    return analyzed_file\n        \n        # Not found in analyzed files - likely external dependency\n        return None\n    \n    def _get_package_name(self, module: str) -> str:\n        \"\"\"\n        Extract package name from module path.\n        \n        Examples:\n            \"numpy.array\" -> \"numpy\"\n            \"react\" -> \"react\"\n            \"@types/node\" -> \"@types/node\"\n        \n        Args:\n            module: Full module path\n        \n        Returns:\n            Package name\n        \"\"\"\n        # Handle scoped packages (@org/package)\n        if module.startswith('@'):\n            parts = module.split('/')\n            if len(parts) >= 2:\n                return f\"{parts[0]}/{parts[1]}\"\n            return module\n        \n        # Regular packages\n        return module.split('.')[0].split('/')[0]\n    \n    def _detect_circular_dependencies(self, graph: DependencyGraph) -> List[CircularDependency]:\n        \"\"\"\n        Detect circular dependencies using depth-first search.\n        \n        Uses DFS with a recursion stack to detect cycles in the dependency graph.\n        \n        Args:\n            graph: Dependency graph to analyze\n        \n        Returns:\n            List of detected circular dependencies\n        \"\"\"\n        logger.debug(\"Detecting circular dependencies...\")\n        \n        circular_deps = []\n        visited: Set[str] = set()\n        rec_stack: Set[str] = set()\n        path: List[str] = []\n        \n        def dfs(node_path: str) -> bool:\n            \"\"\"\n            Depth-first search to detect cycles.\n            \n            Returns True if cycle detected.\n            \"\"\"\n            visited.add(node_path)\n            rec_stack.add(node_path)\n            path.append(node_path)\n            \n            # Check all dependencies\n            node = graph.nodes.get(node_path)\n            if node:\n                for imported_file in node.imports:\n                    if imported_file not in visited:\n                        if dfs(imported_file):\n                            return True\n                    elif imported_file in rec_stack:\n                        # Cycle detected!\n                        cycle_start = path.index(imported_file)\n                        cycle = path[cycle_start:] + [imported_file]\n                        \n                        circular_deps.append(CircularDependency(\n                            cycle=cycle,\n                            severity='warning'\n                        ))\n                        \n                        logger.warning(f\"Circular dependency detected: {' -> '.join(cycle)}\")\n                        return True\n            \n            path.pop()\n            rec_stack.remove(node_path)\n            return False\n        \n        # Run DFS from each unvisited node\n        for node_path in graph.nodes.keys():\n            if node_path not in visited:\n                dfs(node_path)\n        \n        logger.debug(f\"Found {len(circular_deps)} circular dependencies\")\n        \n        return circular_deps\n    \n    def get_dependency_metrics(self, graph: DependencyGraph) -> Dict[str, Any]:\n        \"\"\"\n        Calculate dependency metrics for the graph.\n        \n        Args:\n            graph: Dependency graph\n        \n        Returns:\n            Dictionary of metrics\n        \"\"\"\n        total_files = len(graph.nodes)\n        total_edges = len(graph.edges)\n        total_external = len(graph.external_dependencies)\n        total_circular = len(graph.circular_dependencies)\n        \n        # Calculate average dependencies per file\n        if total_files > 0:\n            avg_imports = sum(len(node.imports) for node in graph.nodes.values()) / total_files\n            avg_imported_by = sum(len(node.imported_by) for node in graph.nodes.values()) / total_files\n        else:\n            avg_imports = 0\n            avg_imported_by = 0\n        \n        # Find most imported files\n        most_imported = sorted(\n            [(path, len(node.imported_by)) for path, node in graph.nodes.items()],\n            key=lambda x: x[1],\n            reverse=True\n        )[:10]\n        \n        # Find files with most imports\n        most_imports = sorted(\n            [(path, len(node.imports)) for path, node in graph.nodes.items()],\n            key=lambda x: x[1],\n            reverse=True",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 27 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: import_info,"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (8 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "e2f21812-485c-46c3-a1fb-a0a793397543",
          "title": "Content Validator: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.78). Well-documented (100% coverage). Ideal complexity (avg: 4.7) for teaching. Contains some patterns. Well-structured code. Demonstrates: python_comprehensions",
          "order": 3,
          "difficulty": "beginner",
          "duration_minutes": 48,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\content_validator.py",
          "teaching_value": 0.78,
          "learning_objectives": [
            "Understand python comprehensions pattern",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_comprehensions"
          ],
          "exercises": [],
          "tags": [
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "a8165823-8d7b-462c-a392-9e18692148c9",
          "title": "Content Generator: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.82). Well-documented (100% coverage). Ideal complexity (avg: 5.3) for teaching. Contains useful patterns. Reasonable structure. Demonstrates: python_context_managers, python_async_await, python_comprehensions",
          "order": 4,
          "difficulty": "intermediate",
          "duration_minutes": 48,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\content_generator.py",
          "teaching_value": 0.82,
          "learning_objectives": [
            "Understand python context managers pattern",
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "43ebb55a-e4a0-4ef2-913d-fdcb36e8d284",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\content_generator.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (15 occurrences)"
              ],
              "starter_code": "# Generate objectives from patterns\n        \n        # Generate objectives from functions/classes\n            # Focus on most complex function\n        \n        # Add objective based on complexity\n        \n        # Add objective based on documentation\n        \n        # Ensure we have 3-5 objectives (Req 2.2)\n        \n        # Limit to 5 objectives\n    \n    def generate_introduction(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate lesson introduction.\n        \n        \n            \n        \"\"\"\n        \n        # Start with teaching value explanation if available\n        \n        # Add context about what patterns are demonstrated\n        \n        # Add what students will be able to do\n        \n\n    \n    def generate_explanation(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Generate explanation of the code and concepts.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Add audience-appropriate introduction (Task 13.2)\n        \n        # Explain the overall purpose\n            # Skip redundant header for non-beginners\n        \n            # Explain class-based code\n                    # Use first sentence of docstring\n        \n            # Explain function-based code\n        \n        # Explain key patterns\n                \n                # Explain the pattern\n        \n        # Explain complexity if high\n            \n            \n        \n    \n    def generate_walkthrough(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate step-by-step code walkthrough.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Walk through classes\n                \n                \n                # Explain inheritance\n                \n                # Walk through methods\n                        \n                            # Use first line of docstring\n                        \n        \n        # Walk through standalone functions\n        \n                \n                \n                # Explain parameters\n                \n                # Note complexity if high\n        \n        # Add annotations from code example\n        \n    \n    def generate_summary(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Generate lesson summary.\n        \n        \n            \n        \"\"\"\n        \n        \n        # Recap objectives\n        \n        \n        # Highlight key takeaways\n        \n        # Takeaway from patterns\n        \n        # Takeaway from complexity\n        \n        # Takeaway from documentation\n        \n        # Generic takeaway\n        \n        \n        # Next steps\n        \n    \n    # ========== Helper Methods ==========\n    \n    def _read_file_content(self, file_path: str) -> str:\n        \"\"\"Read the content of a source file.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n            \n            # Limit to max_code_lines if configured (Req 7.2)\n                    # Take first max_code_lines\n            \n    \n    def _detect_language(self, file_path: str) -> str:\n        \"\"\"Detect programming language from file extension.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n            \n        \"\"\"\n        import os\n        \n        \n    \n    def _create_highlights(self, file_analysis: FileAnalysis) -> List[CodeHighlight]:\n        \"\"\"Create code highlights for important sections.\n        \n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Highlight complex functions\n            # Find the function in symbol info",
              "solution_code": "# Generate objectives from patterns\n        for pattern in patterns[:3]:  # Top 3 patterns\n            objective = self._pattern_to_objective(pattern)\n            if objective:\n                objectives.append(objective)\n        \n        # Generate objectives from functions/classes\n        if file_analysis.symbol_info.classes:\n            objectives.append(\n                f\"Implement {file_analysis.symbol_info.classes[0].name} class structure\"\n            )\n        elif file_analysis.symbol_info.functions:\n            # Focus on most complex function\n            complex_funcs = [\n                f for f in file_analysis.symbol_info.functions\n                if f.complexity > 5\n            ]\n            if complex_funcs:\n                func = complex_funcs[0]\n                objectives.append(f\"Analyze {func.name} function implementation\")\n        \n        # Add objective based on complexity\n        if file_analysis.complexity_metrics.avg_complexity > 5:\n            objectives.append(\"Apply techniques for managing code complexity\")\n        \n        # Add objective based on documentation\n        if file_analysis.documentation_coverage > 0.7:\n            objectives.append(\"Understand documentation best practices\")\n        \n        # Ensure we have 3-5 objectives (Req 2.2)\n        if len(objectives) < 3:\n            objectives.append(\"Understand the code structure and organization\")\n        if len(objectives) < 3:\n            objectives.append(\"Apply the concepts in your own projects\")\n        \n        # Limit to 5 objectives\n        return objectives[:5]\n    \n    def generate_introduction(\n        self,\n        file_analysis: FileAnalysis,\n        objectives: List[str]\n    ) -> str:\n        \"\"\"Generate lesson introduction.\n        \n        Implements Requirement 2.4: Creates introduction section.\n        \n        Args:\n            file_analysis: Analysis results for the source file\n            objectives: Learning objectives for the lesson\n            \n        Returns:\n            Introduction text in Markdown format\n        \"\"\"\n        parts = []\n        \n        # Start with teaching value explanation if available\n        if file_analysis.teaching_value.explanation:\n            parts.append(file_analysis.teaching_value.explanation)\n        else:\n            parts.append(\n                \"This lesson explores a practical code example that demonstrates \"\n                \"important programming concepts.\"\n            )\n        \n        # Add context about what patterns are demonstrated\n        if file_analysis.patterns:\n            pattern_names = [\n                p.pattern_type.replace('_', ' ').title()\n                for p in file_analysis.patterns[:3]\n            ]\n            parts.append(\n                f\"\\n\\nYou'll learn about {', '.join(pattern_names)} \"\n                f\"through hands-on code analysis.\"\n            )\n        \n        # Add what students will be able to do\n        if objectives:\n            parts.append(\n                f\"\\n\\nBy the end of this lesson, you'll be able to:\\n\"\n            )\n            for obj in objectives:\n                parts.append(f\"- {obj}\")\n        \n        return \"\".join(parts)\n\n    \n    def generate_explanation(self, file_analysis: FileAnalysis) -> str:\n        \"\"\"Generate explanation of the code and concepts.\n        \n        Implements Requirements 2.4, 7.1: Creates explanation section using\n        simple language appropriate for target difficulty level.\n        \n        Args:\n            file_analysis: Analysis results for the source file\n            \n        Returns:\n            Explanation text in Markdown format\n        \"\"\"\n        parts = []\n        \n        # Add audience-appropriate introduction (Task 13.2)\n        if self.config.target_audience == \"beginner\":\n            parts.append(\"## Understanding the Code\\n\\n\")\n            parts.append(\"Let's break down this code step by step.\\n\\n\")\n        elif self.config.target_audience == \"advanced\":\n            parts.append(\"## Technical Overview\\n\\n\")\n        else:\n            parts.append(\"## What This Code Does\\n\\n\")\n        \n        # Explain the overall purpose\n        if self.config.target_audience != \"beginner\":\n            # Skip redundant header for non-beginners\n            pass\n        else:\n            parts.append(\"### Purpose\\n\\n\")\n        \n        if file_analysis.symbol_info.classes:\n            # Explain class-based code\n            for cls in file_analysis.symbol_info.classes[:2]:  # Top 2 classes\n                parts.append(f\"The `{cls.name}` class \")\n                if cls.docstring:\n                    # Use first sentence of docstring\n                    first_sentence = cls.docstring.split('.')[0] + '.'\n                    parts.append(first_sentence.lower())\n                else:\n                    parts.append(\n                        f\"provides {len(cls.methods)} methods for \"\n                        f\"implementing its functionality.\"\n                    )\n                parts.append(\"\\n\\n\")\n        \n        elif file_analysis.symbol_info.functions:\n            # Explain function-based code\n            parts.append(\"This file contains several functions:\\n\\n\")\n            for func in file_analysis.symbol_info.functions[:3]:  # Top 3 functions\n                parts.append(f\"- **{func.name}**: \")\n                if func.docstring:\n                    first_sentence = func.docstring.split('.')[0] + '.'\n                    parts.append(first_sentence)\n                else:\n                    parts.append(f\"Takes {len(func.parameters)} parameter(s)\")\n                parts.append(\"\\n\")\n        \n        # Explain key patterns\n        if file_analysis.patterns:\n            parts.append(\"\\n## Key Patterns\\n\\n\")\n            for pattern in file_analysis.patterns[:3]:\n                pattern_name = pattern.pattern_type.replace('_', ' ').title()\n                parts.append(f\"### {pattern_name}\\n\\n\")\n                \n                # Explain the pattern\n                pattern_explanation = self._explain_pattern(pattern)\n                parts.append(pattern_explanation)\n                parts.append(\"\\n\\n\")\n        \n        # Explain complexity if high\n        if file_analysis.complexity_metrics.avg_complexity > 5:\n            parts.append(\"## Complexity Considerations\\n\\n\")\n            parts.append(\n                f\"This code has an average complexity of \"\n                f\"{file_analysis.complexity_metrics.avg_complexity:.1f}. \"\n            )\n            \n            if file_analysis.complexity_metrics.high_complexity_functions:\n                parts.append(\n                    f\"The most complex functions are: \"\n                    f\"{', '.join(file_analysis.complexity_metrics.high_complexity_functions[:3])}. \"\n                )\n            \n            parts.append(\n                \"Pay special attention to how the code manages this complexity \"\n                \"through clear structure and organization.\\n\\n\"\n            )\n        \n        return \"\".join(parts)\n    \n    def generate_walkthrough(\n        self,\n        code_example: CodeExample,\n        file_analysis: FileAnalysis\n    ) -> str:\n        \"\"\"Generate step-by-step code walkthrough.\n        \n        Implements Requirements 2.3, 2.4: Creates walkthrough with code annotations.\n        \n        Args:\n            code_example: The code example to walk through\n            file_analysis: Analysis results for the source file\n            \n        Returns:\n            Walkthrough text in Markdown format\n        \"\"\"\n        parts = []\n        \n        parts.append(\"## Code Walkthrough\\n\\n\")\n        parts.append(\"Let's walk through the code step by step:\\n\\n\")\n        \n        # Walk through classes\n        if file_analysis.symbol_info.classes:\n            for cls in file_analysis.symbol_info.classes:\n                parts.append(f\"### {cls.name} Class\\n\\n\")\n                \n                if cls.docstring:\n                    parts.append(f\"{cls.docstring}\\n\\n\")\n                \n                # Explain inheritance\n                if cls.base_classes:\n                    parts.append(\n                        f\"This class inherits from: {', '.join(cls.base_classes)}\\n\\n\"\n                    )\n                \n                # Walk through methods\n                if cls.methods:\n                    parts.append(\"**Key Methods:**\\n\\n\")\n                    for method in cls.methods[:5]:  # Top 5 methods\n                        parts.append(f\"- `{method.name}(\")\n                        parts.append(\", \".join(method.parameters))\n                        parts.append(\")`\")\n                        \n                        if method.docstring:\n                            # Use first line of docstring\n                            first_line = method.docstring.split('\\n')[0]\n                            parts.append(f\": {first_line}\")\n                        \n                        parts.append(\"\\n\")\n                    parts.append(\"\\n\")\n        \n        # Walk through standalone functions\n        standalone_funcs = [\n            f for f in file_analysis.symbol_info.functions\n            if not any(f in cls.methods for cls in file_analysis.symbol_info.classes)\n        ]\n        \n        if standalone_funcs:\n            parts.append(\"### Functions\\n\\n\")\n            for func in standalone_funcs[:5]:  # Top 5 functions\n                parts.append(f\"**{func.name}**\\n\\n\")\n                \n                if func.docstring:\n                    parts.append(f\"{func.docstring}\\n\\n\")\n                \n                # Explain parameters\n                if func.parameters:\n                    parts.append(\"Parameters:\\n\")\n                    for param in func.parameters:\n                        parts.append(f\"- `{param}`\\n\")\n                    parts.append(\"\\n\")\n                \n                # Note complexity if high\n                if func.complexity > 5:\n                    parts.append(\n                        f\"*Note: This function has complexity {func.complexity}, \"\n                        f\"so pay attention to its control flow.*\\n\\n\"\n                    )\n        \n        # Add annotations from code example\n        if code_example.annotations:\n            parts.append(\"### Important Code Sections\\n\\n\")\n            for line_num, annotation in sorted(code_example.annotations.items())[:5]:\n                parts.append(f\"**Line {line_num}**: {annotation}\\n\\n\")\n        \n        return \"\".join(parts)\n    \n    def generate_summary(\n        self,\n        objectives: List[str],\n        file_analysis: FileAnalysis\n    ) -> str:\n        \"\"\"Generate lesson summary.\n        \n        Implements Requirement 2.4: Creates summary section for lesson recap.\n        \n        Args:\n            objectives: Learning objectives for the lesson\n            file_analysis: Analysis results for the source file\n            \n        Returns:\n            Summary text in Markdown format\n        \"\"\"\n        parts = []\n        \n        parts.append(\"## Summary\\n\\n\")\n        parts.append(\"In this lesson, you learned:\\n\\n\")\n        \n        # Recap objectives\n        for obj in objectives:\n            parts.append(f\"- {obj}\\n\")\n        \n        parts.append(\"\\n\")\n        \n        # Highlight key takeaways\n        parts.append(\"### Key Takeaways\\n\\n\")\n        \n        # Takeaway from patterns\n        if file_analysis.patterns:\n            pattern_names = [\n                p.pattern_type.replace('_', ' ')\n                for p in file_analysis.patterns[:2]\n            ]\n            parts.append(\n                f\"- Understanding {' and '.join(pattern_names)} \"\n                f\"will help you write better code\\n\"\n            )\n        \n        # Takeaway from complexity\n        if file_analysis.complexity_metrics.avg_complexity > 5:\n            parts.append(\n                \"- Managing complexity through clear structure is essential \"\n                \"for maintainable code\\n\"\n            )\n        \n        # Takeaway from documentation\n        if file_analysis.documentation_coverage > 0.7:\n            parts.append(\n                \"- Good documentation makes code easier to understand and maintain\\n\"\n            )\n        \n        # Generic takeaway\n        parts.append(\n            \"- Practice implementing these concepts in your own projects\\n\"\n        )\n        \n        parts.append(\"\\n\")\n        \n        # Next steps\n        parts.append(\"### Next Steps\\n\\n\")\n        parts.append(\n            \"Try modifying the code to experiment with different approaches. \"\n            \"Complete the exercises to reinforce your understanding.\\n\"\n        )\n        \n        return \"\".join(parts)\n    \n    # ========== Helper Methods ==========\n    \n    def _read_file_content(self, file_path: str) -> str:\n        \"\"\"Read the content of a source file.\n        \n        Args:\n            file_path: Path to the source file\n            \n        Returns:\n            File content as string\n        \"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n            \n            # Limit to max_code_lines if configured (Req 7.2)\n            if self.config.max_code_lines:\n                lines = content.split('\\n')\n                if len(lines) > self.config.max_code_lines:\n                    # Take first max_code_lines\n                    content = '\\n'.join(lines[:self.config.max_code_lines])\n                    content += f\"\\n\\n# ... ({len(lines) - self.config.max_code_lines} more lines)\"\n            \n            return content\n        except Exception as e:\n            return f\"# Error reading file: {e}\"\n    \n    def _detect_language(self, file_path: str) -> str:\n        \"\"\"Detect programming language from file extension.\n        \n        Args:\n            file_path: Path to the source file\n            \n        Returns:\n            Language identifier for syntax highlighting\n        \"\"\"\n        import os\n        ext = os.path.splitext(file_path)[1].lower()\n        \n        language_map = {\n            '.py': 'python',\n            '.js': 'javascript',\n            '.ts': 'typescript',\n            '.jsx': 'jsx',\n            '.tsx': 'tsx',\n            '.java': 'java',\n            '.cpp': 'cpp',\n            '.c': 'c',\n            '.cs': 'csharp',\n            '.go': 'go',\n            '.rs': 'rust',\n            '.rb': 'ruby',\n            '.php': 'php',\n            '.swift': 'swift',\n            '.kt': 'kotlin',\n            '.scala': 'scala',\n            '.html': 'html',\n            '.css': 'css',\n            '.sql': 'sql',\n            '.sh': 'bash',\n            '.yaml': 'yaml',\n            '.yml': 'yaml',\n            '.json': 'json',\n            '.xml': 'xml',\n            '.md': 'markdown',\n        }\n        \n        return language_map.get(ext, 'text')\n    \n    def _create_highlights(self, file_analysis: FileAnalysis) -> List[CodeHighlight]:\n        \"\"\"Create code highlights for important sections.\n        \n        Implements Requirement 7.2: Creates code highlights for important sections.\n        \n        Args:\n            file_analysis: Analysis results for the source file\n            \n        Returns:\n            List of CodeHighlight objects\n        \"\"\"\n        highlights = []\n        \n        # Highlight complex functions\n        for func in file_analysis.complexity_metrics.high_complexity_functions[:3]:\n            # Find the function in symbol info\n            func_info = next(",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 18 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: import os"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (15 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "python_context_managers",
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "505dcd77-413a-44d8-bbf4-a699fd4c3240",
          "title": "Code Section Guide Generator: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.80). Well-documented (100% coverage). Slightly complex (avg complexity: 9.0). Contains useful patterns. Reasonable structure. Demonstrates: password_hashing, python_generators, python_async_await, python_comprehensions",
          "order": 5,
          "difficulty": "intermediate",
          "duration_minutes": 54,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\code_section_guide_generator.py",
          "teaching_value": 0.795,
          "learning_objectives": [
            "Understand password hashing pattern",
            "Understand python generators pattern",
            "Understand python async await pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "password_hashing",
            "python_generators",
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "40045591-4b39-4444-a27f-b8b0afd95d91",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\code_section_guide_generator.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (8 occurrences)"
              ],
              "starter_code": "# Add test evidence if available\n        \n    \n    def extract_key_concepts(self, code: CodeExample) -> List[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Language-specific concepts\n        \n        # Common patterns across languages\n        \n        \n        \n        \n        \n        \n        \n        \n        # Data structure concepts\n        \n        \n        # API and web concepts\n        \n        \n        # Database concepts\n        \n        # Return unique concepts\n    \n    def suggest_explanation_approach(self, code: CodeExample) -> List[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n            \n        \"\"\"\n        \n        # Step 1: Start with the big picture\n        \n        # Step 2: Explain the structure\n        \n        # Step 3: Dive into specific patterns\n        \n        \n        \n        # Step 4: Highlight important details\n        \n        \n        # Step 5: Connect to broader context\n        \n        # Step 6: Discuss edge cases and best practices\n        \n    \n    def find_related_code(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n            \n        \"\"\"\n        \n        # Extract imports/dependencies from the code\n        \n        # Find related files from dependencies\n            # Check if this dependency is imported in the code\n        \n        # Find files that depend on this code\n        \n        # Look for related files in source_files\n                # Check if files are in the same directory (likely related)\n        \n    \n    def identify_common_mistakes(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n            \n        \"\"\"\n        \n        # Analyze test descriptions for common pitfalls\n            \n            # Look for negative test cases\n        \n        # Common Python mistakes\n            \n            \n        \n        # Common JavaScript/TypeScript mistakes\n            \n        \n        # Async/await mistakes\n            \n        \n        # Error handling mistakes\n        \n        # Security-related mistakes\n        \n        \n    \n    # Helper methods\n    \n    def _extract_line_range(self, code: CodeExample) -> Tuple[int, int]:\n        \"\"\"Extract line range from code example.\"\"\"\n        # Count lines in code\n        # TODO: Implement python_comprehensions logic here\n        pass\n    \n    def _find_tests_for_code(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Find tests related to this code.\"\"\"\n        \n        # Extract function/class names from code\n        \n            \n                \n                # Check if test name mentions any of the code names\n        \n    \n    def _find_git_evidence(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"Find git commits related to this code file.\"\"\"\n        \n            # Check if commit affected this file\n        \n    \n    def _extract_class_name(self, code: str) -> str:\n        \"\"\"Extract class name from code.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n    \n    def _extract_function_name(self, code: str) -> str:\n        \"\"\"Extract function name from code.\"\"\"\n        # Try Python function\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Try JavaScript function\n        \n        # Try arrow function with const\n        \n    \n    def _extract_names(self, code: str) -> List[str]:\n        \"\"\"Extract function and class names from code.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        # Extract class names\n        \n        # Extract function names\n        \n        \n        \n    \n    def _extract_python_concepts(self, code: str) -> List[str]:\n        \"\"\"Extract Python-specific concepts.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n        \n        \n        \n        \n        \n    \n    def _extract_javascript_concepts(self, code: str) -> List[str]:\n        \"\"\"Extract JavaScript/TypeScript-specific concepts.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n        \n        \n        \n        \n        \n    \n    def _extract_imports(self, code: str, language: str) -> List[str]:\n        \"\"\"Extract import statements from code.\"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            # Python imports\n        \n            # JavaScript/TypeScript imports",
              "solution_code": "# Add test evidence if available\n        if tests:\n            test_descriptions = [t.get('description', '') for t in tests if t.get('description')]\n            if test_descriptions:\n                purpose_parts.append(f\"(validated by {len(tests)} test(s): {', '.join(test_descriptions[:2])})\")\n        \n        return \" \".join(purpose_parts)\n    \n    def extract_key_concepts(self, code: CodeExample) -> List[str]:\n        \"\"\"\n        Extract key programming concepts from code patterns and structure.\n        \n        Args:\n            code: The code example\n            \n        Returns:\n            List of key concepts demonstrated in the code\n        \"\"\"\n        concepts = []\n        code_text = code.code\n        code_lower = code_text.lower()\n        \n        # Language-specific concepts\n        if code.language in ['python', 'py']:\n            concepts.extend(self._extract_python_concepts(code_text))\n        elif code.language in ['javascript', 'typescript', 'js', 'ts']:\n            concepts.extend(self._extract_javascript_concepts(code_text))\n        \n        # Common patterns across languages\n        if 'class ' in code_text:\n            concepts.append(\"Object-Oriented Programming\")\n            if '__init__' in code_text or 'constructor' in code_text:\n                concepts.append(\"Class Initialization\")\n        \n        if 'async ' in code_text or 'await ' in code_text:\n            concepts.append(\"Asynchronous Programming\")\n        \n        if 'try:' in code_text or 'try {' in code_text or 'catch' in code_text:\n            concepts.append(\"Error Handling\")\n        \n        if 'import ' in code_text or 'from ' in code_text or 'require(' in code_text:\n            concepts.append(\"Module Imports\")\n        \n        if '@' in code_text and ('def ' in code_text or 'function' in code_text):\n            concepts.append(\"Decorators\" if code.language == 'python' else \"Annotations\")\n        \n        if 'if ' in code_text or 'else' in code_text:\n            concepts.append(\"Conditional Logic\")\n        \n        if 'for ' in code_text or 'while ' in code_text:\n            concepts.append(\"Iteration\")\n        \n        if 'lambda' in code_text or '=>' in code_text:\n            concepts.append(\"Lambda Functions\")\n        \n        # Data structure concepts\n        if '[' in code_text and ']' in code_text:\n            concepts.append(\"Lists/Arrays\")\n        \n        if '{' in code_text and ':' in code_text and code.language == 'python':\n            concepts.append(\"Dictionaries\")\n        elif '{' in code_text and code.language in ['javascript', 'typescript']:\n            concepts.append(\"Objects\")\n        \n        # API and web concepts\n        if any(method in code_lower for method in ['get', 'post', 'put', 'delete', 'patch']):\n            if 'route' in code_lower or '@app.' in code_lower:\n                concepts.append(\"RESTful API\")\n        \n        if 'request' in code_lower or 'response' in code_lower:\n            concepts.append(\"HTTP Request/Response\")\n        \n        # Database concepts\n        if any(db in code_lower for db in ['query', 'select', 'insert', 'update', 'delete', 'database', 'db.']):\n            concepts.append(\"Database Operations\")\n        \n        # Return unique concepts\n        return list(dict.fromkeys(concepts))  # Preserve order while removing duplicates\n    \n    def suggest_explanation_approach(self, code: CodeExample) -> List[str]:\n        \"\"\"\n        Suggest a progressive disclosure approach for explaining code.\n        \n        This method provides a step-by-step approach to explain code from\n        simple to complex concepts, following pedagogical best practices.\n        \n        Args:\n            code: The code example\n            \n        Returns:\n            List of explanation steps ordered from simple to complex\n        \"\"\"\n        approach = []\n        code_text = code.code\n        \n        # Step 1: Start with the big picture\n        if 'class ' in code_text:\n            approach.append(\"Start by explaining what the class represents and its role in the system\")\n        elif 'def ' in code_text or 'function ' in code_text:\n            approach.append(\"Begin with what the function does at a high level (inputs and outputs)\")\n        else:\n            approach.append(\"Start with the overall purpose of this code section\")\n        \n        # Step 2: Explain the structure\n        if 'class ' in code_text:\n            approach.append(\"Describe the class attributes and their purposes\")\n            approach.append(\"Walk through the main methods in order of typical usage\")\n        elif 'def ' in code_text or 'function ' in code_text:\n            approach.append(\"Explain the function signature (parameters and return type)\")\n            approach.append(\"Walk through the function logic step by step\")\n        \n        # Step 3: Dive into specific patterns\n        if 'async ' in code_text or 'await ' in code_text:\n            approach.append(\"Explain the asynchronous nature and why it's needed\")\n        \n        if 'try:' in code_text or 'try {' in code_text:\n            approach.append(\"Discuss error handling strategy and what errors are caught\")\n        \n        if '@' in code_text and ('def ' in code_text or 'function' in code_text):\n            approach.append(\"Explain the decorator/annotation and what it adds to the function\")\n        \n        # Step 4: Highlight important details\n        if 'if ' in code_text or 'else' in code_text:\n            approach.append(\"Walk through the conditional logic and different code paths\")\n        \n        if 'for ' in code_text or 'while ' in code_text:\n            approach.append(\"Explain the iteration logic and what's being processed\")\n        \n        # Step 5: Connect to broader context\n        approach.append(\"Show how this code fits into the larger application\")\n        approach.append(\"Mention common use cases and when this code is called\")\n        \n        # Step 6: Discuss edge cases and best practices\n        approach.append(\"Point out edge cases and how they're handled\")\n        approach.append(\"Highlight best practices demonstrated in the code\")\n        \n        return approach\n    \n    def find_related_code(\n        self,\n        code: CodeExample,\n        evidence: EvidenceBundle\n    ) -> List[Dict[str, str]]:\n        \"\"\"\n        Find related code sections with context and relationships.\n        \n        Args:\n            code: The code example\n            evidence: Evidence bundle with dependencies and source files\n            \n        Returns:\n            List of related code with path, context, and relationship\n        \"\"\"\n        related = []\n        \n        # Extract imports/dependencies from the code\n        imports = self._extract_imports(code.code, code.language)\n        \n        # Find related files from dependencies\n        for dep in evidence.dependencies:\n            dep_name = dep.get('name', '')\n            # Check if this dependency is imported in the code\n            if any(imp in dep_name or dep_name in imp for imp in imports):\n                related.append({\n                    'path': dep_name,\n                    'context': dep.get('reason', 'Dependency'),\n                    'relationship': 'imports'\n                })\n        \n        # Find files that depend on this code\n        for dependent in evidence.dependents:\n            dep_name = dependent.get('name', '')\n            related.append({\n                'path': dep_name,\n                'context': dependent.get('usage', 'Used by this file'),\n                'relationship': 'imported_by'\n            })\n        \n        # Look for related files in source_files\n        current_file = code.filename\n        for source_file in evidence.source_files:\n            file_path = source_file.get('path', '')\n            if file_path != current_file:\n                # Check if files are in the same directory (likely related)\n                if self._are_files_related(current_file, file_path):\n                    related.append({\n                        'path': file_path,\n                        'context': 'Related file in same module',\n                        'relationship': 'sibling'\n                    })\n        \n        return related[:10]  # Limit to top 10 related files\n    \n    def identify_common_mistakes(\n        self,\n        code: CodeExample,\n        tests: List[Dict[str, str]]\n    ) -> List[str]:\n        \"\"\"\n        Identify common mistakes from test failures and code patterns.\n        \n        Args:\n            code: The code example\n            tests: List of related tests\n            \n        Returns:\n            List of common mistakes to highlight\n        \"\"\"\n        mistakes = []\n        code_text = code.code\n        code_lower = code_text.lower()\n        \n        # Analyze test descriptions for common pitfalls\n        for test in tests:\n            test_name = test.get('test_name', '').lower()\n            test_desc = test.get('description', '').lower()\n            \n            # Look for negative test cases\n            if any(word in test_name or word in test_desc for word in ['error', 'fail', 'invalid', 'exception', 'edge']):\n                mistakes.append(f\"Watch out for: {test.get('description', test.get('test_name', 'edge case'))}\")\n        \n        # Common Python mistakes\n        if code.language in ['python', 'py']:\n            if '==' in code_text and 'is' not in code_text:\n                mistakes.append(\"Using == for comparison (consider 'is' for None/True/False)\")\n            \n            if 'except:' in code_text:\n                mistakes.append(\"Catching all exceptions with bare 'except:' (be more specific)\")\n            \n            if 'global ' in code_text:\n                mistakes.append(\"Using global variables (consider passing as parameters)\")\n        \n        # Common JavaScript/TypeScript mistakes\n        if code.language in ['javascript', 'typescript', 'js', 'ts']:\n            if '==' in code_text and '===' not in code_text:\n                mistakes.append(\"Using == instead of === (loose vs strict equality)\")\n            \n            if 'var ' in code_text:\n                mistakes.append(\"Using 'var' instead of 'let' or 'const'\")\n        \n        # Async/await mistakes\n        if 'async ' in code_text:\n            if 'await ' not in code_text:\n                mistakes.append(\"Async function without await (might not need to be async)\")\n            \n            if 'try' not in code_text:\n                mistakes.append(\"Async code without error handling (use try/catch)\")\n        \n        # Error handling mistakes\n        if 'try:' in code_text or 'try {' in code_text:\n            if 'finally' not in code_text and ('open(' in code_text or 'file' in code_lower):\n                mistakes.append(\"Opening files without 'finally' block for cleanup\")\n        \n        # Security-related mistakes\n        if 'password' in code_lower:\n            if 'hash' not in code_lower and 'bcrypt' not in code_lower:\n                mistakes.append(\"Handling passwords without hashing (always hash passwords)\")\n        \n        if 'sql' in code_lower or 'query' in code_lower:\n            if 'format' in code_text or '+' in code_text:\n                mistakes.append(\"Potential SQL injection risk (use parameterized queries)\")\n        \n        return mistakes[:8]  # Limit to top 8 most relevant mistakes\n    \n    # Helper methods\n    \n    def _extract_line_range(self, code: CodeExample) -> Tuple[int, int]:\n        \"\"\"Extract line range from code example.\"\"\"\n        # Count lines in code\n        lines = code.code.split('\\n')\n        return (1, len(lines))\n    \n    def _find_tests_for_code(\n        self,\n        code: CodeExample,\n        test_files: List[Dict[str, Any]]\n    ) -> List[Dict[str, str]]:\n        \"\"\"Find tests related to this code.\"\"\"\n        related_tests = []\n        \n        # Extract function/class names from code\n        names = self._extract_names(code.code)\n        \n        for test_file in test_files:\n            test_path = test_file.get('path', '')\n            tests = test_file.get('tests', [])\n            \n            for test in tests:\n                test_name = test.get('name', '')\n                test_desc = test.get('description', '')\n                \n                # Check if test name mentions any of the code names\n                if any(name.lower() in test_name.lower() for name in names):\n                    related_tests.append({\n                        'test_name': test_name,\n                        'description': test_desc,\n                        'file': test_path\n                    })\n        \n        return related_tests\n    \n    def _find_git_evidence(\n        self,\n        code: CodeExample,\n        git_commits: List[Dict[str, Any]]\n    ) -> List[Dict[str, str]]:\n        \"\"\"Find git commits related to this code file.\"\"\"\n        related_commits = []\n        \n        for commit in git_commits:\n            # Check if commit affected this file\n            files_changed = commit.get('files_changed', [])\n            if code.filename in files_changed or any(code.filename in f for f in files_changed):\n                related_commits.append({\n                    'commit': commit.get('hash', '')[:8],  # Short hash\n                    'message': commit.get('message', ''),\n                    'date': commit.get('date', '')\n                })\n        \n        return related_commits[:5]  # Limit to 5 most recent commits\n    \n    def _extract_class_name(self, code: str) -> str:\n        \"\"\"Extract class name from code.\"\"\"\n        match = re.search(r'class\\s+(\\w+)', code)\n        return match.group(1) if match else \"class\"\n    \n    def _extract_function_name(self, code: str) -> str:\n        \"\"\"Extract function name from code.\"\"\"\n        # Try Python function\n        match = re.search(r'def\\s+(\\w+)', code)\n        if match:\n            return match.group(1)\n        \n        # Try JavaScript function\n        match = re.search(r'function\\s+(\\w+)', code)\n        if match:\n            return match.group(1)\n        \n        # Try arrow function with const\n        match = re.search(r'const\\s+(\\w+)\\s*=', code)\n        if match:\n            return match.group(1)\n        \n        return \"function\"\n    \n    def _extract_names(self, code: str) -> List[str]:\n        \"\"\"Extract function and class names from code.\"\"\"\n        names = []\n        \n        # Extract class names\n        for match in re.finditer(r'class\\s+(\\w+)', code):\n            names.append(match.group(1))\n        \n        # Extract function names\n        for match in re.finditer(r'def\\s+(\\w+)', code):\n            names.append(match.group(1))\n        \n        for match in re.finditer(r'function\\s+(\\w+)', code):\n            names.append(match.group(1))\n        \n        for match in re.finditer(r'const\\s+(\\w+)\\s*=.*=>', code):\n            names.append(match.group(1))\n        \n        return names\n    \n    def _extract_python_concepts(self, code: str) -> List[str]:\n        \"\"\"Extract Python-specific concepts.\"\"\"\n        concepts = []\n        \n        if 'with ' in code:\n            concepts.append(\"Context Managers\")\n        \n        if '__' in code:\n            concepts.append(\"Dunder Methods\")\n        \n        if 'yield' in code:\n            concepts.append(\"Generators\")\n        \n        if '@property' in code:\n            concepts.append(\"Properties\")\n        \n        if 'isinstance' in code or 'type(' in code:\n            concepts.append(\"Type Checking\")\n        \n        if 'list comprehension' in code or '[' in code and 'for' in code and ']' in code:\n            concepts.append(\"List Comprehensions\")\n        \n        return concepts\n    \n    def _extract_javascript_concepts(self, code: str) -> List[str]:\n        \"\"\"Extract JavaScript/TypeScript-specific concepts.\"\"\"\n        concepts = []\n        \n        if 'Promise' in code or '.then(' in code:\n            concepts.append(\"Promises\")\n        \n        if 'useState' in code or 'useEffect' in code:\n            concepts.append(\"React Hooks\")\n        \n        if 'export default' in code or 'export {' in code:\n            concepts.append(\"ES6 Modules\")\n        \n        if '=>' in code:\n            concepts.append(\"Arrow Functions\")\n        \n        if 'const {' in code or 'const [' in code:\n            concepts.append(\"Destructuring\")\n        \n        if '...' in code:\n            concepts.append(\"Spread Operator\")\n        \n        return concepts\n    \n    def _extract_imports(self, code: str, language: str) -> List[str]:\n        \"\"\"Extract import statements from code.\"\"\"\n        imports = []\n        \n        if language in ['python', 'py']:\n            # Python imports\n            for match in re.finditer(r'from\\s+([\\w.]+)\\s+import', code):\n                imports.append(match.group(1))\n            for match in re.finditer(r'import\\s+([\\w.]+)', code):\n                imports.append(match.group(1))\n        \n        elif language in ['javascript', 'typescript', 'js', 'ts']:\n            # JavaScript/TypeScript imports\n            for match in re.finditer(r'from\\s+[\\'\"]([^\\'\"]+)[\\'\"]', code):\n                imports.append(match.group(1))\n            for match in re.finditer(r'require\\([\\'\"]([^\\'\"]+)[\\'\"]\\)', code):\n                imports.append(match.group(1))",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 43 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: imports = self._extract_imports(code.code, code.language)"
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (8 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "password_hashing",
            "python_generators",
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "7a2531af-2bf1-4658-981b-545bdbf047fd",
          "title": "Investigation Engine: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.79). Well-documented (100% coverage). Ideal complexity (avg: 5.7) for teaching. Contains useful patterns. Well-structured code. Demonstrates: python_generators, python_comprehensions",
          "order": 6,
          "difficulty": "intermediate",
          "duration_minutes": 48,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\investigation_engine.py",
          "teaching_value": 0.79,
          "learning_objectives": [
            "Understand python generators pattern",
            "Understand python comprehensions pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_generators",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "2cbe6306-d1ca-4612-b956-479dfc7480bc",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\investigation_engine.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (10 occurrences)"
              ],
              "starter_code": "# Extract high-level functionality from code structure\n                \n                # Analyze code structure\n                \n        \n        # Cross-reference with test expectations\n            \n                # Add test-validated behaviors\n        \n        # Combine into coherent description\n        \n        \n\n    \n    def investigate_why_it_exists(self, evidence: EvidenceBundle) -> str:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n            \n        \"\"\"\n        \n        # Extract from git commit messages\n            \n            # Extract purpose from commit message\n            \n        \n        # Extract from documentation\n            \n            # Extract purpose from docstrings/comments\n            \n        \n        # Combine into coherent explanation\n        \n        \n    \n    def investigate_how_it_works(self, evidence: EvidenceBundle) -> str:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n            \n        \"\"\"\n        \n        # Analyze each source file\n            \n                \n                # Analyze implementation approach\n                \n        \n        # Analyze dependencies to understand integration\n        \n        # Combine into coherent explanation\n        \n        \n    \n    def investigate_when_used(self, evidence: EvidenceBundle) -> List[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n            \n        \"\"\"\n        \n        # Analyze dependents (what calls this code)\n            \n        \n        # Analyze test files for usage patterns\n            \n            # Extract usage scenarios from test descriptions\n                \n                    # Convert test description to usage scenario\n        \n        # If no specific usage found, provide general scenarios\n        \n        \n    \n    def investigate_edge_cases(self, evidence: EvidenceBundle) -> List[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        from test files and code comments.\n        \n            \n        \"\"\"\n        \n        # Analyze test files for edge case handling\n            \n                \n                # Look for edge case indicators\n        \n        # Extract from code comments\n            \n            # Look for edge case mentions in comments\n        \n        # If no edge cases found\n        \n        \n    \n    def investigate_pitfalls(self, evidence: EvidenceBundle) -> List[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n        \n            \n        \"\"\"\n        \n        # Extract from documentation and comments\n            \n            # Look for warning indicators\n        \n        # Extract from test descriptions (tests often reveal pitfalls)\n            \n                \n                # Look for pitfall indicators\n        \n        # Extract from git commits (bug fixes reveal pitfalls)\n            \n        \n        # If no pitfalls found\n        \n        \n    \n    # Helper methods for code analysis\n    \n    def _analyze_code_functionality(self, code: str, language: str) -> Optional[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Look for common patterns\n        \n        # Function/class definitions\n                # Extract function name\n        \n        \n        # Common operations\n        \n\n    \n    def _extract_purpose_from_commit(self, message: str) -> Optional[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Clean up message\n        \n        # Use first line (subject) as primary source\n        \n        # Look for common patterns\n        \n        \n        # If no pattern matched, use subject as-is\n        \n    \n    def _extract_purpose_from_documentation(self, content: str) -> Optional[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        # Clean up content\n        \n        \n        # First line is usually the summary\n        \n        # Remove common docstring markers\n        first_line = first_line.strip('\"\"\"\\'')\n        \n        # If it's a reasonable length, use it\n        \n    \n    def _analyze_implementation(self, code: str, language: str) -> Optional[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n        \n        # Detect patterns\n        \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    def _test_to_usage_scenario(self, test_description: str) -> str:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        # Remove test-specific language\n        \n        # Capitalize first letter\n        \n    \n    def _is_edge_case_test(self, description: str) -> bool:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        \n    \n    def _extract_edge_case(self, description: str) -> str:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        # Clean up description\n        \n        # Capitalize\n        \n    \n    def _extract_edge_case_from_doc(self, content: str) -> Optional[str]:\n        \"\"\"\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \n            \n        \"\"\"\n        # Look for sentences mentioning edge cases\n        ",
              "solution_code": "# Extract high-level functionality from code structure\n            for section in source_file.get('sections', []):\n                start_line = section.get('start_line', 1)\n                end_line = section.get('end_line', 1)\n                code = section.get('code', '')\n                \n                # Analyze code structure\n                functionality = self._analyze_code_functionality(code, language)\n                \n                if functionality:\n                    citation = f\"[{file_path}:{start_line}-{end_line}]\"\n                    descriptions.append(f\"{functionality} {citation}\")\n        \n        # Cross-reference with test expectations\n        for test_file in evidence.test_files:\n            test_path = test_file['path']\n            coverage = test_file.get('coverage', [])\n            \n            if coverage:\n                # Add test-validated behaviors\n                for behavior in coverage[:3]:  # Top 3 most important\n                    citation = f\"[validated by {test_path}]\"\n                    descriptions.append(f\"{behavior} {citation}\")\n        \n        # Combine into coherent description\n        if descriptions:\n            result = \"This code \" + \"; \".join(descriptions[:5])  # Top 5 descriptions\n        else:\n            result = \"This code provides functionality as defined in the source files.\"\n        \n        logger.debug(f\"Generated 'what it does' description with {len(descriptions)} citations\")\n        \n        return result\n\n    \n    def investigate_why_it_exists(self, evidence: EvidenceBundle) -> str:\n        \"\"\"\n        Explain why the code exists with citations to git commits or documentation.\n        \n        Extracts business/technical rationale from commit messages and\n        documentation to explain the purpose and motivation.\n        \n        Args:\n            evidence: Evidence bundle with git commits and documentation\n            \n        Returns:\n            Explanation with git/doc citations\n        \"\"\"\n        reasons = []\n        \n        # Extract from git commit messages\n        for commit in evidence.git_commits[:5]:  # Top 5 most relevant commits\n            commit_hash = commit.get('hash', '')[:8]\n            message = commit.get('message', '')\n            subject = commit.get('subject', '')\n            \n            # Extract purpose from commit message\n            purpose = self._extract_purpose_from_commit(message or subject)\n            \n            if purpose:\n                citation = f\"[commit {commit_hash}]\"\n                reasons.append(f\"{purpose} {citation}\")\n        \n        # Extract from documentation\n        for doc in evidence.documentation[:3]:  # Top 3 most relevant docs\n            content = doc.get('content', '')\n            location = doc.get('location', '')\n            \n            # Extract purpose from docstrings/comments\n            purpose = self._extract_purpose_from_documentation(content)\n            \n            if purpose:\n                citation = f\"[{location}]\"\n                reasons.append(f\"{purpose} {citation}\")\n        \n        # Combine into coherent explanation\n        if reasons:\n            result = \"This code exists to: \" + \"; \".join(reasons[:3])  # Top 3 reasons\n        else:\n            result = \"This code exists to provide functionality as part of the system architecture.\"\n        \n        logger.debug(f\"Generated 'why it exists' explanation with {len(reasons)} citations\")\n        \n        return result\n    \n    def investigate_how_it_works(self, evidence: EvidenceBundle) -> str:\n        \"\"\"\n        Explain how the code works with citations to implementation details.\n        \n        Analyzes code structure, algorithms, and patterns to explain\n        the technical implementation approach.\n        \n        Args:\n            evidence: Evidence bundle with source files\n            \n        Returns:\n            Technical explanation with code section citations\n        \"\"\"\n        explanations = []\n        \n        # Analyze each source file\n        for source_file in evidence.source_files:\n            file_path = source_file['path']\n            language = source_file.get('language', 'unknown')\n            \n            for section in source_file.get('sections', []):\n                start_line = section.get('start_line', 1)\n                end_line = section.get('end_line', 1)\n                code = section.get('code', '')\n                \n                # Analyze implementation approach\n                implementation = self._analyze_implementation(code, language)\n                \n                if implementation:\n                    citation = f\"[{file_path}:{start_line}-{end_line}]\"\n                    explanations.append(f\"{implementation} {citation}\")\n        \n        # Analyze dependencies to understand integration\n        if evidence.dependencies:\n            dep_names = [dep['name'] for dep in evidence.dependencies[:3]]\n            if dep_names:\n                deps_str = \", \".join(dep_names)\n                explanations.append(f\"Integrates with {deps_str} for extended functionality\")\n        \n        # Combine into coherent explanation\n        if explanations:\n            result = \"Implementation approach: \" + \"; \".join(explanations[:4])  # Top 4 explanations\n        else:\n            result = \"Implementation follows standard patterns for the language and framework.\"\n        \n        logger.debug(f\"Generated 'how it works' explanation with {len(explanations)} citations\")\n        \n        return result\n    \n    def investigate_when_used(self, evidence: EvidenceBundle) -> List[str]:\n        \"\"\"\n        Identify when the code is used with citations to call sites.\n        \n        Analyzes dependents and usage patterns to identify scenarios\n        where this code is invoked.\n        \n        Args:\n            evidence: Evidence bundle with dependents information\n            \n        Returns:\n            List of usage scenarios with citations\n        \"\"\"\n        usage_scenarios = []\n        \n        # Analyze dependents (what calls this code)\n        for dependent in evidence.dependents:\n            dep_name = dependent.get('name', '')\n            usage = dependent.get('usage', '')\n            evidence_str = dependent.get('evidence', '')\n            \n            if usage:\n                citation = f\"[called by {dep_name}]\"\n                scenario = f\"{usage} {citation}\"\n                usage_scenarios.append(scenario)\n        \n        # Analyze test files for usage patterns\n        for test_file in evidence.test_files:\n            test_path = test_file['path']\n            test_cases = test_file.get('test_cases', [])\n            \n            # Extract usage scenarios from test descriptions\n            for test_case in test_cases[:3]:  # Top 3 test cases\n                description = test_case.get('description', '')\n                \n                if description:\n                    # Convert test description to usage scenario\n                    scenario = self._test_to_usage_scenario(description)\n                    citation = f\"[tested in {test_path}]\"\n                    usage_scenarios.append(f\"{scenario} {citation}\")\n        \n        # If no specific usage found, provide general scenarios\n        if not usage_scenarios:\n            usage_scenarios.append(\"Used as part of the application's core functionality\")\n        \n        logger.debug(f\"Identified {len(usage_scenarios)} usage scenarios\")\n        \n        return usage_scenarios[:5]  # Return top 5 scenarios\n    \n    def investigate_edge_cases(self, evidence: EvidenceBundle) -> List[str]:\n        \"\"\"\n        Identify edge cases with citations from test analysis.\n        \n        Extracts special handling, boundary conditions, and edge cases\n        from test files and code comments.\n        \n        Args:\n            evidence: Evidence bundle with test files\n            \n        Returns:\n            List of edge cases with test citations\n        \"\"\"\n        edge_cases = []\n        \n        # Analyze test files for edge case handling\n        for test_file in evidence.test_files:\n            test_path = test_file['path']\n            test_cases = test_file.get('test_cases', [])\n            \n            for test_case in test_cases:\n                description = test_case.get('description', '').lower()\n                \n                # Look for edge case indicators\n                if self._is_edge_case_test(description):\n                    edge_case = self._extract_edge_case(description)\n                    citation = f\"[{test_path}: {test_case.get('name', 'test')}]\"\n                    edge_cases.append(f\"{edge_case} {citation}\")\n        \n        # Extract from code comments\n        for doc in evidence.documentation:\n            content = doc.get('content', '').lower()\n            location = doc.get('location', '')\n            \n            # Look for edge case mentions in comments\n            if any(keyword in content for keyword in ['edge case', 'special case', 'boundary', 'corner case']):\n                edge_case = self._extract_edge_case_from_doc(content)\n                if edge_case:\n                    citation = f\"[{location}]\"\n                    edge_cases.append(f\"{edge_case} {citation}\")\n        \n        # If no edge cases found\n        if not edge_cases:\n            edge_cases.append(\"No specific edge cases documented in tests or comments\")\n        \n        logger.debug(f\"Identified {len(edge_cases)} edge cases\")\n        \n        return edge_cases[:5]  # Return top 5 edge cases\n    \n    def investigate_pitfalls(self, evidence: EvidenceBundle) -> List[str]:\n        \"\"\"\n        Identify common pitfalls with citations from comments and tests.\n        \n        Extracts warnings, gotchas, and common mistakes from code comments,\n        documentation, and test failure scenarios.\n        \n        Args:\n            evidence: Evidence bundle with documentation and tests\n            \n        Returns:\n            List of common pitfalls with citations\n        \"\"\"\n        pitfalls = []\n        \n        # Extract from documentation and comments\n        for doc in evidence.documentation:\n            content = doc.get('content', '').lower()\n            location = doc.get('location', '')\n            \n            # Look for warning indicators\n            if self._contains_warning(content):\n                pitfall = self._extract_pitfall_from_doc(content)\n                if pitfall:\n                    citation = f\"[{location}]\"\n                    pitfalls.append(f\"{pitfall} {citation}\")\n        \n        # Extract from test descriptions (tests often reveal pitfalls)\n        for test_file in evidence.test_files:\n            test_path = test_file['path']\n            test_cases = test_file.get('test_cases', [])\n            \n            for test_case in test_cases:\n                description = test_case.get('description', '').lower()\n                \n                # Look for pitfall indicators\n                if self._is_pitfall_test(description):\n                    pitfall = self._extract_pitfall_from_test(description)\n                    citation = f\"[{test_path}: {test_case.get('name', 'test')}]\"\n                    pitfalls.append(f\"{pitfall} {citation}\")\n        \n        # Extract from git commits (bug fixes reveal pitfalls)\n        for commit in evidence.git_commits:\n            message = commit.get('message', '').lower()\n            commit_hash = commit.get('hash', '')[:8]\n            \n            if self._is_bug_fix_commit(message):\n                pitfall = self._extract_pitfall_from_commit(message)\n                if pitfall:\n                    citation = f\"[commit {commit_hash}]\"\n                    pitfalls.append(f\"{pitfall} {citation}\")\n        \n        # If no pitfalls found\n        if not pitfalls:\n            pitfalls.append(\"No specific pitfalls documented in comments or tests\")\n        \n        logger.debug(f\"Identified {len(pitfalls)} common pitfalls\")\n        \n        return pitfalls[:5]  # Return top 5 pitfalls\n    \n    # Helper methods for code analysis\n    \n    def _analyze_code_functionality(self, code: str, language: str) -> Optional[str]:\n        \"\"\"\n        Analyze code to determine its primary functionality.\n        \n        Args:\n            code: Source code snippet\n            language: Programming language\n            \n        Returns:\n            Description of functionality or None\n        \"\"\"\n        if not code.strip():\n            return None\n        \n        # Look for common patterns\n        code_lower = code.lower()\n        \n        # Function/class definitions\n        if language == 'python':\n            if 'def ' in code and 'class ' not in code:\n                # Extract function name\n                match = re.search(r'def\\s+(\\w+)\\s*\\(', code)\n                if match:\n                    func_name = match.group(1)\n                    return f\"defines function '{func_name}'\"\n            elif 'class ' in code:\n                match = re.search(r'class\\s+(\\w+)', code)\n                if match:\n                    class_name = match.group(1)\n                    return f\"defines class '{class_name}'\"\n        \n        elif language in ['javascript', 'typescript']:\n            if 'function ' in code or '=>' in code:\n                match = re.search(r'function\\s+(\\w+)\\s*\\(', code)\n                if match:\n                    func_name = match.group(1)\n                    return f\"defines function '{func_name}'\"\n                elif 'const ' in code or 'let ' in code:\n                    return \"defines a function\"\n            elif 'class ' in code:\n                match = re.search(r'class\\s+(\\w+)', code)\n                if match:\n                    class_name = match.group(1)\n                    return f\"defines class '{class_name}'\"\n        \n        # Common operations\n        if 'return' in code_lower:\n            return \"performs computation and returns result\"\n        if 'async' in code_lower or 'await' in code_lower:\n            return \"performs asynchronous operations\"\n        if 'fetch' in code_lower or 'request' in code_lower or 'http' in code_lower:\n            return \"makes HTTP requests\"\n        if 'database' in code_lower or 'query' in code_lower or 'select' in code_lower:\n            return \"performs database operations\"\n        if 'validate' in code_lower or 'check' in code_lower:\n            return \"validates data or conditions\"\n        if 'parse' in code_lower or 'transform' in code_lower:\n            return \"parses or transforms data\"\n        \n        return \"provides functionality\"\n\n    \n    def _extract_purpose_from_commit(self, message: str) -> Optional[str]:\n        \"\"\"\n        Extract purpose/rationale from commit message.\n        \n        Args:\n            message: Commit message\n            \n        Returns:\n            Purpose statement or None\n        \"\"\"\n        if not message:\n            return None\n        \n        # Clean up message\n        message = message.strip()\n        lines = message.split('\\n')\n        \n        # Use first line (subject) as primary source\n        subject = lines[0].strip()\n        \n        # Look for common patterns\n        patterns = [\n            (r'^add(?:ed)?\\s+(.+)', 'add'),\n            (r'^implement(?:ed)?\\s+(.+)', 'implement'),\n            (r'^create(?:d)?\\s+(.+)', 'create'),\n            (r'^fix(?:ed)?\\s+(.+)', 'fix'),\n            (r'^update(?:d)?\\s+(.+)', 'update'),\n            (r'^improve(?:d)?\\s+(.+)', 'improve'),\n            (r'^refactor(?:ed)?\\s+(.+)', 'refactor'),\n        ]\n        \n        for pattern, action in patterns:\n            match = re.search(pattern, subject, re.IGNORECASE)\n            if match:\n                what = match.group(1).strip()\n                return f\"{action} {what}\"\n        \n        # If no pattern matched, use subject as-is\n        if len(subject) > 10:\n            return subject\n        \n        return None\n    \n    def _extract_purpose_from_documentation(self, content: str) -> Optional[str]:\n        \"\"\"\n        Extract purpose from documentation/docstring.\n        \n        Args:\n            content: Documentation content\n            \n        Returns:\n            Purpose statement or None\n        \"\"\"\n        if not content:\n            return None\n        \n        # Clean up content\n        content = content.strip()\n        lines = [line.strip() for line in content.split('\\n') if line.strip()]\n        \n        if not lines:\n            return None\n        \n        # First line is usually the summary\n        first_line = lines[0]\n        \n        # Remove common docstring markers\n        first_line = first_line.strip('\"\"\"\\'')\n        \n        # If it's a reasonable length, use it\n        if 10 < len(first_line) < 200:\n            return first_line\n        \n        return None\n    \n    def _analyze_implementation(self, code: str, language: str) -> Optional[str]:\n        \"\"\"\n        Analyze implementation approach from code.\n        \n        Args:\n            code: Source code snippet\n            language: Programming language\n            \n        Returns:\n            Implementation description or None\n        \"\"\"\n        if not code.strip():\n            return None\n        \n        code_lower = code.lower()\n        approaches = []\n        \n        # Detect patterns\n        if 'async' in code_lower or 'await' in code_lower:\n            approaches.append(\"uses asynchronous programming\")\n        \n        if 'class' in code_lower:\n            approaches.append(\"uses object-oriented design\")\n        \n        if 'try' in code_lower and 'except' in code_lower:\n            approaches.append(\"includes error handling\")\n        elif 'try' in code_lower and 'catch' in code_lower:\n            approaches.append(\"includes error handling\")\n        \n        if 'decorator' in code_lower or '@' in code:\n            approaches.append(\"uses decorators\")\n        \n        if 'generator' in code_lower or 'yield' in code_lower:\n            approaches.append(\"uses generators\")\n        \n        if 'lambda' in code_lower or '=>' in code:\n            approaches.append(\"uses functional programming\")\n        \n        if 'cache' in code_lower or 'memo' in code_lower:\n            approaches.append(\"implements caching\")\n        \n        if 'validate' in code_lower or 'schema' in code_lower:\n            approaches.append(\"validates input data\")\n        \n        if approaches:\n            return \", \".join(approaches)\n        \n        return None\n    \n    def _test_to_usage_scenario(self, test_description: str) -> str:\n        \"\"\"\n        Convert test description to usage scenario.\n        \n        Args:\n            test_description: Test case description\n            \n        Returns:\n            Usage scenario description\n        \"\"\"\n        # Remove test-specific language\n        scenario = test_description.lower()\n        scenario = scenario.replace('should ', '')\n        scenario = scenario.replace('test ', '')\n        scenario = scenario.replace('it ', '')\n        \n        # Capitalize first letter\n        if scenario:\n            scenario = scenario[0].upper() + scenario[1:]\n        \n        return scenario\n    \n    def _is_edge_case_test(self, description: str) -> bool:\n        \"\"\"\n        Check if test description indicates an edge case.\n        \n        Args:\n            description: Test description\n            \n        Returns:\n            True if edge case test\n        \"\"\"\n        edge_case_keywords = [\n            'edge case', 'corner case', 'boundary',\n            'empty', 'null', 'none', 'zero',\n            'invalid', 'error', 'exception',\n            'maximum', 'minimum', 'limit',\n            'special case', 'unusual'\n        ]\n        \n        return any(keyword in description for keyword in edge_case_keywords)\n    \n    def _extract_edge_case(self, description: str) -> str:\n        \"\"\"\n        Extract edge case description from test.\n        \n        Args:\n            description: Test description\n            \n        Returns:\n            Edge case description\n        \"\"\"\n        # Clean up description\n        edge_case = description.replace('should ', '')\n        edge_case = edge_case.replace('test ', '')\n        \n        # Capitalize\n        if edge_case:\n            edge_case = edge_case[0].upper() + edge_case[1:]\n        \n        return edge_case\n    \n    def _extract_edge_case_from_doc(self, content: str) -> Optional[str]:\n        \"\"\"\n        Extract edge case from documentation.\n        \n        Args:\n            content: Documentation content\n            \n        Returns:\n            Edge case description or None\n        \"\"\"\n        # Look for sentences mentioning edge cases\n        sentences = content.split('.')\n        \n        for sentence in sentences:\n            if any(keyword in sentence.lower() for keyword in ['edge case', 'special case', 'boundary']):\n                return sentence.strip()",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 51 main components. Focus on the function signatures and return values first.",
                "You'll need these imports: from test files and code comments."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (10 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "python_generators",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "93013580-c480-4cad-9ccf-e8ee7b382072",
          "title": "Validation Engine: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.79). Well-documented (100% coverage). Ideal complexity (avg: 5.7) for teaching. Contains useful patterns. Well-structured code. Demonstrates: python_async_await, python_comprehensions",
          "order": 7,
          "difficulty": "intermediate",
          "duration_minutes": 48,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\validation_engine.py",
          "teaching_value": 0.79,
          "learning_objectives": [
            "Understand python async await pattern",
            "Understand python comprehensions pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_async_await",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "c87b7425-4d8f-4242-9564-ce0ddad1f8b9",
              "title": "Practice: Python Comprehensions",
              "description": "Implement a python_comprehensions based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\validation_engine.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the python_comprehensions following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Uses comprehensions (8 occurrences)"
              ],
              "starter_code": "# Common commit type patterns (check more specific patterns first)\n    \n    def _consolidate_git_contexts(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n            \n        \"\"\"\n        \n        # Group by commit type\n        \n        # Build description\n        \n                # Limit description length\n        \n    \n    def cross_reference_sources(\n        # TODO: Implement python_comprehensions logic here\n        pass\n        \"\"\"\n        \n        \n                \n        \"\"\"\n        \n        # Check if we have enough evidence to cross-reference\n        \n        \n        # Extract key terms from each source\n        \n        # Check for overlapping concepts\n        ",
              "solution_code": "# Common commit type patterns (check more specific patterns first)\n        if any(word in subject_lower for word in ['test', 'spec']):\n            return 'test'\n        elif any(word in subject_lower for word in ['fix', 'bug', 'resolve', 'patch']):\n            return 'fix'\n        elif any(word in subject_lower for word in ['refactor', 'restructure', 'reorganize']):\n            return 'refactor'\n        elif any(word in subject_lower for word in ['doc', 'comment', 'readme']):\n            return 'documentation'\n        elif any(word in subject_lower for word in ['remove', 'delete', 'clean']):\n            return 'removal'\n        elif any(word in subject_lower for word in ['update', 'modify', 'change']):\n            return 'update'\n        elif any(word in subject_lower for word in ['add', 'implement', 'create', 'feat']):\n            return 'feature'\n        else:\n            return 'other'\n    \n    def _consolidate_git_contexts(\n        self,\n        contexts: List[Dict[str, str]]\n    ) -> str:\n        \"\"\"\n        Consolidate git contexts into a coherent description.\n        \n        Args:\n            contexts: List of context dictionaries\n            \n        Returns:\n            Consolidated context description\n        \"\"\"\n        if not contexts:\n            return \"No contexts identified\"\n        \n        # Group by commit type\n        by_type: Dict[str, List[Dict[str, str]]] = {}\n        for context in contexts:\n            commit_type = context.get('type', 'other')\n            if commit_type not in by_type:\n                by_type[commit_type] = []\n            by_type[commit_type].append(context)\n        \n        # Build description\n        descriptions = []\n        descriptions.append(\"Git history context:\")\n        \n        for commit_type, type_contexts in by_type.items():\n            descriptions.append(f\"\\n{commit_type.capitalize()} commits:\")\n            for context in type_contexts:\n                desc = context['description']\n                citation = context['citation']\n                # Limit description length\n                if len(desc) > 100:\n                    desc = desc[:97] + \"...\"\n                descriptions.append(f\"  - {desc} ({citation})\")\n        \n        return \"\\n\".join(descriptions)\n    \n    def cross_reference_sources(\n        self,\n        evidence: Dict[str, Any]\n    ) -> bool:\n        \"\"\"\n        Verify consistency across all evidence sources.\n        \n        Cross-references code behavior, test expectations, documentation,\n        and git context to ensure they tell a consistent story.\n        \n        Args:\n            evidence: Dictionary containing all evidence:\n                - code_behavior: Code behavior description\n                - test_expectations: Test expectations description\n                - documentation_alignment: Documentation alignment description\n                - git_context: Git context description\n                \n        Returns:\n            True if sources are consistent, False if inconsistencies detected\n        \"\"\"\n        code_behavior = evidence.get('code_behavior', '')\n        test_expectations = evidence.get('test_expectations', '')\n        documentation = evidence.get('documentation_alignment', '')\n        git_context = evidence.get('git_context', '')\n        \n        # Check if we have enough evidence to cross-reference\n        available_sources = sum([\n            bool(code_behavior and code_behavior != \"No source code available for validation\"),\n            bool(test_expectations and test_expectations != \"No tests available for validation\"),\n            bool(documentation and documentation != \"No documentation available for validation\"),\n            bool(git_context and git_context != \"No git history available for validation\")\n        ])\n        \n        if available_sources < 2:\n            logger.warning(\n                f\"Insufficient evidence sources for cross-referencing: \"\n                f\"{available_sources} source(s) available\"\n            )\n            return True  # Can't determine inconsistency with < 2 sources\n        \n        # Extract key terms from each source\n        code_terms = self._extract_key_terms(code_behavior)\n        test_terms = self._extract_key_terms(test_expectations)\n        doc_terms = self._extract_key_terms(documentation)\n        git_terms = self._extract_key_terms(git_context)\n        \n        # Check for overlapping concepts\n        all_terms = [code_terms, test_terms, doc_terms, git_terms]\n        available_term_sets = [terms for terms in all_terms if terms]\n        \n        if len(available_term_sets) < 2:",
              "hints": [
                "Start by understanding the structure of a python_comprehensions. Look at the imports and main components needed.",
                "Key elements to implement: 13 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Python Comprehensions",
                "Practice writing clean, maintainable code for Python Comprehensions",
                "Apply Uses comprehensions (8 occurrences) in your implementation"
              ]
            }
          ],
          "tags": [
            "python_async_await",
            "python_comprehensions"
          ]
        },
        {
          "lesson_id": "29b97c26-8b12-4239-8844-c1edb7a1a81a",
          "title": "Teaching Value Scorer: Python Comprehensions",
          "description": "Excellent teaching value (score: 0.78). Well-documented (100% coverage). Ideal complexity (avg: 6.0) for teaching. Contains some patterns. Well-structured code. Demonstrates: python_comprehensions",
          "order": 8,
          "difficulty": "intermediate",
          "duration_minutes": 42,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\teaching_value_scorer.py",
          "teaching_value": 0.78,
          "learning_objectives": [
            "Understand python comprehensions pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "python_comprehensions"
          ],
          "exercises": [],
          "tags": [
            "python_comprehensions"
          ]
        }
      ]
    },
    {
      "module_id": "a3778d75-3d8a-4f76-a575-436bc0721db8",
      "title": "Module 3: Database Migration",
      "description": "This module covers: session_authentication, api_key_authentication, jwt_authentication, oauth_authentication, password_hashing",
      "order": 2,
      "difficulty": "intermediate",
      "duration_hours": 1.0,
      "learning_objectives": [
        "Master database migration patterns",
        "Master jwt authentication patterns",
        "Master oauth authentication patterns",
        "Apply intermediate programming concepts"
      ],
      "lessons": [
        {
          "lesson_id": "142d4f96-a1d2-485c-9fc2-ba51c9d1a00e",
          "title": "Pattern Detector: Database Migration",
          "description": "Excellent teaching value (score: 0.98). Well-documented (100% coverage). Ideal complexity (avg: 6.5) for teaching. Contains useful patterns. Well-structured code. Demonstrates: database_migration, jwt_authentication, oauth_authentication, session_authentication, api_key_authentication, password_hashing, python_comprehensions",
          "order": 0,
          "difficulty": "intermediate",
          "duration_minutes": 60,
          "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\pattern_detector.py",
          "teaching_value": 0.98,
          "learning_objectives": [
            "Understand database migration pattern",
            "Understand jwt authentication pattern",
            "Understand oauth authentication pattern",
            "Analyze complex code structure",
            "Learn documentation best practices"
          ],
          "prerequisites": [],
          "concepts": [
            "database_migration",
            "jwt_authentication",
            "oauth_authentication",
            "session_authentication",
            "api_key_authentication",
            "password_hashing",
            "python_comprehensions"
          ],
          "exercises": [
            {
              "exercise_id": "c3f73756-4f80-46a0-8a54-9e988556f70a",
              "title": "Practice: Database Migration",
              "description": "Implement a database_migration based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\pattern_detector.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the database_migration following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: Contains migration function: def upgrade(, Contains migration function: def downgrade(, Contains migration function: exports.up"
              ],
              "starter_code": "# Migration indicators",
              "solution_code": "# Migration indicators\n    MIGRATION_INDICATORS = [\n        'def upgrade(', 'def downgrade(',  # Alembic\n        'exports.up', 'exports.down',  # Knex migrations\n        'class Migration',  # Django migrations\n        'async up(', 'async down('  # TypeORM migrations\n    ]",
              "hints": [
                "Start by understanding the structure of a database_migration. Look at the imports and main components needed.",
                "Key elements to implement: 2 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Database Migration",
                "Practice writing clean, maintainable code for Database Migration",
                "Apply Contains migration function: def upgrade( in your implementation",
                "Apply Contains migration function: def downgrade( in your implementation"
              ]
            },
            {
              "exercise_id": "921df8c6-bf84-4dcd-9b21-9bb6da357454",
              "title": "Practice: Jwt Authentication",
              "description": "Implement a jwt_authentication based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\pattern_detector.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the jwt_authentication following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: JWT operation: JWT, JWT operation: JWT, JWT operation: JWT"
              ],
              "starter_code": "    \"\"\"\n    \n    # JWT indicators\n    \n    # OAuth indicators\n    \n    # Session indicators\n    \n    # API key indicators\n    \n    # Password hashing indicators\n    \n    def detect(self, symbol_info: SymbolInfo, file_content: str, file_path: str) -> List[DetectedPattern]:\n        \"\"\"\n        # TODO: Implement jwt_authentication logic here\n        pass\n        \n        \n        \"\"\"\n        \n        # Detect JWT patterns\n        \n        # Detect OAuth patterns\n        \n        # Detect session-based auth\n        \n        # Detect API key auth\n        \n        # Detect password hashing\n        \n    \n    def _detect_jwt_pattern(\n        # TODO: Implement jwt_authentication logic here\n        pass\n        \"\"\"\n        \n        \"\"\"",
              "solution_code": "Supports:\n    - JWT (JSON Web Tokens)\n    - OAuth (OAuth2, OpenID Connect)\n    - Session-based authentication\n    - API key authentication\n    \"\"\"\n    \n    # JWT indicators\n    JWT_INDICATORS = [\n        'jwt.encode', 'jwt.decode', 'jsonwebtoken',\n        'JWT', 'JWTBearer', 'create_access_token',\n        'verify_token', 'decode_token'\n    ]\n    \n    # OAuth indicators\n    OAUTH_INDICATORS = [\n        'OAuth', 'oauth2', 'OpenID', 'OIDC',\n        'authorize_url', 'token_url', 'client_id',\n        'client_secret', 'authorization_code',\n        'OAuthProvider', 'GoogleOAuth', 'FacebookOAuth'\n    ]\n    \n    # Session indicators\n    SESSION_INDICATORS = [\n        'session', 'Session', 'SessionMiddleware',\n        'set_session', 'get_session', 'session_id',\n        'cookie-session', 'express-session'\n    ]\n    \n    # API key indicators\n    API_KEY_INDICATORS = [\n        'api_key', 'apiKey', 'API_KEY',\n        'x-api-key', 'Authorization: Bearer',\n        'authenticate_api_key'\n    ]\n    \n    # Password hashing indicators\n    PASSWORD_INDICATORS = [\n        'bcrypt', 'hashpw', 'checkpw',\n        'pbkdf2', 'scrypt', 'argon2',\n        'hash_password', 'verify_password',\n        'PasswordHasher'\n    ]\n    \n    def detect(self, symbol_info: SymbolInfo, file_content: str, file_path: str) -> List[DetectedPattern]:\n        \"\"\"\n        Detect authentication patterns in the file.\n        \n        Args:\n            symbol_info: Extracted symbols from the file\n            file_content: Raw file content as string\n            file_path: Path to the file being analyzed\n        \n        Returns:\n            List of detected authentication patterns\n        \"\"\"\n        patterns = []\n        \n        # Detect JWT patterns\n        jwt_pattern = self._detect_jwt_pattern(symbol_info, file_content, file_path)\n        if jwt_pattern:\n            patterns.append(jwt_pattern)\n        \n        # Detect OAuth patterns\n        oauth_pattern = self._detect_oauth_pattern(symbol_info, file_content, file_path)\n        if oauth_pattern:\n            patterns.append(oauth_pattern)\n        \n        # Detect session-based auth\n        session_pattern = self._detect_session_pattern(symbol_info, file_content, file_path)\n        if session_pattern:\n            patterns.append(session_pattern)\n        \n        # Detect API key auth\n        api_key_pattern = self._detect_api_key_pattern(symbol_info, file_content, file_path)\n        if api_key_pattern:\n            patterns.append(api_key_pattern)\n        \n        # Detect password hashing\n        password_pattern = self._detect_password_hashing(symbol_info, file_content, file_path)\n        if password_pattern:\n            patterns.append(password_pattern)\n        \n        return patterns\n    \n    def _detect_jwt_pattern(\n        self, \n        symbol_info: SymbolInfo, \n        file_content: str, \n        file_path: str\n    ) -> Optional[DetectedPattern]:\n        \"\"\"\n        Detect JWT authentication patterns.\n        \n        Evidence:\n        - Imports JWT library\n        - Uses jwt.encode/decode\n        - Token creation/verification functions\n        \"\"\"",
              "hints": [
                "Start by understanding the structure of a jwt_authentication. Look at the imports and main components needed.",
                "Key elements to implement: 3 main components. Focus on the function signatures and return values first."
              ],
              "learning_objectives": [
                "Understand how to implement a Jwt Authentication",
                "Practice writing clean, maintainable code for Jwt Authentication",
                "Apply JWT operation: JWT in your implementation",
                "Apply JWT operation: JWT in your implementation"
              ]
            },
            {
              "exercise_id": "3465f77a-ff04-4d68-91d3-e7d16d450697",
              "title": "Practice: Oauth Authentication",
              "description": "Implement a oauth_authentication based on the example from C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\analysis\\pattern_detector.py",
              "difficulty": "intermediate",
              "estimated_minutes": 45,
              "instructions": [
                "Implement the oauth_authentication following the pattern shown",
                "Ensure all required functionality is included",
                "Test your implementation with the provided test cases",
                "Key concepts to include: OAuth feature: OAuth, OAuth feature: oauth2, OAuth feature: OpenID"
              ],
              "starter_code": "    \"\"\"\n    \n    # JWT indicators\n    \n    # OAuth indicators",
              "solution_code": "Supports:\n    - JWT (JSON Web Tokens)\n    - OAuth (OAuth2, OpenID Connect)\n    - Session-based authentication\n    - API key authentication\n    \"\"\"\n    \n    # JWT indicators\n    JWT_INDICATORS = [\n        'jwt.encode', 'jwt.decode', 'jsonwebtoken',\n        'JWT', 'JWTBearer', 'create_access_token',\n        'verify_token', 'decode_token'\n    ]\n    \n    # OAuth indicators\n    OAUTH_INDICATORS = [\n        'OAuth', 'oauth2', 'OpenID', 'OIDC',\n        'authorize_url', 'token_url', 'client_id',\n        'client_secret', 'authorization_code',\n        'OAuthProvider', 'GoogleOAuth', 'FacebookOAuth'\n    ]",
              "hints": [
                "Start by understanding the structure of a oauth_authentication. Look at the imports and main components needed."
              ],
              "learning_objectives": [
                "Understand how to implement a Oauth Authentication",
                "Practice writing clean, maintainable code for Oauth Authentication",
                "Apply OAuth feature: OAuth in your implementation",
                "Apply OAuth feature: oauth2 in your implementation"
              ]
            }
          ],
          "tags": [
            "database_migration",
            "jwt_authentication",
            "oauth_authentication",
            "session_authentication",
            "api_key_authentication",
            "password_hashing",
            "python_comprehensions"
          ]
        }
      ]
    }
  ]
}