{
  "lesson_id": "c0566b6d-190c-4a44-8392-231d97b7928a",
  "feature_mapping": {
    "feature_name": "Incremental Updater: Python Async Await",
    "user_facing_purpose": "Excellent teaching value (score: 0.88). Well-documented (100% coverage). Ideal complexity (avg: 3.3) for teaching. Contains useful patterns. Well-structured code. Demonstrates: python_context_managers, python_async_await, python_comprehensions",
    "business_value": "Manages incremental updates to course content.\r. Provides functionality for:. Implements Requirement 15.4: Provides access to course version history.",
    "entry_points": [
      "Class: IncrementalUpdateManager with 15 public method(s)"
    ],
    "feature_flow": [
      "User initiates the feature",
      "System processes the request",
      "System returns result to caller"
    ]
  },
  "evidence_bundle": {
    "source_files": [
      {
        "path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py",
        "code": "\"\"\"Incremental Course Update Manager.\n\nThis module provides incremental update functionality for courses.\nImplements Requirements 15.1, 15.2, 15.3, 15.4, 15.5:\n- Detects which lessons need updates based on file changes\n- Tracks course version history\n- Preserves manual edits to lesson content\n- Archives deleted lessons\n- Completes updates in <3s for <5 changes\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Dict, List, Optional, Set, Tuple, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\n\nfrom .models import CourseOutline, Module, Lesson, LessonContent\nfrom .course_cache import CourseCacheManager\nfrom src.models import CodebaseAnalysis\n\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass FileChange:\n    \"\"\"Represents a change to a source file.\"\"\"\n    file_path: str\n    change_type: str  # 'added', 'modified', 'deleted'\n    old_hash: Optional[str] = None\n    new_hash: Optional[str] = None\n    detected_at: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass LessonUpdate:\n    \"\"\"Represents an update to a lesson.\"\"\"\n    lesson_id: str\n    file_path: str\n    update_type: str  # 'content', 'structure', 'archived'\n    changes: List[str] = field(default_factory=list)\n    timestamp: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass CourseVersion:\n    \"\"\"Represents a version of the course.\"\"\"\n    version: str\n    created_at: datetime\n    updated_at: datetime\n    change_summary: str\n    lesson_updates: List[LessonUpdate] = field(default_factory=list)\n    file_changes: List[FileChange] = field(default_factory=list)\n    total_lessons: int = 0\n    updated_lessons: int = 0\n    archived_lessons: int = 0\n\n\nclass IncrementalUpdateManager:\n    \"\"\"Manages incremental updates to course content.\n    \n    Provides functionality for:\n    - Detecting file changes\n    - Identifying lessons that need updates\n    - Preserving manual edits\n    - Tracking version history\n    - Archiving deleted lessons\n    \"\"\"\n    \n    def __init__(self, cache_manager: CourseCacheManager, output_dir: str = \"output/courses\"):\n        \"\"\"Initialize the incremental update manager.\n        \n        Args:\n            cache_manager: Course cache manager instance\n            output_dir: Directory where course files are stored\n        \"\"\"\n        self.cache = cache_manager\n        self.output_dir = output_dir\n        \n        # Version history storage\n        self.version_history: Dict[str, List[CourseVersion]] = {}\n        \n        # Manual edit tracking\n        self.manual_edits: Dict[str, Set[str]] = {}  # lesson_id -> set of edited sections\n        \n        # File hash tracking for change detection\n        self.file_hashes: Dict[str, str] = {}\n        \n        # Archived lessons\n        self.archived_lessons: Dict[str, List[Lesson]] = {}  # course_id -> archived lessons\n    \n    def _compute_file_hash(self, file_path: str) -> str:\n        \"\"\"Compute SHA256 hash of file content.\n        \n        Args:\n            file_path: Path to file\n            \n        Returns:\n            SHA256 hash of file content\n        \"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                return hashlib.sha256(f.read()).hexdigest()\n        except Exception as e:\n            logger.warning(f\"Failed to hash file {file_path}: {e}\")\n            return \"\"\n    \n    def _get_file_mtime(self, file_path: str) -> float:\n        \"\"\"Get file modification time.\n        \n        Args:\n            file_path: Path to file\n            \n        Returns:\n            Modification time as timestamp\n        \"\"\"\n        try:\n            return os.path.getmtime(file_path)\n        except Exception as e:\n            logger.warning(f\"Failed to get mtime for {file_path}: {e}\")\n            return 0.0\n    \n    async def detect_file_changes(\n        self,\n        codebase_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> List[FileChange]:\n        \"\"\"Detect changes to source files since last course generation.\n        \n        Implements Requirement 15.1: Detects which lessons need updates based on file changes.\n        \n        Args:\n            codebase_id: Unique codebase identifier\n            current_files: List of current file paths in the codebase\n            analysis: Current codebase analysis\n            \n        Returns:\n            List of FileChange objects representing detected changes\n        \"\"\"\n        changes = []\n        \n        # Get cached course structure to find previous files\n        cached_course = await self.cache.get_course_structure(codebase_id)\n        \n        if not cached_course or \"file_paths\" not in cached_course:\n            # No previous course, all files are new\n            for file_path in current_files:\n                file_hash = self._compute_file_hash(file_path)\n                changes.append(FileChange(\n                    file_path=file_path,\n                    change_type='added',\n                    new_hash=file_hash\n                ))\n            return changes\n        \n        previous_files = set(cached_course[\"file_paths\"])\n        current_files_set = set(current_files)\n        \n        # Detect added files\n        added_files = current_files_set - previous_files\n        for file_path in added_files:\n            file_hash = self._compute_file_hash(file_path)\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='added',\n                new_hash=file_hash\n            ))\n            logger.info(f\"Detected added file: {file_path}\")\n        \n        # Detect deleted files\n        deleted_files = previous_files - current_files_set\n        for file_path in deleted_files:\n            old_hash = self.file_hashes.get(file_path, \"\")\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='deleted',\n                old_hash=old_hash\n            ))\n            logger.info(f\"Detected deleted file: {file_path}\")\n        \n        # Detect modified files\n        for file_path in current_files_set & previous_files:\n            current_hash = self._compute_file_hash(file_path)\n            \n            # Check if file has changed using cache\n            if await self.cache._is_file_changed(file_path):\n                old_hash = self.file_hashes.get(file_path, \"\")\n                if current_hash != old_hash:\n                    changes.append(FileChange(\n                        file_path=file_path,\n                        change_type='modified',\n                        old_hash=old_hash,\n                        new_hash=current_hash\n                    ))\n                    logger.info(f\"Detected modified file: {file_path}\")\n            \n            # Update hash tracking\n            self.file_hashes[file_path] = current_hash\n        \n        logger.info(\n            f\"Detected {len(changes)} file changes: \"\n            f\"{len(added_files)} added, {len(deleted_files)} deleted, \"\n            f\"{len([c for c in changes if c.change_type == 'modified'])} modified\"\n        )\n        \n        return changes\n    \n    def identify_lessons_to_update(\n        self,\n        course: CourseOutline,\n        file_changes: List[FileChange]\n    ) -> List[Tuple[Lesson, FileChange]]:\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        Implements Requirement 15.1: Detects which lessons need updates.\n        \n        Args:\n            course: Current course outline\n            file_changes: List of detected file changes\n            \n        Returns:\n            List of (Lesson, FileChange) tuples for lessons that need updates\n        \"\"\"\n        lessons_to_update = []\n        \n        # Build map of file_path -> lesson\n        file_to_lesson: Dict[str, Lesson] = {}\n        for module in course.modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n        \n        # Match file changes to lessons\n        for change in file_changes:\n            if change.file_path in file_to_lesson:\n                lesson = file_to_lesson[change.file_path]\n                \n                # Check if lesson has manual edits that should be preserved\n                if self._has_manual_edits(lesson.lesson_id):\n                    logger.info(\n                        f\"Lesson {lesson.lesson_id} has manual edits, \"\n                        f\"will preserve during update\"\n                    )\n                \n                lessons_to_update.append((lesson, change))\n        \n        logger.info(f\"Identified {len(lessons_to_update)} lessons to update\")\n        return lessons_to_update\n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        Implements Requirement 15.2: Preserves manual edits.\n        \n        Args:\n            lesson_id: Lesson identifier\n            \n        Returns:\n            True if lesson has manual edits, False otherwise\n        \"\"\"\n        return lesson_id in self.manual_edits and len(self.manual_edits[lesson_id]) > 0\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        Implements Requirement 15.2: Tracks manual edits to preserve them.\n        \n        Args:\n            lesson_id: Lesson identifier\n            section: Section name that was edited (e.g., 'introduction', 'explanation')\n        \"\"\"\n        if lesson_id not in self.manual_edits:\n            self.manual_edits[lesson_id] = set()\n        \n        self.manual_edits[lesson_id].add(section)\n        logger.info(f\"Marked manual edit: {lesson_id}.{section}\")\n    \n    def preserve_manual_edits(\n        self,\n        lesson_id: str,\n        old_content: LessonContent,\n        new_content: LessonContent\n    ) -> LessonContent:\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        Implements Requirement 15.2: Preserves manual edits to lesson content.\n        \n        Args:\n            lesson_id: Lesson identifier\n            old_content: Previous lesson content (may have manual edits)\n            new_content: Newly generated lesson content\n            \n        Returns:\n            Merged lesson content with manual edits preserved\n        \"\"\"\n        if not self._has_manual_edits(lesson_id):\n            return new_content\n        \n        edited_sections = self.manual_edits[lesson_id]\n        \n        # Create a copy of new content\n        merged_content = LessonContent(\n            introduction=new_content.introduction,\n            explanation=new_content.explanation,\n            code_example=new_content.code_example,\n            walkthrough=new_content.walkthrough,\n            summary=new_content.summary,\n            further_reading=new_content.further_reading\n        )\n        \n        # Preserve manually edited sections\n        if 'introduction' in edited_sections:\n            merged_content.introduction = old_content.introduction\n            logger.info(f\"Preserved manual edit: {lesson_id}.introduction\")\n        \n        if 'explanation' in edited_sections:\n            merged_content.explanation = old_content.explanation\n            logger.info(f\"Preserved manual edit: {lesson_id}.explanation\")\n        \n        if 'walkthrough' in edited_sections:\n            merged_content.walkthrough = old_content.walkthrough\n            logger.info(f\"Preserved manual edit: {lesson_id}.walkthrough\")\n        \n        if 'summary' in edited_sections:\n            merged_content.summary = old_content.summary\n            logger.info(f\"Preserved manual edit: {lesson_id}.summary\")\n        \n        if 'further_reading' in edited_sections:\n            merged_content.further_reading = old_content.further_reading\n            logger.info(f\"Preserved manual edit: {lesson_id}.further_reading\")\n        \n        # Note: code_example is always regenerated from source\n        \n        return merged_content\n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\n        \n        Args:\n            course_id: Course identifier\n            lesson: Lesson to archive\n            reason: Reason for archiving\n        \"\"\"\n        if course_id not in self.archived_lessons:\n            self.archived_lessons[course_id] = []\n        \n        # Add archive metadata\n        lesson.tags.append(f\"archived:{reason}\")\n        lesson.tags.append(f\"archived_at:{datetime.now().isoformat()}\")\n        \n        self.archived_lessons[course_id].append(lesson)\n        \n        logger.info(\n            f\"Archived lesson {lesson.lesson_id} ({lesson.title}) \"\n            f\"from course {course_id}: {reason}\"\n        )\n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of archived lessons\n        \"\"\"\n        return self.archived_lessons.get(course_id, [])\n    \n    def create_version(\n        self,\n        course_id: str,\n        version: str,\n        change_summary: str,\n        lesson_updates: List[LessonUpdate],\n        file_changes: List[FileChange],\n        total_lessons: int\n    ) -> CourseVersion:\n        \"\"\"Create a new course version entry.\n        \n        Implements Requirement 15.4: Tracks course version history.\n        \n        Args:\n            course_id: Course identifier\n            version: Version string (e.g., \"1.0.1\")\n            change_summary: Summary of changes\n            lesson_updates: List of lesson updates\n            file_changes: List of file changes\n            total_lessons: Total number of lessons in course\n            \n        Returns:\n            CourseVersion object\n        \"\"\"\n        now = datetime.now()\n        \n        course_version = CourseVersion(\n            version=version,\n            created_at=now,\n            updated_at=now,\n            change_summary=change_summary,\n            lesson_updates=lesson_updates,\n            file_changes=file_changes,\n            total_lessons=total_lessons,\n            updated_lessons=len(lesson_updates),\n            archived_lessons=len([u for u in lesson_updates if u.update_type == 'archived'])\n        )\n        \n        # Add to version history\n        if course_id not in self.version_history:\n            self.version_history[course_id] = []\n        \n        self.version_history[course_id].append(course_version)\n        \n        logger.info(\n            f\"Created course version {version} for {course_id}: \"\n            f\"{course_version.updated_lessons} lessons updated, \"\n            f\"{course_version.archived_lessons} lessons archived\"\n        )\n        \n        return course_version\n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        Implements Requirement 15.4: Provides access to course version history.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of CourseVersion objects, newest first (in reverse order of creation)\n        \"\"\"\n        history = self.version_history.get(course_id, [])\n        # Return in reverse order (newest first) since versions are appended chronologically\n        return list(reversed(history))\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Latest CourseVersion or None if no versions exist\n        \"\"\"\n        history = self.get_version_history(course_id)\n        return history[0] if history else None\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        Args:\n            current_version: Current version string (e.g., \"1.0.0\")\n            change_type: Type of change ('major', 'minor', 'patch')\n            \n        Returns:\n            New version string\n        \"\"\"\n        try:\n            parts = current_version.split('.')\n            major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])\n            \n            if change_type == 'major':\n                major += 1\n                minor = 0\n                patch = 0\n            elif change_type == 'minor':\n                minor += 1\n                patch = 0\n            else:  # patch\n                patch += 1\n            \n            return f\"{major}.{minor}.{patch}\"\n        except Exception as e:\n            logger.warning(f\"Failed to increment version {current_version}: {e}\")\n            return current_version\n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        Args:\n            course_id: Course identifier\n            output_path: Optional custom output path\n        \"\"\"\n        if output_path is None:\n            output_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        history = self.get_version_history(course_id)\n        \n        # Serialize to JSON\n        history_data = []\n        for version in history:\n            history_data.append({\n                \"version\": version.version,\n                \"created_at\": version.created_at.isoformat(),\n                \"updated_at\": version.updated_at.isoformat(),\n                \"change_summary\": version.change_summary,\n                \"total_lessons\": version.total_lessons,\n                \"updated_lessons\": version.updated_lessons,\n                \"archived_lessons\": version.archived_lessons,\n                \"lesson_updates\": [\n                    {\n                        \"lesson_id\": u.lesson_id,\n                        \"file_path\": u.file_path,\n                        \"update_type\": u.update_type,\n                        \"changes\": u.changes,\n                        \"timestamp\": u.timestamp.isoformat()\n                    }\n                    for u in version.lesson_updates\n                ],\n                \"file_changes\": [\n                    {\n                        \"file_path\": c.file_path,\n                        \"change_type\": c.change_type,\n                        \"old_hash\": c.old_hash,\n                        \"new_hash\": c.new_hash,\n                        \"detected_at\": c.detected_at.isoformat()\n                    }\n                    for c in version.file_changes\n                ]\n            })\n        \n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(history_data, f, indent=2)\n        \n        logger.info(f\"Saved version history to {output_path}\")\n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        Args:\n            course_id: Course identifier\n            input_path: Optional custom input path\n        \"\"\"\n        if input_path is None:\n            input_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        if not os.path.exists(input_path):\n            logger.debug(f\"No version history file found at {input_path}\")\n            return\n        \n        try:\n            with open(input_path, 'r', encoding='utf-8') as f:\n                history_data = json.load(f)\n            \n            # Deserialize from JSON\n            versions = []\n            for data in history_data:\n                version = CourseVersion(\n                    version=data[\"version\"],\n                    created_at=datetime.fromisoformat(data[\"created_at\"]),\n                    updated_at=datetime.fromisoformat(data[\"updated_at\"]),\n                    change_summary=data[\"change_summary\"],\n                    total_lessons=data[\"total_lessons\"],\n                    updated_lessons=data[\"updated_lessons\"],\n                    archived_lessons=data[\"archived_lessons\"],\n                    lesson_updates=[\n                        LessonUpdate(\n                            lesson_id=u[\"lesson_id\"],\n                            file_path=u[\"file_path\"],\n                            update_type=u[\"update_type\"],\n                            changes=u[\"changes\"],\n                            timestamp=datetime.fromisoformat(u[\"timestamp\"])\n                        )\n                        for u in data[\"lesson_updates\"]\n                    ],\n                    file_changes=[\n                        FileChange(\n                            file_path=c[\"file_path\"],\n                            change_type=c[\"change_type\"],\n                            old_hash=c.get(\"old_hash\"),\n                            new_hash=c.get(\"new_hash\"),\n                            detected_at=datetime.fromisoformat(c[\"detected_at\"])\n                        )\n                        for c in data[\"file_changes\"]\n                    ]\n                )\n                versions.append(version)\n            \n            self.version_history[course_id] = versions\n            logger.info(f\"Loaded {len(versions)} versions from {input_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to load version history from {input_path}: {e}\")\n\n\n    async def update_course_incrementally(\n        self,\n        course: CourseOutline,\n        analysis: CodebaseAnalysis,\n        file_changes: List[FileChange],\n        content_generator,\n        structure_generator\n    ) -> Tuple[CourseOutline, CourseVersion]:\n        \"\"\"Update course incrementally based on file changes.\n        \n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\n        - Updates only changed lessons\n        - Preserves manual edits\n        - Archives deleted lessons\n        - Completes updates in <3s for <5 changes\n        \n        Args:\n            course: Current course outline\n            analysis: Current codebase analysis\n            file_changes: List of detected file changes\n            content_generator: LessonContentGenerator instance\n            structure_generator: CourseStructureGenerator instance\n            \n        Returns:\n            Tuple of (updated CourseOutline, CourseVersion)\n        \"\"\"\n        start_time = time.time()\n        \n        logger.info(\n            f\"Starting incremental update for course {course.course_id} \"\n            f\"with {len(file_changes)} file changes\"\n        )\n        \n        # Identify lessons to update\n        lessons_to_update = self.identify_lessons_to_update(course, file_changes)\n        \n        # Track updates\n        lesson_updates: List[LessonUpdate] = []\n        \n        # Process each lesson update\n        for lesson, change in lessons_to_update:\n            if change.change_type == 'deleted':\n                # Archive the lesson\n                self.archive_lesson(course.course_id, lesson, \"file_deleted\")\n                lesson_updates.append(LessonUpdate(\n                    lesson_id=lesson.lesson_id,\n                    file_path=lesson.file_path,\n                    update_type='archived',\n                    changes=['File deleted, lesson archived']\n                ))\n            \n            elif change.change_type in ['added', 'modified']:\n                # Update lesson content\n                update = await self._update_lesson_content(\n                    lesson,\n                    analysis,\n                    content_generator\n                )\n                lesson_updates.append(update)\n        \n        # Remove archived lessons from course\n        course = self._remove_archived_lessons(course, lesson_updates)\n        \n        # Update course metadata\n        course.version = self.increment_version(\n            course.version,\n            'minor' if len(file_changes) > 5 else 'patch'\n        )\n        course.created_at = datetime.now()  # Update timestamp\n        \n        # Create version entry\n        change_summary = self._generate_change_summary(file_changes, lesson_updates)\n        version = self.create_version(\n            course.course_id,\n            course.version,\n            change_summary,\n            lesson_updates,\n            file_changes,\n            self._count_total_lessons(course)\n        )\n        \n        # Save version history\n        self.save_version_history(course.course_id)\n        \n        elapsed_time = time.time() - start_time\n        logger.info(\n            f\"Incremental update completed in {elapsed_time:.2f}s: \"\n            f\"{len(lesson_updates)} lessons updated\"\n        )\n        \n        # Verify performance requirement (Req 15.5)\n        if len(file_changes) < 5 and elapsed_time > 3.0:\n            logger.warning(\n                f\"Update took {elapsed_time:.2f}s for {len(file_changes)} changes, \"\n                f\"exceeding 3s target\"\n            )\n        \n        return course, version\n    \n    async def _update_lesson_content(\n        self,\n        lesson: Lesson,\n        analysis: CodebaseAnalysis,\n        content_generator\n    ) -> LessonUpdate:\n        \"\"\"Update content for a single lesson.\n        \n        Implements Requirement 15.2: Preserves manual edits during update.\n        \n        Args:\n            lesson: Lesson to update\n            analysis: Current codebase analysis\n            content_generator: LessonContentGenerator instance\n            \n        Returns:\n            LessonUpdate describing the changes\n        \"\"\"\n        changes = []\n        \n        # Get file analysis\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            logger.warning(f\"No analysis found for {lesson.file_path}\")\n            return LessonUpdate(\n                lesson_id=lesson.lesson_id,\n                file_path=lesson.file_path,\n                update_type='content',\n                changes=['No analysis available']\n            )\n        \n        # Store old content if it exists\n        old_content = lesson.content\n        \n        # Generate new content\n        new_content = await content_generator.generate_lesson_content(file_analysis)\n        \n        # Preserve manual edits if any\n        if old_content and self._has_manual_edits(lesson.lesson_id):\n            merged_content = self.preserve_manual_edits(\n                lesson.lesson_id,\n                old_content,\n                new_content\n            )\n            lesson.content = merged_content\n            changes.append(\"Preserved manual edits\")\n        else:\n            lesson.content = new_content\n            changes.append(\"Regenerated content\")\n        \n        # Update lesson metadata\n        lesson.teaching_value = file_analysis.teaching_value.score\n        \n        # Update learning objectives if patterns changed\n        old_patterns = set(lesson.concepts)\n        new_patterns = set(p.pattern_type for p in file_analysis.patterns)\n        \n        if old_patterns != new_patterns:\n            lesson.concepts = list(new_patterns)\n            lesson.tags = list(new_patterns)\n            changes.append(f\"Updated patterns: {new_patterns - old_patterns}\")\n        \n        # Update complexity-based difficulty\n        new_difficulty = self._calculate_difficulty(file_analysis)\n        if new_difficulty != lesson.difficulty:\n            old_diff = lesson.difficulty\n            lesson.difficulty = new_difficulty\n            changes.append(f\"Difficulty changed: {old_diff} -> {new_difficulty}\")\n        \n        return LessonUpdate(\n            lesson_id=lesson.lesson_id,\n            file_path=lesson.file_path,\n            update_type='content',\n            changes=changes\n        )\n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        Args:\n            file_analysis: FileAnalysis object\n            \n        Returns:\n            Difficulty level string\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n    \n    def _remove_archived_lessons(\n        self,\n        course: CourseOutline,\n        lesson_updates: List[LessonUpdate]\n    ) -> CourseOutline:\n        \"\"\"Remove archived lessons from course structure.\n        \n        Args:\n            course: Course outline\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Updated course outline\n        \"\"\"\n        archived_ids = {\n            u.lesson_id for u in lesson_updates\n            if u.update_type == 'archived'\n        }\n        \n        if not archived_ids:\n            return course\n        \n        # Remove archived lessons from modules\n        for module in course.modules:\n            module.lessons = [\n                lesson for lesson in module.lessons\n                if lesson.lesson_id not in archived_ids\n            ]\n            \n            # Update lesson order after removal\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n            \n            # Update module duration\n            module.duration_hours = sum(l.duration_minutes for l in module.lessons) / 60.0\n        \n        # Remove empty modules\n        course.modules = [m for m in course.modules if len(m.lessons) > 0]\n        \n        # Update module order\n        for idx, module in enumerate(course.modules):\n            module.order = idx\n        \n        # Update course duration\n        course.total_duration_hours = sum(m.duration_hours for m in course.modules)\n        \n        # Update difficulty distribution\n        course.difficulty_distribution = self._calculate_difficulty_distribution(course)\n        \n        logger.info(f\"Removed {len(archived_ids)} archived lessons from course\")\n        \n        return course\n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Dictionary mapping difficulty levels to counts\n        \"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        \n        for module in course.modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n        \n        return distribution\n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Total number of lessons\n        \"\"\"\n        return sum(len(module.lessons) for module in course.modules)\n    \n    def _generate_change_summary(\n        self,\n        file_changes: List[FileChange],\n        lesson_updates: List[LessonUpdate]\n    ) -> str:\n        \"\"\"Generate a human-readable summary of changes.\n        \n        Args:\n            file_changes: List of file changes\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Change summary string\n        \"\"\"\n        parts = []\n        \n        # Count change types\n        added = len([c for c in file_changes if c.change_type == 'added'])\n        modified = len([c for c in file_changes if c.change_type == 'modified'])\n        deleted = len([c for c in file_changes if c.change_type == 'deleted'])\n        \n        if added > 0:\n            parts.append(f\"{added} file(s) added\")\n        if modified > 0:\n            parts.append(f\"{modified} file(s) modified\")\n        if deleted > 0:\n            parts.append(f\"{deleted} file(s) deleted\")\n        \n        # Count update types\n        content_updates = len([u for u in lesson_updates if u.update_type == 'content'])\n        archived = len([u for u in lesson_updates if u.update_type == 'archived'])\n        \n        if content_updates > 0:\n            parts.append(f\"{content_updates} lesson(s) updated\")\n        if archived > 0:\n            parts.append(f\"{archived} lesson(s) archived\")\n        \n        return \", \".join(parts) if parts else \"No changes\"\n    \n    async def check_for_updates(\n        self,\n        course_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> Tuple[bool, List[FileChange]]:\n        \"\"\"Check if course needs updates.\n        \n        Args:\n            course_id: Course identifier\n            current_files: List of current file paths\n            analysis: Current codebase analysis\n            \n        Returns:\n            Tuple of (needs_update, file_changes)\n        \"\"\"\n        file_changes = await self.detect_file_changes(\n            course_id,\n            current_files,\n            analysis\n        )\n        \n        needs_update = len(file_changes) > 0\n        \n        return needs_update, file_changes\n    \n    def get_update_statistics(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics about course updates.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Dictionary with update statistics\n        \"\"\"\n        history = self.get_version_history(course_id)\n        \n        if not history:\n            return {\n                \"total_versions\": 0,\n                \"total_updates\": 0,\n                \"total_archived\": 0,\n                \"latest_version\": None,\n                \"last_updated\": None\n            }\n        \n        total_updates = sum(v.updated_lessons for v in history)\n        total_archived = sum(v.archived_lessons for v in history)\n        latest = history[0]\n        \n        return {\n            \"total_versions\": len(history),\n            \"total_updates\": total_updates,\n            \"total_archived\": total_archived,\n            \"latest_version\": latest.version,\n            \"last_updated\": latest.updated_at.isoformat(),\n            \"manual_edits\": len(self.manual_edits),\n            \"archived_lessons\": len(self.archived_lessons.get(course_id, []))\n        }\n",
        "lines": 974,
        "language": "python",
        "sections": [
          {
            "start_line": 1,
            "end_line": 974,
            "description": "Complete file",
            "code": "\"\"\"Incremental Course Update Manager.\n\nThis module provides incremental update functionality for courses.\nImplements Requirements 15.1, 15.2, 15.3, 15.4, 15.5:\n- Detects which lessons need updates based on file changes\n- Tracks course version history\n- Preserves manual edits to lesson content\n- Archives deleted lessons\n- Completes updates in <3s for <5 changes\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Dict, List, Optional, Set, Tuple, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\n\nfrom .models import CourseOutline, Module, Lesson, LessonContent\nfrom .course_cache import CourseCacheManager\nfrom src.models import CodebaseAnalysis\n\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass FileChange:\n    \"\"\"Represents a change to a source file.\"\"\"\n    file_path: str\n    change_type: str  # 'added', 'modified', 'deleted'\n    old_hash: Optional[str] = None\n    new_hash: Optional[str] = None\n    detected_at: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass LessonUpdate:\n    \"\"\"Represents an update to a lesson.\"\"\"\n    lesson_id: str\n    file_path: str\n    update_type: str  # 'content', 'structure', 'archived'\n    changes: List[str] = field(default_factory=list)\n    timestamp: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass CourseVersion:\n    \"\"\"Represents a version of the course.\"\"\"\n    version: str\n    created_at: datetime\n    updated_at: datetime\n    change_summary: str\n    lesson_updates: List[LessonUpdate] = field(default_factory=list)\n    file_changes: List[FileChange] = field(default_factory=list)\n    total_lessons: int = 0\n    updated_lessons: int = 0\n    archived_lessons: int = 0\n\n\nclass IncrementalUpdateManager:\n    \"\"\"Manages incremental updates to course content.\n    \n    Provides functionality for:\n    - Detecting file changes\n    - Identifying lessons that need updates\n    - Preserving manual edits\n    - Tracking version history\n    - Archiving deleted lessons\n    \"\"\"\n    \n    def __init__(self, cache_manager: CourseCacheManager, output_dir: str = \"output/courses\"):\n        \"\"\"Initialize the incremental update manager.\n        \n        Args:\n            cache_manager: Course cache manager instance\n            output_dir: Directory where course files are stored\n        \"\"\"\n        self.cache = cache_manager\n        self.output_dir = output_dir\n        \n        # Version history storage\n        self.version_history: Dict[str, List[CourseVersion]] = {}\n        \n        # Manual edit tracking\n        self.manual_edits: Dict[str, Set[str]] = {}  # lesson_id -> set of edited sections\n        \n        # File hash tracking for change detection\n        self.file_hashes: Dict[str, str] = {}\n        \n        # Archived lessons\n        self.archived_lessons: Dict[str, List[Lesson]] = {}  # course_id -> archived lessons\n    \n    def _compute_file_hash(self, file_path: str) -> str:\n        \"\"\"Compute SHA256 hash of file content.\n        \n        Args:\n            file_path: Path to file\n            \n        Returns:\n            SHA256 hash of file content\n        \"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                return hashlib.sha256(f.read()).hexdigest()\n        except Exception as e:\n            logger.warning(f\"Failed to hash file {file_path}: {e}\")\n            return \"\"\n    \n    def _get_file_mtime(self, file_path: str) -> float:\n        \"\"\"Get file modification time.\n        \n        Args:\n            file_path: Path to file\n            \n        Returns:\n            Modification time as timestamp\n        \"\"\"\n        try:\n            return os.path.getmtime(file_path)\n        except Exception as e:\n            logger.warning(f\"Failed to get mtime for {file_path}: {e}\")\n            return 0.0\n    \n    async def detect_file_changes(\n        self,\n        codebase_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> List[FileChange]:\n        \"\"\"Detect changes to source files since last course generation.\n        \n        Implements Requirement 15.1: Detects which lessons need updates based on file changes.\n        \n        Args:\n            codebase_id: Unique codebase identifier\n            current_files: List of current file paths in the codebase\n            analysis: Current codebase analysis\n            \n        Returns:\n            List of FileChange objects representing detected changes\n        \"\"\"\n        changes = []\n        \n        # Get cached course structure to find previous files\n        cached_course = await self.cache.get_course_structure(codebase_id)\n        \n        if not cached_course or \"file_paths\" not in cached_course:\n            # No previous course, all files are new\n            for file_path in current_files:\n                file_hash = self._compute_file_hash(file_path)\n                changes.append(FileChange(\n                    file_path=file_path,\n                    change_type='added',\n                    new_hash=file_hash\n                ))\n            return changes\n        \n        previous_files = set(cached_course[\"file_paths\"])\n        current_files_set = set(current_files)\n        \n        # Detect added files\n        added_files = current_files_set - previous_files\n        for file_path in added_files:\n            file_hash = self._compute_file_hash(file_path)\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='added',\n                new_hash=file_hash\n            ))\n            logger.info(f\"Detected added file: {file_path}\")\n        \n        # Detect deleted files\n        deleted_files = previous_files - current_files_set\n        for file_path in deleted_files:\n            old_hash = self.file_hashes.get(file_path, \"\")\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='deleted',\n                old_hash=old_hash\n            ))\n            logger.info(f\"Detected deleted file: {file_path}\")\n        \n        # Detect modified files\n        for file_path in current_files_set & previous_files:\n            current_hash = self._compute_file_hash(file_path)\n            \n            # Check if file has changed using cache\n            if await self.cache._is_file_changed(file_path):\n                old_hash = self.file_hashes.get(file_path, \"\")\n                if current_hash != old_hash:\n                    changes.append(FileChange(\n                        file_path=file_path,\n                        change_type='modified',\n                        old_hash=old_hash,\n                        new_hash=current_hash\n                    ))\n                    logger.info(f\"Detected modified file: {file_path}\")\n            \n            # Update hash tracking\n            self.file_hashes[file_path] = current_hash\n        \n        logger.info(\n            f\"Detected {len(changes)} file changes: \"\n            f\"{len(added_files)} added, {len(deleted_files)} deleted, \"\n            f\"{len([c for c in changes if c.change_type == 'modified'])} modified\"\n        )\n        \n        return changes\n    \n    def identify_lessons_to_update(\n        self,\n        course: CourseOutline,\n        file_changes: List[FileChange]\n    ) -> List[Tuple[Lesson, FileChange]]:\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        Implements Requirement 15.1: Detects which lessons need updates.\n        \n        Args:\n            course: Current course outline\n            file_changes: List of detected file changes\n            \n        Returns:\n            List of (Lesson, FileChange) tuples for lessons that need updates\n        \"\"\"\n        lessons_to_update = []\n        \n        # Build map of file_path -> lesson\n        file_to_lesson: Dict[str, Lesson] = {}\n        for module in course.modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n        \n        # Match file changes to lessons\n        for change in file_changes:\n            if change.file_path in file_to_lesson:\n                lesson = file_to_lesson[change.file_path]\n                \n                # Check if lesson has manual edits that should be preserved\n                if self._has_manual_edits(lesson.lesson_id):\n                    logger.info(\n                        f\"Lesson {lesson.lesson_id} has manual edits, \"\n                        f\"will preserve during update\"\n                    )\n                \n                lessons_to_update.append((lesson, change))\n        \n        logger.info(f\"Identified {len(lessons_to_update)} lessons to update\")\n        return lessons_to_update\n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        Implements Requirement 15.2: Preserves manual edits.\n        \n        Args:\n            lesson_id: Lesson identifier\n            \n        Returns:\n            True if lesson has manual edits, False otherwise\n        \"\"\"\n        return lesson_id in self.manual_edits and len(self.manual_edits[lesson_id]) > 0\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        Implements Requirement 15.2: Tracks manual edits to preserve them.\n        \n        Args:\n            lesson_id: Lesson identifier\n            section: Section name that was edited (e.g., 'introduction', 'explanation')\n        \"\"\"\n        if lesson_id not in self.manual_edits:\n            self.manual_edits[lesson_id] = set()\n        \n        self.manual_edits[lesson_id].add(section)\n        logger.info(f\"Marked manual edit: {lesson_id}.{section}\")\n    \n    def preserve_manual_edits(\n        self,\n        lesson_id: str,\n        old_content: LessonContent,\n        new_content: LessonContent\n    ) -> LessonContent:\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        Implements Requirement 15.2: Preserves manual edits to lesson content.\n        \n        Args:\n            lesson_id: Lesson identifier\n            old_content: Previous lesson content (may have manual edits)\n            new_content: Newly generated lesson content\n            \n        Returns:\n            Merged lesson content with manual edits preserved\n        \"\"\"\n        if not self._has_manual_edits(lesson_id):\n            return new_content\n        \n        edited_sections = self.manual_edits[lesson_id]\n        \n        # Create a copy of new content\n        merged_content = LessonContent(\n            introduction=new_content.introduction,\n            explanation=new_content.explanation,\n            code_example=new_content.code_example,\n            walkthrough=new_content.walkthrough,\n            summary=new_content.summary,\n            further_reading=new_content.further_reading\n        )\n        \n        # Preserve manually edited sections\n        if 'introduction' in edited_sections:\n            merged_content.introduction = old_content.introduction\n            logger.info(f\"Preserved manual edit: {lesson_id}.introduction\")\n        \n        if 'explanation' in edited_sections:\n            merged_content.explanation = old_content.explanation\n            logger.info(f\"Preserved manual edit: {lesson_id}.explanation\")\n        \n        if 'walkthrough' in edited_sections:\n            merged_content.walkthrough = old_content.walkthrough\n            logger.info(f\"Preserved manual edit: {lesson_id}.walkthrough\")\n        \n        if 'summary' in edited_sections:\n            merged_content.summary = old_content.summary\n            logger.info(f\"Preserved manual edit: {lesson_id}.summary\")\n        \n        if 'further_reading' in edited_sections:\n            merged_content.further_reading = old_content.further_reading\n            logger.info(f\"Preserved manual edit: {lesson_id}.further_reading\")\n        \n        # Note: code_example is always regenerated from source\n        \n        return merged_content\n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\n        \n        Args:\n            course_id: Course identifier\n            lesson: Lesson to archive\n            reason: Reason for archiving\n        \"\"\"\n        if course_id not in self.archived_lessons:\n            self.archived_lessons[course_id] = []\n        \n        # Add archive metadata\n        lesson.tags.append(f\"archived:{reason}\")\n        lesson.tags.append(f\"archived_at:{datetime.now().isoformat()}\")\n        \n        self.archived_lessons[course_id].append(lesson)\n        \n        logger.info(\n            f\"Archived lesson {lesson.lesson_id} ({lesson.title}) \"\n            f\"from course {course_id}: {reason}\"\n        )\n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of archived lessons\n        \"\"\"\n        return self.archived_lessons.get(course_id, [])\n    \n    def create_version(\n        self,\n        course_id: str,\n        version: str,\n        change_summary: str,\n        lesson_updates: List[LessonUpdate],\n        file_changes: List[FileChange],\n        total_lessons: int\n    ) -> CourseVersion:\n        \"\"\"Create a new course version entry.\n        \n        Implements Requirement 15.4: Tracks course version history.\n        \n        Args:\n            course_id: Course identifier\n            version: Version string (e.g., \"1.0.1\")\n            change_summary: Summary of changes\n            lesson_updates: List of lesson updates\n            file_changes: List of file changes\n            total_lessons: Total number of lessons in course\n            \n        Returns:\n            CourseVersion object\n        \"\"\"\n        now = datetime.now()\n        \n        course_version = CourseVersion(\n            version=version,\n            created_at=now,\n            updated_at=now,\n            change_summary=change_summary,\n            lesson_updates=lesson_updates,\n            file_changes=file_changes,\n            total_lessons=total_lessons,\n            updated_lessons=len(lesson_updates),\n            archived_lessons=len([u for u in lesson_updates if u.update_type == 'archived'])\n        )\n        \n        # Add to version history\n        if course_id not in self.version_history:\n            self.version_history[course_id] = []\n        \n        self.version_history[course_id].append(course_version)\n        \n        logger.info(\n            f\"Created course version {version} for {course_id}: \"\n            f\"{course_version.updated_lessons} lessons updated, \"\n            f\"{course_version.archived_lessons} lessons archived\"\n        )\n        \n        return course_version\n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        Implements Requirement 15.4: Provides access to course version history.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of CourseVersion objects, newest first (in reverse order of creation)\n        \"\"\"\n        history = self.version_history.get(course_id, [])\n        # Return in reverse order (newest first) since versions are appended chronologically\n        return list(reversed(history))\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Latest CourseVersion or None if no versions exist\n        \"\"\"\n        history = self.get_version_history(course_id)\n        return history[0] if history else None\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        Args:\n            current_version: Current version string (e.g., \"1.0.0\")\n            change_type: Type of change ('major', 'minor', 'patch')\n            \n        Returns:\n            New version string\n        \"\"\"\n        try:\n            parts = current_version.split('.')\n            major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])\n            \n            if change_type == 'major':\n                major += 1\n                minor = 0\n                patch = 0\n            elif change_type == 'minor':\n                minor += 1\n                patch = 0\n            else:  # patch\n                patch += 1\n            \n            return f\"{major}.{minor}.{patch}\"\n        except Exception as e:\n            logger.warning(f\"Failed to increment version {current_version}: {e}\")\n            return current_version\n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        Args:\n            course_id: Course identifier\n            output_path: Optional custom output path\n        \"\"\"\n        if output_path is None:\n            output_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        history = self.get_version_history(course_id)\n        \n        # Serialize to JSON\n        history_data = []\n        for version in history:\n            history_data.append({\n                \"version\": version.version,\n                \"created_at\": version.created_at.isoformat(),\n                \"updated_at\": version.updated_at.isoformat(),\n                \"change_summary\": version.change_summary,\n                \"total_lessons\": version.total_lessons,\n                \"updated_lessons\": version.updated_lessons,\n                \"archived_lessons\": version.archived_lessons,\n                \"lesson_updates\": [\n                    {\n                        \"lesson_id\": u.lesson_id,\n                        \"file_path\": u.file_path,\n                        \"update_type\": u.update_type,\n                        \"changes\": u.changes,\n                        \"timestamp\": u.timestamp.isoformat()\n                    }\n                    for u in version.lesson_updates\n                ],\n                \"file_changes\": [\n                    {\n                        \"file_path\": c.file_path,\n                        \"change_type\": c.change_type,\n                        \"old_hash\": c.old_hash,\n                        \"new_hash\": c.new_hash,\n                        \"detected_at\": c.detected_at.isoformat()\n                    }\n                    for c in version.file_changes\n                ]\n            })\n        \n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(history_data, f, indent=2)\n        \n        logger.info(f\"Saved version history to {output_path}\")\n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        Args:\n            course_id: Course identifier\n            input_path: Optional custom input path\n        \"\"\"\n        if input_path is None:\n            input_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        if not os.path.exists(input_path):\n            logger.debug(f\"No version history file found at {input_path}\")\n            return\n        \n        try:\n            with open(input_path, 'r', encoding='utf-8') as f:\n                history_data = json.load(f)\n            \n            # Deserialize from JSON\n            versions = []\n            for data in history_data:\n                version = CourseVersion(\n                    version=data[\"version\"],\n                    created_at=datetime.fromisoformat(data[\"created_at\"]),\n                    updated_at=datetime.fromisoformat(data[\"updated_at\"]),\n                    change_summary=data[\"change_summary\"],\n                    total_lessons=data[\"total_lessons\"],\n                    updated_lessons=data[\"updated_lessons\"],\n                    archived_lessons=data[\"archived_lessons\"],\n                    lesson_updates=[\n                        LessonUpdate(\n                            lesson_id=u[\"lesson_id\"],\n                            file_path=u[\"file_path\"],\n                            update_type=u[\"update_type\"],\n                            changes=u[\"changes\"],\n                            timestamp=datetime.fromisoformat(u[\"timestamp\"])\n                        )\n                        for u in data[\"lesson_updates\"]\n                    ],\n                    file_changes=[\n                        FileChange(\n                            file_path=c[\"file_path\"],\n                            change_type=c[\"change_type\"],\n                            old_hash=c.get(\"old_hash\"),\n                            new_hash=c.get(\"new_hash\"),\n                            detected_at=datetime.fromisoformat(c[\"detected_at\"])\n                        )\n                        for c in data[\"file_changes\"]\n                    ]\n                )\n                versions.append(version)\n            \n            self.version_history[course_id] = versions\n            logger.info(f\"Loaded {len(versions)} versions from {input_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to load version history from {input_path}: {e}\")\n\n\n    async def update_course_incrementally(\n        self,\n        course: CourseOutline,\n        analysis: CodebaseAnalysis,\n        file_changes: List[FileChange],\n        content_generator,\n        structure_generator\n    ) -> Tuple[CourseOutline, CourseVersion]:\n        \"\"\"Update course incrementally based on file changes.\n        \n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\n        - Updates only changed lessons\n        - Preserves manual edits\n        - Archives deleted lessons\n        - Completes updates in <3s for <5 changes\n        \n        Args:\n            course: Current course outline\n            analysis: Current codebase analysis\n            file_changes: List of detected file changes\n            content_generator: LessonContentGenerator instance\n            structure_generator: CourseStructureGenerator instance\n            \n        Returns:\n            Tuple of (updated CourseOutline, CourseVersion)\n        \"\"\"\n        start_time = time.time()\n        \n        logger.info(\n            f\"Starting incremental update for course {course.course_id} \"\n            f\"with {len(file_changes)} file changes\"\n        )\n        \n        # Identify lessons to update\n        lessons_to_update = self.identify_lessons_to_update(course, file_changes)\n        \n        # Track updates\n        lesson_updates: List[LessonUpdate] = []\n        \n        # Process each lesson update\n        for lesson, change in lessons_to_update:\n            if change.change_type == 'deleted':\n                # Archive the lesson\n                self.archive_lesson(course.course_id, lesson, \"file_deleted\")\n                lesson_updates.append(LessonUpdate(\n                    lesson_id=lesson.lesson_id,\n                    file_path=lesson.file_path,\n                    update_type='archived',\n                    changes=['File deleted, lesson archived']\n                ))\n            \n            elif change.change_type in ['added', 'modified']:\n                # Update lesson content\n                update = await self._update_lesson_content(\n                    lesson,\n                    analysis,\n                    content_generator\n                )\n                lesson_updates.append(update)\n        \n        # Remove archived lessons from course\n        course = self._remove_archived_lessons(course, lesson_updates)\n        \n        # Update course metadata\n        course.version = self.increment_version(\n            course.version,\n            'minor' if len(file_changes) > 5 else 'patch'\n        )\n        course.created_at = datetime.now()  # Update timestamp\n        \n        # Create version entry\n        change_summary = self._generate_change_summary(file_changes, lesson_updates)\n        version = self.create_version(\n            course.course_id,\n            course.version,\n            change_summary,\n            lesson_updates,\n            file_changes,\n            self._count_total_lessons(course)\n        )\n        \n        # Save version history\n        self.save_version_history(course.course_id)\n        \n        elapsed_time = time.time() - start_time\n        logger.info(\n            f\"Incremental update completed in {elapsed_time:.2f}s: \"\n            f\"{len(lesson_updates)} lessons updated\"\n        )\n        \n        # Verify performance requirement (Req 15.5)\n        if len(file_changes) < 5 and elapsed_time > 3.0:\n            logger.warning(\n                f\"Update took {elapsed_time:.2f}s for {len(file_changes)} changes, \"\n                f\"exceeding 3s target\"\n            )\n        \n        return course, version\n    \n    async def _update_lesson_content(\n        self,\n        lesson: Lesson,\n        analysis: CodebaseAnalysis,\n        content_generator\n    ) -> LessonUpdate:\n        \"\"\"Update content for a single lesson.\n        \n        Implements Requirement 15.2: Preserves manual edits during update.\n        \n        Args:\n            lesson: Lesson to update\n            analysis: Current codebase analysis\n            content_generator: LessonContentGenerator instance\n            \n        Returns:\n            LessonUpdate describing the changes\n        \"\"\"\n        changes = []\n        \n        # Get file analysis\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            logger.warning(f\"No analysis found for {lesson.file_path}\")\n            return LessonUpdate(\n                lesson_id=lesson.lesson_id,\n                file_path=lesson.file_path,\n                update_type='content',\n                changes=['No analysis available']\n            )\n        \n        # Store old content if it exists\n        old_content = lesson.content\n        \n        # Generate new content\n        new_content = await content_generator.generate_lesson_content(file_analysis)\n        \n        # Preserve manual edits if any\n        if old_content and self._has_manual_edits(lesson.lesson_id):\n            merged_content = self.preserve_manual_edits(\n                lesson.lesson_id,\n                old_content,\n                new_content\n            )\n            lesson.content = merged_content\n            changes.append(\"Preserved manual edits\")\n        else:\n            lesson.content = new_content\n            changes.append(\"Regenerated content\")\n        \n        # Update lesson metadata\n        lesson.teaching_value = file_analysis.teaching_value.score\n        \n        # Update learning objectives if patterns changed\n        old_patterns = set(lesson.concepts)\n        new_patterns = set(p.pattern_type for p in file_analysis.patterns)\n        \n        if old_patterns != new_patterns:\n            lesson.concepts = list(new_patterns)\n            lesson.tags = list(new_patterns)\n            changes.append(f\"Updated patterns: {new_patterns - old_patterns}\")\n        \n        # Update complexity-based difficulty\n        new_difficulty = self._calculate_difficulty(file_analysis)\n        if new_difficulty != lesson.difficulty:\n            old_diff = lesson.difficulty\n            lesson.difficulty = new_difficulty\n            changes.append(f\"Difficulty changed: {old_diff} -> {new_difficulty}\")\n        \n        return LessonUpdate(\n            lesson_id=lesson.lesson_id,\n            file_path=lesson.file_path,\n            update_type='content',\n            changes=changes\n        )\n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        Args:\n            file_analysis: FileAnalysis object\n            \n        Returns:\n            Difficulty level string\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n    \n    def _remove_archived_lessons(\n        self,\n        course: CourseOutline,\n        lesson_updates: List[LessonUpdate]\n    ) -> CourseOutline:\n        \"\"\"Remove archived lessons from course structure.\n        \n        Args:\n            course: Course outline\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Updated course outline\n        \"\"\"\n        archived_ids = {\n            u.lesson_id for u in lesson_updates\n            if u.update_type == 'archived'\n        }\n        \n        if not archived_ids:\n            return course\n        \n        # Remove archived lessons from modules\n        for module in course.modules:\n            module.lessons = [\n                lesson for lesson in module.lessons\n                if lesson.lesson_id not in archived_ids\n            ]\n            \n            # Update lesson order after removal\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n            \n            # Update module duration\n            module.duration_hours = sum(l.duration_minutes for l in module.lessons) / 60.0\n        \n        # Remove empty modules\n        course.modules = [m for m in course.modules if len(m.lessons) > 0]\n        \n        # Update module order\n        for idx, module in enumerate(course.modules):\n            module.order = idx\n        \n        # Update course duration\n        course.total_duration_hours = sum(m.duration_hours for m in course.modules)\n        \n        # Update difficulty distribution\n        course.difficulty_distribution = self._calculate_difficulty_distribution(course)\n        \n        logger.info(f\"Removed {len(archived_ids)} archived lessons from course\")\n        \n        return course\n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Dictionary mapping difficulty levels to counts\n        \"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        \n        for module in course.modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n        \n        return distribution\n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Total number of lessons\n        \"\"\"\n        return sum(len(module.lessons) for module in course.modules)\n    \n    def _generate_change_summary(\n        self,\n        file_changes: List[FileChange],\n        lesson_updates: List[LessonUpdate]\n    ) -> str:\n        \"\"\"Generate a human-readable summary of changes.\n        \n        Args:\n            file_changes: List of file changes\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Change summary string\n        \"\"\"\n        parts = []\n        \n        # Count change types\n        added = len([c for c in file_changes if c.change_type == 'added'])\n        modified = len([c for c in file_changes if c.change_type == 'modified'])\n        deleted = len([c for c in file_changes if c.change_type == 'deleted'])\n        \n        if added > 0:\n            parts.append(f\"{added} file(s) added\")\n        if modified > 0:\n            parts.append(f\"{modified} file(s) modified\")\n        if deleted > 0:\n            parts.append(f\"{deleted} file(s) deleted\")\n        \n        # Count update types\n        content_updates = len([u for u in lesson_updates if u.update_type == 'content'])\n        archived = len([u for u in lesson_updates if u.update_type == 'archived'])\n        \n        if content_updates > 0:\n            parts.append(f\"{content_updates} lesson(s) updated\")\n        if archived > 0:\n            parts.append(f\"{archived} lesson(s) archived\")\n        \n        return \", \".join(parts) if parts else \"No changes\"\n    \n    async def check_for_updates(\n        self,\n        course_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> Tuple[bool, List[FileChange]]:\n        \"\"\"Check if course needs updates.\n        \n        Args:\n            course_id: Course identifier\n            current_files: List of current file paths\n            analysis: Current codebase analysis\n            \n        Returns:\n            Tuple of (needs_update, file_changes)\n        \"\"\"\n        file_changes = await self.detect_file_changes(\n            course_id,\n            current_files,\n            analysis\n        )\n        \n        needs_update = len(file_changes) > 0\n        \n        return needs_update, file_changes\n    \n    def get_update_statistics(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics about course updates.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Dictionary with update statistics\n        \"\"\"\n        history = self.get_version_history(course_id)\n        \n        if not history:\n            return {\n                \"total_versions\": 0,\n                \"total_updates\": 0,\n                \"total_archived\": 0,\n                \"latest_version\": None,\n                \"last_updated\": None\n            }\n        \n        total_updates = sum(v.updated_lessons for v in history)\n        total_archived = sum(v.archived_lessons for v in history)\n        latest = history[0]\n        \n        return {\n            \"total_versions\": len(history),\n            \"total_updates\": total_updates,\n            \"total_archived\": total_archived,\n            \"latest_version\": latest.version,\n            \"last_updated\": latest.updated_at.isoformat(),\n            \"manual_edits\": len(self.manual_edits),\n            \"archived_lessons\": len(self.archived_lessons.get(course_id, []))\n        }\n"
          }
        ]
      }
    ],
    "test_files": [],
    "git_commits": [
      {
        "hash": "4c8499be704b26376e56d914254e91e241e29bc0",
        "author": "briansbrian",
        "email": "briansbrianaddress@gmail.com",
        "date": "2025-11-13T04:08:47+03:00",
        "subject": "docs for specs",
        "message": "docs for specs",
        "files": [
          ".kiro/specs/analysis-engine/tasks.md",
          ".kiro/specs/course-generator/tasks.md",
          "docs/ANALYSIS_ENGINE_API.md",
          "docs/ANALYSIS_ENGINE_CONFIGURATION.md",
          "docs/ANALYSIS_ENGINE_DOCUMENTATION_SUMMARY.md",
          "docs/COURSE_API.md",
          "docs/COURSE_CONFIGURATION.md",
          "docs/COURSE_GENERATOR_README.md",
          "docs/INCREMENTAL_UPDATES.md",
          "docs/INDEX.md",
          "docs/METADATA_GENERATION.md",
          "examples/README.md",
          "examples/analyze_codebase_example.py",
          "examples/analyze_single_file_example.py",
          "examples/course_generator_example.py",
          "examples/custom_pattern_detector_example.py",
          "examples/incremental_analysis_example.py",
          "examples/mcp_tools_usage_example.py",
          "examples/metadata_generator_example.py",
          "output/course_manifest_example.json",
          "src/course/__init__.py",
          "src/course/content_generator.py",
          "src/course/course_cache.py",
          "src/course/exercise_generator.py",
          "src/course/incremental_updater.py",
          "src/course/metadata_generator.py",
          "src/course/performance_monitor.py",
          "src/course/structure_generator.py",
          "src/server.py",
          "tests/test_content_validator.py",
          "tests/test_course_config.py",
          "tests/test_course_performance.py",
          "tests/test_incremental_updates.py",
          "tests/test_metadata_generator.py"
        ]
      }
    ],
    "documentation": [
      {
        "type": "docstring",
        "content": "Represents a change to a source file.",
        "location": "Class: FileChange (lines 30-36)",
        "context": "Documents class 'FileChange'"
      },
      {
        "type": "docstring",
        "content": "Represents an update to a lesson.",
        "location": "Class: LessonUpdate (lines 40-46)",
        "context": "Documents class 'LessonUpdate'"
      },
      {
        "type": "docstring",
        "content": "Represents a version of the course.",
        "location": "Class: CourseVersion (lines 50-60)",
        "context": "Documents class 'CourseVersion'"
      },
      {
        "type": "docstring",
        "content": "Manages incremental updates to course content.\r\n    \r\n    Provides functionality for:\r\n    - Detecting file changes\r\n    - Identifying lessons that need updates\r\n    - Preserving manual edits\r\n    - Tracking version history\r\n    - Archiving deleted lessons",
        "location": "Class: IncrementalUpdateManager (lines 63-973)",
        "context": "Documents class 'IncrementalUpdateManager'"
      },
      {
        "type": "docstring",
        "content": "Initialize the incremental update manager.\r\n        \r\n        Args:\r\n            cache_manager: Course cache manager instance\r\n            output_dir: Directory where course files are stored",
        "location": "Method: IncrementalUpdateManager.__init__ (lines 74-94)",
        "context": "Documents method 'IncrementalUpdateManager.__init__'"
      },
      {
        "type": "docstring",
        "content": "Compute SHA256 hash of file content.\r\n        \r\n        Args:\r\n            file_path: Path to file\r\n            \r\n        Returns:\r\n            SHA256 hash of file content",
        "location": "Method: IncrementalUpdateManager._compute_file_hash (lines 96-110)",
        "context": "Documents method 'IncrementalUpdateManager._compute_file_hash'"
      },
      {
        "type": "docstring",
        "content": "Get file modification time.\r\n        \r\n        Args:\r\n            file_path: Path to file\r\n            \r\n        Returns:\r\n            Modification time as timestamp",
        "location": "Method: IncrementalUpdateManager._get_file_mtime (lines 112-125)",
        "context": "Documents method 'IncrementalUpdateManager._get_file_mtime'"
      },
      {
        "type": "docstring",
        "content": "Detect changes to source files since last course generation.\r\n        \r\n        Implements Requirement 15.1: Detects which lessons need updates based on file changes.\r\n        \r\n        Args:\r\n            codebase_id: Unique codebase identifier\r\n            current_files: List of current file paths in the codebase\r\n            analysis: Current codebase analysis\r\n            \r\n        Returns:\r\n            List of FileChange objects representing detected changes",
        "location": "Method: IncrementalUpdateManager.detect_file_changes (lines 127-211)",
        "context": "Documents method 'IncrementalUpdateManager.detect_file_changes'"
      },
      {
        "type": "docstring",
        "content": "Identify which lessons need updates based on file changes.\r\n        \r\n        Implements Requirement 15.1: Detects which lessons need updates.\r\n        \r\n        Args:\r\n            course: Current course outline\r\n            file_changes: List of detected file changes\r\n            \r\n        Returns:\r\n            List of (Lesson, FileChange) tuples for lessons that need updates",
        "location": "Method: IncrementalUpdateManager.identify_lessons_to_update (lines 213-252)",
        "context": "Documents method 'IncrementalUpdateManager.identify_lessons_to_update'"
      },
      {
        "type": "docstring",
        "content": "Check if a lesson has manual edits.\r\n        \r\n        Implements Requirement 15.2: Preserves manual edits.\r\n        \r\n        Args:\r\n            lesson_id: Lesson identifier\r\n            \r\n        Returns:\r\n            True if lesson has manual edits, False otherwise",
        "location": "Method: IncrementalUpdateManager._has_manual_edits (lines 254-265)",
        "context": "Documents method 'IncrementalUpdateManager._has_manual_edits'"
      },
      {
        "type": "docstring",
        "content": "Mark a section of a lesson as manually edited.\r\n        \r\n        Implements Requirement 15.2: Tracks manual edits to preserve them.\r\n        \r\n        Args:\r\n            lesson_id: Lesson identifier\r\n            section: Section name that was edited (e.g., 'introduction', 'explanation')",
        "location": "Method: IncrementalUpdateManager.mark_manual_edit (lines 267-280)",
        "context": "Documents method 'IncrementalUpdateManager.mark_manual_edit'"
      },
      {
        "type": "docstring",
        "content": "Preserve manually edited sections when updating lesson content.\r\n        \r\n        Implements Requirement 15.2: Preserves manual edits to lesson content.\r\n        \r\n        Args:\r\n            lesson_id: Lesson identifier\r\n            old_content: Previous lesson content (may have manual edits)\r\n            new_content: Newly generated lesson content\r\n            \r\n        Returns:\r\n            Merged lesson content with manual edits preserved",
        "location": "Method: IncrementalUpdateManager.preserve_manual_edits (lines 282-338)",
        "context": "Documents method 'IncrementalUpdateManager.preserve_manual_edits'"
      },
      {
        "type": "docstring",
        "content": "Archive a lesson instead of deleting it.\r\n        \r\n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            lesson: Lesson to archive\r\n            reason: Reason for archiving",
        "location": "Method: IncrementalUpdateManager.archive_lesson (lines 340-362)",
        "context": "Documents method 'IncrementalUpdateManager.archive_lesson'"
      },
      {
        "type": "docstring",
        "content": "Get archived lessons for a course.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            \r\n        Returns:\r\n            List of archived lessons",
        "location": "Method: IncrementalUpdateManager.get_archived_lessons (lines 364-373)",
        "context": "Documents method 'IncrementalUpdateManager.get_archived_lessons'"
      },
      {
        "type": "docstring",
        "content": "Create a new course version entry.\r\n        \r\n        Implements Requirement 15.4: Tracks course version history.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            version: Version string (e.g., \"1.0.1\")\r\n            change_summary: Summary of changes\r\n            lesson_updates: List of lesson updates\r\n            file_changes: List of file changes\r\n            total_lessons: Total number of lessons in course\r\n            \r\n        Returns:\r\n            CourseVersion object",
        "location": "Method: IncrementalUpdateManager.create_version (lines 375-425)",
        "context": "Documents method 'IncrementalUpdateManager.create_version'"
      },
      {
        "type": "docstring",
        "content": "Get version history for a course.\r\n        \r\n        Implements Requirement 15.4: Provides access to course version history.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            \r\n        Returns:\r\n            List of CourseVersion objects, newest first (in reverse order of creation)",
        "location": "Method: IncrementalUpdateManager.get_version_history (lines 427-440)",
        "context": "Documents method 'IncrementalUpdateManager.get_version_history'"
      },
      {
        "type": "docstring",
        "content": "Get the latest version for a course.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            \r\n        Returns:\r\n            Latest CourseVersion or None if no versions exist",
        "location": "Method: IncrementalUpdateManager.get_latest_version (lines 442-452)",
        "context": "Documents method 'IncrementalUpdateManager.get_latest_version'"
      },
      {
        "type": "docstring",
        "content": "Increment version number based on change type.\r\n        \r\n        Args:\r\n            current_version: Current version string (e.g., \"1.0.0\")\r\n            change_type: Type of change ('major', 'minor', 'patch')\r\n            \r\n        Returns:\r\n            New version string",
        "location": "Method: IncrementalUpdateManager.increment_version (lines 454-481)",
        "context": "Documents method 'IncrementalUpdateManager.increment_version'"
      },
      {
        "type": "docstring",
        "content": "Save version history to disk.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            output_path: Optional custom output path",
        "location": "Method: IncrementalUpdateManager.save_version_history (lines 483-537)",
        "context": "Documents method 'IncrementalUpdateManager.save_version_history'"
      },
      {
        "type": "docstring",
        "content": "Load version history from disk.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            input_path: Optional custom input path",
        "location": "Method: IncrementalUpdateManager.load_version_history (lines 539-599)",
        "context": "Documents method 'IncrementalUpdateManager.load_version_history'"
      },
      {
        "type": "docstring",
        "content": "Update course incrementally based on file changes.\r\n        \r\n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\r\n        - Updates only changed lessons\r\n        - Preserves manual edits\r\n        - Archives deleted lessons\r\n        - Completes updates in <3s for <5 changes\r\n        \r\n        Args:\r\n            course: Current course outline\r\n            analysis: Current codebase analysis\r\n            file_changes: List of detected file changes\r\n            content_generator: LessonContentGenerator instance\r\n            structure_generator: CourseStructureGenerator instance\r\n            \r\n        Returns:\r\n            Tuple of (updated CourseOutline, CourseVersion)",
        "location": "Method: IncrementalUpdateManager.update_course_incrementally (lines 602-699)",
        "context": "Documents method 'IncrementalUpdateManager.update_course_incrementally'"
      },
      {
        "type": "docstring",
        "content": "Update content for a single lesson.\r\n        \r\n        Implements Requirement 15.2: Preserves manual edits during update.\r\n        \r\n        Args:\r\n            lesson: Lesson to update\r\n            analysis: Current codebase analysis\r\n            content_generator: LessonContentGenerator instance\r\n            \r\n        Returns:\r\n            LessonUpdate describing the changes",
        "location": "Method: IncrementalUpdateManager._update_lesson_content (lines 701-775)",
        "context": "Documents method 'IncrementalUpdateManager._update_lesson_content'"
      },
      {
        "type": "docstring",
        "content": "Calculate lesson difficulty from file analysis.\r\n        \r\n        Args:\r\n            file_analysis: FileAnalysis object\r\n            \r\n        Returns:\r\n            Difficulty level string",
        "location": "Method: IncrementalUpdateManager._calculate_difficulty (lines 777-793)",
        "context": "Documents method 'IncrementalUpdateManager._calculate_difficulty'"
      },
      {
        "type": "docstring",
        "content": "Remove archived lessons from course structure.\r\n        \r\n        Args:\r\n            course: Course outline\r\n            lesson_updates: List of lesson updates\r\n            \r\n        Returns:\r\n            Updated course outline",
        "location": "Method: IncrementalUpdateManager._remove_archived_lessons (lines 795-846)",
        "context": "Documents method 'IncrementalUpdateManager._remove_archived_lessons'"
      },
      {
        "type": "docstring",
        "content": "Calculate difficulty distribution across all lessons.\r\n        \r\n        Args:\r\n            course: Course outline\r\n            \r\n        Returns:\r\n            Dictionary mapping difficulty levels to counts",
        "location": "Method: IncrementalUpdateManager._calculate_difficulty_distribution (lines 848-863)",
        "context": "Documents method 'IncrementalUpdateManager._calculate_difficulty_distribution'"
      },
      {
        "type": "docstring",
        "content": "Count total lessons in course.\r\n        \r\n        Args:\r\n            course: Course outline\r\n            \r\n        Returns:\r\n            Total number of lessons",
        "location": "Method: IncrementalUpdateManager._count_total_lessons (lines 865-874)",
        "context": "Documents method 'IncrementalUpdateManager._count_total_lessons'"
      },
      {
        "type": "docstring",
        "content": "Generate a human-readable summary of changes.\r\n        \r\n        Args:\r\n            file_changes: List of file changes\r\n            lesson_updates: List of lesson updates\r\n            \r\n        Returns:\r\n            Change summary string",
        "location": "Method: IncrementalUpdateManager._generate_change_summary (lines 876-913)",
        "context": "Documents method 'IncrementalUpdateManager._generate_change_summary'"
      },
      {
        "type": "docstring",
        "content": "Check if course needs updates.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            current_files: List of current file paths\r\n            analysis: Current codebase analysis\r\n            \r\n        Returns:\r\n            Tuple of (needs_update, file_changes)",
        "location": "Method: IncrementalUpdateManager.check_for_updates (lines 915-939)",
        "context": "Documents method 'IncrementalUpdateManager.check_for_updates'"
      },
      {
        "type": "docstring",
        "content": "Get statistics about course updates.\r\n        \r\n        Args:\r\n            course_id: Course identifier\r\n            \r\n        Returns:\r\n            Dictionary with update statistics",
        "location": "Method: IncrementalUpdateManager.get_update_statistics (lines 941-973)",
        "context": "Documents method 'IncrementalUpdateManager.get_update_statistics'"
      }
    ],
    "dependencies": [
      {
        "name": "hashlib",
        "symbols": [],
        "reason": "Provides functionality from hashlib",
        "evidence": "Line 12: import",
        "type": "standard_library",
        "is_relative": false
      },
      {
        "name": "json",
        "symbols": [],
        "reason": "Provides functionality from json",
        "evidence": "Line 13: import",
        "type": "standard_library",
        "is_relative": false
      },
      {
        "name": "logging",
        "symbols": [],
        "reason": "Logging functionality",
        "evidence": "Line 14: import",
        "type": "standard_library",
        "is_relative": false
      },
      {
        "name": "os",
        "symbols": [],
        "reason": "Provides functionality from os",
        "evidence": "Line 15: import",
        "type": "standard_library",
        "is_relative": false
      },
      {
        "name": "time",
        "symbols": [],
        "reason": "Provides functionality from time",
        "evidence": "Line 16: import",
        "type": "standard_library",
        "is_relative": false
      },
      {
        "name": "Any",
        "symbols": [],
        "reason": "Provides functionality from Any",
        "evidence": "Line 17: from_import",
        "type": "third_party",
        "is_relative": false
      },
      {
        "name": "datetime",
        "symbols": [],
        "reason": "Provides functionality from datetime",
        "evidence": "Line 18: from_import",
        "type": "standard_library",
        "is_relative": false
      },
      {
        "name": "field",
        "symbols": [],
        "reason": "Provides functionality from field",
        "evidence": "Line 19: from_import",
        "type": "third_party",
        "is_relative": false
      },
      {
        "name": "LessonContent",
        "symbols": [],
        "reason": "Provides functionality from LessonContent",
        "evidence": "Line 21: from_import",
        "type": "third_party",
        "is_relative": true
      },
      {
        "name": "CourseCacheManager",
        "symbols": [],
        "reason": "Provides functionality from CourseCacheManager",
        "evidence": "Line 22: from_import",
        "type": "third_party",
        "is_relative": true
      },
      {
        "name": "CodebaseAnalysis",
        "symbols": [],
        "reason": "Provides functionality from CodebaseAnalysis",
        "evidence": "Line 23: from_import",
        "type": "third_party",
        "is_relative": false
      }
    ],
    "dependents": []
  },
  "validation_checklist": {
    "code_behavior": "Code behavior analysis:\n- Defines function '__init__': Initialize the incremental update manager (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:74)\n- Defines function 'mark_manual_edit': Mark a section of a lesson as manually edited (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:267)\n- Defines function 'archive_lesson': Archive a lesson instead of deleting it (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:340)\n- Defines function 'save_version_history': Save version history to disk (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:483)\n- Defines function 'load_version_history': Load version history from disk (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:539)\n- Defines class 'FileChange': Represents a change to a source file (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:30)\n- Defines class 'LessonUpdate': Represents an update to a lesson (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:40)\n- Defines class 'CourseVersion': Represents a version of the course (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:50)\n- Defines class 'IncrementalUpdateManager': Manages incremental updates to course content (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:63)\n- Uses asynchronous programming patterns (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py)\n- Uses dataclass pattern for data structures (C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py)",
    "expected_behavior": "No tests available for validation",
    "documentation_alignment": "Documentation alignment:\n- Documents class 'FileChange': Represents a change to a source file (Class: FileChange (lines 30-36) (docstring))\n- Documents class 'LessonUpdate': Represents an update to a lesson (Class: LessonUpdate (lines 40-46) (docstring))\n- Documents class 'CourseVersion': Represents a version of the course (Class: CourseVersion (lines 50-60) (docstring))\n- Documents class 'IncrementalUpdateManager': Manages incremental updates to course content (Class: IncrementalUpdateManager (lines 63-973) (docstring))\n- Documents method 'IncrementalUpdateManager.__init__': Initialize the incremental update manager (Method: IncrementalUpdateManager.__init__ (lines 74-94) (docstring))\n- Documents method 'IncrementalUpdateManager._compute_file_hash': Compute SHA256 hash of file content (Method: IncrementalUpdateManager._compute_file_hash (lines 96-110) (docstring))\n- Documents method 'IncrementalUpdateManager._get_file_mtime': Get file modification time (Method: IncrementalUpdateManager._get_file_mtime (lines 112-125) (docstring))\n- Documents method 'IncrementalUpdateManager.detect_file_changes': Detect changes to source files since last course generation (Method: IncrementalUpdateManager.detect_file_changes (lines 127-211) (docstring))\n- Documents method 'IncrementalUpdateManager.identify_lessons_to_update': Identify which lessons need updates based on file changes (Method: IncrementalUpdateManager.identify_lessons_to_update (lines 213-252) (docstring))\n- Documents method 'IncrementalUpdateManager._has_manual_edits': Check if a lesson has manual edits (Method: IncrementalUpdateManager._has_manual_edits (lines 254-265) (docstring))\n- Documents method 'IncrementalUpdateManager.mark_manual_edit': Mark a section of a lesson as manually edited (Method: IncrementalUpdateManager.mark_manual_edit (lines 267-280) (docstring))\n- Documents method 'IncrementalUpdateManager.preserve_manual_edits': Preserve manually edited sections when updating lesson content (Method: IncrementalUpdateManager.preserve_manual_edits (lines 282-338) (docstring))\n- Documents method 'IncrementalUpdateManager.archive_lesson': Archive a lesson instead of deleting it (Method: IncrementalUpdateManager.archive_lesson (lines 340-362) (docstring))\n- Documents method 'IncrementalUpdateManager.get_archived_lessons': Get archived lessons for a course (Method: IncrementalUpdateManager.get_archived_lessons (lines 364-373) (docstring))\n- Documents method 'IncrementalUpdateManager.create_version': Create a new course version entry (Method: IncrementalUpdateManager.create_version (lines 375-425) (docstring))\n- Documents method 'IncrementalUpdateManager.get_version_history': Get version history for a course (Method: IncrementalUpdateManager.get_version_history (lines 427-440) (docstring))\n- Documents method 'IncrementalUpdateManager.get_latest_version': Get the latest version for a course (Method: IncrementalUpdateManager.get_latest_version (lines 442-452) (docstring))\n- Documents method 'IncrementalUpdateManager.increment_version': Increment version number based on change type (Method: IncrementalUpdateManager.increment_version (lines 454-481) (docstring))\n- Documents method 'IncrementalUpdateManager.save_version_history': Save version history to disk (Method: IncrementalUpdateManager.save_version_history (lines 483-537) (docstring))\n- Documents method 'IncrementalUpdateManager.load_version_history': Load version history from disk (Method: IncrementalUpdateManager.load_version_history (lines 539-599) (docstring))\n- Documents method 'IncrementalUpdateManager.update_course_incrementally': Update course incrementally based on file changes (Method: IncrementalUpdateManager.update_course_incrementally (lines 602-699) (docstring))\n- Documents method 'IncrementalUpdateManager._update_lesson_content': Update content for a single lesson (Method: IncrementalUpdateManager._update_lesson_content (lines 701-775) (docstring))\n- Documents method 'IncrementalUpdateManager._calculate_difficulty': Calculate lesson difficulty from file analysis (Method: IncrementalUpdateManager._calculate_difficulty (lines 777-793) (docstring))\n- Documents method 'IncrementalUpdateManager._remove_archived_lessons': Remove archived lessons from course structure (Method: IncrementalUpdateManager._remove_archived_lessons (lines 795-846) (docstring))\n- Documents method 'IncrementalUpdateManager._calculate_difficulty_distribution': Calculate difficulty distribution across all lessons (Method: IncrementalUpdateManager._calculate_difficulty_distribution (lines 848-863) (docstring))\n- Documents method 'IncrementalUpdateManager._count_total_lessons': Count total lessons in course (Method: IncrementalUpdateManager._count_total_lessons (lines 865-874) (docstring))\n- Documents method 'IncrementalUpdateManager._generate_change_summary': Generate a human-readable summary of changes (Method: IncrementalUpdateManager._generate_change_summary (lines 876-913) (docstring))\n- Documents method 'IncrementalUpdateManager.check_for_updates': Check if course needs updates (Method: IncrementalUpdateManager.check_for_updates (lines 915-939) (docstring))\n- Documents method 'IncrementalUpdateManager.get_update_statistics': Get statistics about course updates (Method: IncrementalUpdateManager.get_update_statistics (lines 941-973) (docstring))",
    "git_context": "Git history context:\n\nTest commits:\n  - docs for specs (Commit 4c8499be by briansbrian on 2025-11-13)",
    "consistency_check": false
  },
  "teaching_value_assessment": {
    "scores": {
      "reusability": 0,
      "best_practice": 2,
      "fundamentality": 3,
      "uniqueness": 2,
      "junior_dev": 3
    },
    "total_score": 10,
    "should_teach": true,
    "reasoning": "Low reusability (0/3): Few reusable patterns detected; Strong best practices (2/3): Well-tested and documented; Fundamental concept (3/3): 'Incremental Updater: Python Async Await' is important for developers; Interesting implementation (2/2): Contains unique or novel aspects; High junior dev value (3/3): Good complexity and documentation"
  },
  "systematic_investigation": {
    "what_it_does": "This code defines class 'class' [C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:1-974]",
    "why_it_exists": "This code exists to: docs for specs [commit 4c8499be]; Represents a change to a source file. [Class: FileChange (lines 30-36)]; Represents an update to a lesson. [Class: LessonUpdate (lines 40-46)]",
    "how_it_works": "Implementation approach: uses asynchronous programming, uses object-oriented design, includes error handling, uses decorators, uses generators, implements caching [C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:1-974]; Integrates with hashlib, json, logging for extended functionality",
    "when_its_used": [
      "Used as part of the application's core functionality"
    ],
    "edge_cases": [
      "No specific edge cases documented in tests or comments"
    ],
    "common_pitfalls": [
      "No specific pitfalls documented in comments or tests"
    ]
  },
  "narrative_structure": {
    "introduction_points": [
      "This lesson covers this code defines class 'class'",
      "Understanding this is important because docs for specs",
      "Low reusability (0/3): Few reusable patterns detected; Strong best practices (2/3): Well-tested and documented; Fundamental concept (3/3): 'Incremental Updater: Python Async Await' is important for developers; Interesting implementation (2/2): Contains unique or novel aspects; High junior dev value (3/3): Good complexity and documentation",
      "You'll learn how to use asynchronous programming"
    ],
    "learning_progression": [
      "Class Initialization",
      "Module Imports",
      "Context Managers",
      "Dunder Methods",
      "List Comprehensions",
      "Object-Oriented Programming",
      "Error Handling",
      "Decorators",
      "Conditional Logic",
      "Iteration",
      "Lists/Arrays",
      "Dictionaries",
      "Database Operations",
      "Asynchronous Programming"
    ],
    "code_walkthrough_order": [
      "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py:1-974 - Defines the class class"
    ],
    "conclusion_points": [
      "You now understand how to this code defines class 'class'",
      "Always implement error handling in production code",
      "Avoid: No specific pitfalls documented in comments or tests",
      "This demonstrates asynchronous programming patterns used throughout professional development"
    ],
    "next_steps": [
      "Practice by implementing this pattern in your own project",
      "Explore advanced concepts: concurrent programming and parallelism",
      "Look for examples of this pattern in open-source projects"
    ]
  },
  "code_sections": [
    {
      "file_path": "C:\\Users\\brian\\OneDrive\\Documents\\Apps\\Documee_mcp\\src\\course\\incremental_updater.py",
      "line_range": [
        1,
        974
      ],
      "code_snippet": "\"\"\"Incremental Course Update Manager.\n\nThis module provides incremental update functionality for courses.\nImplements Requirements 15.1, 15.2, 15.3, 15.4, 15.5:\n- Detects which lessons need updates based on file changes\n- Tracks course version history\n- Preserves manual edits to lesson content\n- Archives deleted lessons\n- Completes updates in <3s for <5 changes\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Dict, List, Optional, Set, Tuple, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\n\nfrom .models import CourseOutline, Module, Lesson, LessonContent\nfrom .course_cache import CourseCacheManager\nfrom src.models import CodebaseAnalysis\n\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass FileChange:\n    \"\"\"Represents a change to a source file.\"\"\"\n    file_path: str\n    change_type: str  # 'added', 'modified', 'deleted'\n    old_hash: Optional[str] = None\n    new_hash: Optional[str] = None\n    detected_at: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass LessonUpdate:\n    \"\"\"Represents an update to a lesson.\"\"\"\n    lesson_id: str\n    file_path: str\n    update_type: str  # 'content', 'structure', 'archived'\n    changes: List[str] = field(default_factory=list)\n    timestamp: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass CourseVersion:\n    \"\"\"Represents a version of the course.\"\"\"\n    version: str\n    created_at: datetime\n    updated_at: datetime\n    change_summary: str\n    lesson_updates: List[LessonUpdate] = field(default_factory=list)\n    file_changes: List[FileChange] = field(default_factory=list)\n    total_lessons: int = 0\n    updated_lessons: int = 0\n    archived_lessons: int = 0\n\n\nclass IncrementalUpdateManager:\n    \"\"\"Manages incremental updates to course content.\n    \n    Provides functionality for:\n    - Detecting file changes\n    - Identifying lessons that need updates\n    - Preserving manual edits\n    - Tracking version history\n    - Archiving deleted lessons\n    \"\"\"\n    \n    def __init__(self, cache_manager: CourseCacheManager, output_dir: str = \"output/courses\"):\n        \"\"\"Initialize the incremental update manager.\n        \n        Args:\n            cache_manager: Course cache manager instance\n            output_dir: Directory where course files are stored\n        \"\"\"\n        self.cache = cache_manager\n        self.output_dir = output_dir\n        \n        # Version history storage\n        self.version_history: Dict[str, List[CourseVersion]] = {}\n        \n        # Manual edit tracking\n        self.manual_edits: Dict[str, Set[str]] = {}  # lesson_id -> set of edited sections\n        \n        # File hash tracking for change detection\n        self.file_hashes: Dict[str, str] = {}\n        \n        # Archived lessons\n        self.archived_lessons: Dict[str, List[Lesson]] = {}  # course_id -> archived lessons\n    \n    def _compute_file_hash(self, file_path: str) -> str:\n        \"\"\"Compute SHA256 hash of file content.\n        \n        Args:\n            file_path: Path to file\n            \n        Returns:\n            SHA256 hash of file content\n        \"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                return hashlib.sha256(f.read()).hexdigest()\n        except Exception as e:\n            logger.warning(f\"Failed to hash file {file_path}: {e}\")\n            return \"\"\n    \n    def _get_file_mtime(self, file_path: str) -> float:\n        \"\"\"Get file modification time.\n        \n        Args:\n            file_path: Path to file\n            \n        Returns:\n            Modification time as timestamp\n        \"\"\"\n        try:\n            return os.path.getmtime(file_path)\n        except Exception as e:\n            logger.warning(f\"Failed to get mtime for {file_path}: {e}\")\n            return 0.0\n    \n    async def detect_file_changes(\n        self,\n        codebase_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> List[FileChange]:\n        \"\"\"Detect changes to source files since last course generation.\n        \n        Implements Requirement 15.1: Detects which lessons need updates based on file changes.\n        \n        Args:\n            codebase_id: Unique codebase identifier\n            current_files: List of current file paths in the codebase\n            analysis: Current codebase analysis\n            \n        Returns:\n            List of FileChange objects representing detected changes\n        \"\"\"\n        changes = []\n        \n        # Get cached course structure to find previous files\n        cached_course = await self.cache.get_course_structure(codebase_id)\n        \n        if not cached_course or \"file_paths\" not in cached_course:\n            # No previous course, all files are new\n            for file_path in current_files:\n                file_hash = self._compute_file_hash(file_path)\n                changes.append(FileChange(\n                    file_path=file_path,\n                    change_type='added',\n                    new_hash=file_hash\n                ))\n            return changes\n        \n        previous_files = set(cached_course[\"file_paths\"])\n        current_files_set = set(current_files)\n        \n        # Detect added files\n        added_files = current_files_set - previous_files\n        for file_path in added_files:\n            file_hash = self._compute_file_hash(file_path)\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='added',\n                new_hash=file_hash\n            ))\n            logger.info(f\"Detected added file: {file_path}\")\n        \n        # Detect deleted files\n        deleted_files = previous_files - current_files_set\n        for file_path in deleted_files:\n            old_hash = self.file_hashes.get(file_path, \"\")\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='deleted',\n                old_hash=old_hash\n            ))\n            logger.info(f\"Detected deleted file: {file_path}\")\n        \n        # Detect modified files\n        for file_path in current_files_set & previous_files:\n            current_hash = self._compute_file_hash(file_path)\n            \n            # Check if file has changed using cache\n            if await self.cache._is_file_changed(file_path):\n                old_hash = self.file_hashes.get(file_path, \"\")\n                if current_hash != old_hash:\n                    changes.append(FileChange(\n                        file_path=file_path,\n                        change_type='modified',\n                        old_hash=old_hash,\n                        new_hash=current_hash\n                    ))\n                    logger.info(f\"Detected modified file: {file_path}\")\n            \n            # Update hash tracking\n            self.file_hashes[file_path] = current_hash\n        \n        logger.info(\n            f\"Detected {len(changes)} file changes: \"\n            f\"{len(added_files)} added, {len(deleted_files)} deleted, \"\n            f\"{len([c for c in changes if c.change_type == 'modified'])} modified\"\n        )\n        \n        return changes\n    \n    def identify_lessons_to_update(\n        self,\n        course: CourseOutline,\n        file_changes: List[FileChange]\n    ) -> List[Tuple[Lesson, FileChange]]:\n        \"\"\"Identify which lessons need updates based on file changes.\n        \n        Implements Requirement 15.1: Detects which lessons need updates.\n        \n        Args:\n            course: Current course outline\n            file_changes: List of detected file changes\n            \n        Returns:\n            List of (Lesson, FileChange) tuples for lessons that need updates\n        \"\"\"\n        lessons_to_update = []\n        \n        # Build map of file_path -> lesson\n        file_to_lesson: Dict[str, Lesson] = {}\n        for module in course.modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n        \n        # Match file changes to lessons\n        for change in file_changes:\n            if change.file_path in file_to_lesson:\n                lesson = file_to_lesson[change.file_path]\n                \n                # Check if lesson has manual edits that should be preserved\n                if self._has_manual_edits(lesson.lesson_id):\n                    logger.info(\n                        f\"Lesson {lesson.lesson_id} has manual edits, \"\n                        f\"will preserve during update\"\n                    )\n                \n                lessons_to_update.append((lesson, change))\n        \n        logger.info(f\"Identified {len(lessons_to_update)} lessons to update\")\n        return lessons_to_update\n    \n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n        \n        Implements Requirement 15.2: Preserves manual edits.\n        \n        Args:\n            lesson_id: Lesson identifier\n            \n        Returns:\n            True if lesson has manual edits, False otherwise\n        \"\"\"\n        return lesson_id in self.manual_edits and len(self.manual_edits[lesson_id]) > 0\n    \n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n        \n        Implements Requirement 15.2: Tracks manual edits to preserve them.\n        \n        Args:\n            lesson_id: Lesson identifier\n            section: Section name that was edited (e.g., 'introduction', 'explanation')\n        \"\"\"\n        if lesson_id not in self.manual_edits:\n            self.manual_edits[lesson_id] = set()\n        \n        self.manual_edits[lesson_id].add(section)\n        logger.info(f\"Marked manual edit: {lesson_id}.{section}\")\n    \n    def preserve_manual_edits(\n        self,\n        lesson_id: str,\n        old_content: LessonContent,\n        new_content: LessonContent\n    ) -> LessonContent:\n        \"\"\"Preserve manually edited sections when updating lesson content.\n        \n        Implements Requirement 15.2: Preserves manual edits to lesson content.\n        \n        Args:\n            lesson_id: Lesson identifier\n            old_content: Previous lesson content (may have manual edits)\n            new_content: Newly generated lesson content\n            \n        Returns:\n            Merged lesson content with manual edits preserved\n        \"\"\"\n        if not self._has_manual_edits(lesson_id):\n            return new_content\n        \n        edited_sections = self.manual_edits[lesson_id]\n        \n        # Create a copy of new content\n        merged_content = LessonContent(\n            introduction=new_content.introduction,\n            explanation=new_content.explanation,\n            code_example=new_content.code_example,\n            walkthrough=new_content.walkthrough,\n            summary=new_content.summary,\n            further_reading=new_content.further_reading\n        )\n        \n        # Preserve manually edited sections\n        if 'introduction' in edited_sections:\n            merged_content.introduction = old_content.introduction\n            logger.info(f\"Preserved manual edit: {lesson_id}.introduction\")\n        \n        if 'explanation' in edited_sections:\n            merged_content.explanation = old_content.explanation\n            logger.info(f\"Preserved manual edit: {lesson_id}.explanation\")\n        \n        if 'walkthrough' in edited_sections:\n            merged_content.walkthrough = old_content.walkthrough\n            logger.info(f\"Preserved manual edit: {lesson_id}.walkthrough\")\n        \n        if 'summary' in edited_sections:\n            merged_content.summary = old_content.summary\n            logger.info(f\"Preserved manual edit: {lesson_id}.summary\")\n        \n        if 'further_reading' in edited_sections:\n            merged_content.further_reading = old_content.further_reading\n            logger.info(f\"Preserved manual edit: {lesson_id}.further_reading\")\n        \n        # Note: code_example is always regenerated from source\n        \n        return merged_content\n    \n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n        \n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\n        \n        Args:\n            course_id: Course identifier\n            lesson: Lesson to archive\n            reason: Reason for archiving\n        \"\"\"\n        if course_id not in self.archived_lessons:\n            self.archived_lessons[course_id] = []\n        \n        # Add archive metadata\n        lesson.tags.append(f\"archived:{reason}\")\n        lesson.tags.append(f\"archived_at:{datetime.now().isoformat()}\")\n        \n        self.archived_lessons[course_id].append(lesson)\n        \n        logger.info(\n            f\"Archived lesson {lesson.lesson_id} ({lesson.title}) \"\n            f\"from course {course_id}: {reason}\"\n        )\n    \n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of archived lessons\n        \"\"\"\n        return self.archived_lessons.get(course_id, [])\n    \n    def create_version(\n        self,\n        course_id: str,\n        version: str,\n        change_summary: str,\n        lesson_updates: List[LessonUpdate],\n        file_changes: List[FileChange],\n        total_lessons: int\n    ) -> CourseVersion:\n        \"\"\"Create a new course version entry.\n        \n        Implements Requirement 15.4: Tracks course version history.\n        \n        Args:\n            course_id: Course identifier\n            version: Version string (e.g., \"1.0.1\")\n            change_summary: Summary of changes\n            lesson_updates: List of lesson updates\n            file_changes: List of file changes\n            total_lessons: Total number of lessons in course\n            \n        Returns:\n            CourseVersion object\n        \"\"\"\n        now = datetime.now()\n        \n        course_version = CourseVersion(\n            version=version,\n            created_at=now,\n            updated_at=now,\n            change_summary=change_summary,\n            lesson_updates=lesson_updates,\n            file_changes=file_changes,\n            total_lessons=total_lessons,\n            updated_lessons=len(lesson_updates),\n            archived_lessons=len([u for u in lesson_updates if u.update_type == 'archived'])\n        )\n        \n        # Add to version history\n        if course_id not in self.version_history:\n            self.version_history[course_id] = []\n        \n        self.version_history[course_id].append(course_version)\n        \n        logger.info(\n            f\"Created course version {version} for {course_id}: \"\n            f\"{course_version.updated_lessons} lessons updated, \"\n            f\"{course_version.archived_lessons} lessons archived\"\n        )\n        \n        return course_version\n    \n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n        \n        Implements Requirement 15.4: Provides access to course version history.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            List of CourseVersion objects, newest first (in reverse order of creation)\n        \"\"\"\n        history = self.version_history.get(course_id, [])\n        # Return in reverse order (newest first) since versions are appended chronologically\n        return list(reversed(history))\n    \n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Latest CourseVersion or None if no versions exist\n        \"\"\"\n        history = self.get_version_history(course_id)\n        return history[0] if history else None\n    \n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n        \n        Args:\n            current_version: Current version string (e.g., \"1.0.0\")\n            change_type: Type of change ('major', 'minor', 'patch')\n            \n        Returns:\n            New version string\n        \"\"\"\n        try:\n            parts = current_version.split('.')\n            major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])\n            \n            if change_type == 'major':\n                major += 1\n                minor = 0\n                patch = 0\n            elif change_type == 'minor':\n                minor += 1\n                patch = 0\n            else:  # patch\n                patch += 1\n            \n            return f\"{major}.{minor}.{patch}\"\n        except Exception as e:\n            logger.warning(f\"Failed to increment version {current_version}: {e}\")\n            return current_version\n    \n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n        \n        Args:\n            course_id: Course identifier\n            output_path: Optional custom output path\n        \"\"\"\n        if output_path is None:\n            output_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        history = self.get_version_history(course_id)\n        \n        # Serialize to JSON\n        history_data = []\n        for version in history:\n            history_data.append({\n                \"version\": version.version,\n                \"created_at\": version.created_at.isoformat(),\n                \"updated_at\": version.updated_at.isoformat(),\n                \"change_summary\": version.change_summary,\n                \"total_lessons\": version.total_lessons,\n                \"updated_lessons\": version.updated_lessons,\n                \"archived_lessons\": version.archived_lessons,\n                \"lesson_updates\": [\n                    {\n                        \"lesson_id\": u.lesson_id,\n                        \"file_path\": u.file_path,\n                        \"update_type\": u.update_type,\n                        \"changes\": u.changes,\n                        \"timestamp\": u.timestamp.isoformat()\n                    }\n                    for u in version.lesson_updates\n                ],\n                \"file_changes\": [\n                    {\n                        \"file_path\": c.file_path,\n                        \"change_type\": c.change_type,\n                        \"old_hash\": c.old_hash,\n                        \"new_hash\": c.new_hash,\n                        \"detected_at\": c.detected_at.isoformat()\n                    }\n                    for c in version.file_changes\n                ]\n            })\n        \n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(history_data, f, indent=2)\n        \n        logger.info(f\"Saved version history to {output_path}\")\n    \n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n        \n        Args:\n            course_id: Course identifier\n            input_path: Optional custom input path\n        \"\"\"\n        if input_path is None:\n            input_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n        \n        if not os.path.exists(input_path):\n            logger.debug(f\"No version history file found at {input_path}\")\n            return\n        \n        try:\n            with open(input_path, 'r', encoding='utf-8') as f:\n                history_data = json.load(f)\n            \n            # Deserialize from JSON\n            versions = []\n            for data in history_data:\n                version = CourseVersion(\n                    version=data[\"version\"],\n                    created_at=datetime.fromisoformat(data[\"created_at\"]),\n                    updated_at=datetime.fromisoformat(data[\"updated_at\"]),\n                    change_summary=data[\"change_summary\"],\n                    total_lessons=data[\"total_lessons\"],\n                    updated_lessons=data[\"updated_lessons\"],\n                    archived_lessons=data[\"archived_lessons\"],\n                    lesson_updates=[\n                        LessonUpdate(\n                            lesson_id=u[\"lesson_id\"],\n                            file_path=u[\"file_path\"],\n                            update_type=u[\"update_type\"],\n                            changes=u[\"changes\"],\n                            timestamp=datetime.fromisoformat(u[\"timestamp\"])\n                        )\n                        for u in data[\"lesson_updates\"]\n                    ],\n                    file_changes=[\n                        FileChange(\n                            file_path=c[\"file_path\"],\n                            change_type=c[\"change_type\"],\n                            old_hash=c.get(\"old_hash\"),\n                            new_hash=c.get(\"new_hash\"),\n                            detected_at=datetime.fromisoformat(c[\"detected_at\"])\n                        )\n                        for c in data[\"file_changes\"]\n                    ]\n                )\n                versions.append(version)\n            \n            self.version_history[course_id] = versions\n            logger.info(f\"Loaded {len(versions)} versions from {input_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to load version history from {input_path}: {e}\")\n\n\n    async def update_course_incrementally(\n        self,\n        course: CourseOutline,\n        analysis: CodebaseAnalysis,\n        file_changes: List[FileChange],\n        content_generator,\n        structure_generator\n    ) -> Tuple[CourseOutline, CourseVersion]:\n        \"\"\"Update course incrementally based on file changes.\n        \n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\n        - Updates only changed lessons\n        - Preserves manual edits\n        - Archives deleted lessons\n        - Completes updates in <3s for <5 changes\n        \n        Args:\n            course: Current course outline\n            analysis: Current codebase analysis\n            file_changes: List of detected file changes\n            content_generator: LessonContentGenerator instance\n            structure_generator: CourseStructureGenerator instance\n            \n        Returns:\n            Tuple of (updated CourseOutline, CourseVersion)\n        \"\"\"\n        start_time = time.time()\n        \n        logger.info(\n            f\"Starting incremental update for course {course.course_id} \"\n            f\"with {len(file_changes)} file changes\"\n        )\n        \n        # Identify lessons to update\n        lessons_to_update = self.identify_lessons_to_update(course, file_changes)\n        \n        # Track updates\n        lesson_updates: List[LessonUpdate] = []\n        \n        # Process each lesson update\n        for lesson, change in lessons_to_update:\n            if change.change_type == 'deleted':\n                # Archive the lesson\n                self.archive_lesson(course.course_id, lesson, \"file_deleted\")\n                lesson_updates.append(LessonUpdate(\n                    lesson_id=lesson.lesson_id,\n                    file_path=lesson.file_path,\n                    update_type='archived',\n                    changes=['File deleted, lesson archived']\n                ))\n            \n            elif change.change_type in ['added', 'modified']:\n                # Update lesson content\n                update = await self._update_lesson_content(\n                    lesson,\n                    analysis,\n                    content_generator\n                )\n                lesson_updates.append(update)\n        \n        # Remove archived lessons from course\n        course = self._remove_archived_lessons(course, lesson_updates)\n        \n        # Update course metadata\n        course.version = self.increment_version(\n            course.version,\n            'minor' if len(file_changes) > 5 else 'patch'\n        )\n        course.created_at = datetime.now()  # Update timestamp\n        \n        # Create version entry\n        change_summary = self._generate_change_summary(file_changes, lesson_updates)\n        version = self.create_version(\n            course.course_id,\n            course.version,\n            change_summary,\n            lesson_updates,\n            file_changes,\n            self._count_total_lessons(course)\n        )\n        \n        # Save version history\n        self.save_version_history(course.course_id)\n        \n        elapsed_time = time.time() - start_time\n        logger.info(\n            f\"Incremental update completed in {elapsed_time:.2f}s: \"\n            f\"{len(lesson_updates)} lessons updated\"\n        )\n        \n        # Verify performance requirement (Req 15.5)\n        if len(file_changes) < 5 and elapsed_time > 3.0:\n            logger.warning(\n                f\"Update took {elapsed_time:.2f}s for {len(file_changes)} changes, \"\n                f\"exceeding 3s target\"\n            )\n        \n        return course, version\n    \n    async def _update_lesson_content(\n        self,\n        lesson: Lesson,\n        analysis: CodebaseAnalysis,\n        content_generator\n    ) -> LessonUpdate:\n        \"\"\"Update content for a single lesson.\n        \n        Implements Requirement 15.2: Preserves manual edits during update.\n        \n        Args:\n            lesson: Lesson to update\n            analysis: Current codebase analysis\n            content_generator: LessonContentGenerator instance\n            \n        Returns:\n            LessonUpdate describing the changes\n        \"\"\"\n        changes = []\n        \n        # Get file analysis\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            logger.warning(f\"No analysis found for {lesson.file_path}\")\n            return LessonUpdate(\n                lesson_id=lesson.lesson_id,\n                file_path=lesson.file_path,\n                update_type='content',\n                changes=['No analysis available']\n            )\n        \n        # Store old content if it exists\n        old_content = lesson.content\n        \n        # Generate new content\n        new_content = await content_generator.generate_lesson_content(file_analysis)\n        \n        # Preserve manual edits if any\n        if old_content and self._has_manual_edits(lesson.lesson_id):\n            merged_content = self.preserve_manual_edits(\n                lesson.lesson_id,\n                old_content,\n                new_content\n            )\n            lesson.content = merged_content\n            changes.append(\"Preserved manual edits\")\n        else:\n            lesson.content = new_content\n            changes.append(\"Regenerated content\")\n        \n        # Update lesson metadata\n        lesson.teaching_value = file_analysis.teaching_value.score\n        \n        # Update learning objectives if patterns changed\n        old_patterns = set(lesson.concepts)\n        new_patterns = set(p.pattern_type for p in file_analysis.patterns)\n        \n        if old_patterns != new_patterns:\n            lesson.concepts = list(new_patterns)\n            lesson.tags = list(new_patterns)\n            changes.append(f\"Updated patterns: {new_patterns - old_patterns}\")\n        \n        # Update complexity-based difficulty\n        new_difficulty = self._calculate_difficulty(file_analysis)\n        if new_difficulty != lesson.difficulty:\n            old_diff = lesson.difficulty\n            lesson.difficulty = new_difficulty\n            changes.append(f\"Difficulty changed: {old_diff} -> {new_difficulty}\")\n        \n        return LessonUpdate(\n            lesson_id=lesson.lesson_id,\n            file_path=lesson.file_path,\n            update_type='content',\n            changes=changes\n        )\n    \n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n        \n        Args:\n            file_analysis: FileAnalysis object\n            \n        Returns:\n            Difficulty level string\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n        \n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n    \n    def _remove_archived_lessons(\n        self,\n        course: CourseOutline,\n        lesson_updates: List[LessonUpdate]\n    ) -> CourseOutline:\n        \"\"\"Remove archived lessons from course structure.\n        \n        Args:\n            course: Course outline\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Updated course outline\n        \"\"\"\n        archived_ids = {\n            u.lesson_id for u in lesson_updates\n            if u.update_type == 'archived'\n        }\n        \n        if not archived_ids:\n            return course\n        \n        # Remove archived lessons from modules\n        for module in course.modules:\n            module.lessons = [\n                lesson for lesson in module.lessons\n                if lesson.lesson_id not in archived_ids\n            ]\n            \n            # Update lesson order after removal\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n            \n            # Update module duration\n            module.duration_hours = sum(l.duration_minutes for l in module.lessons) / 60.0\n        \n        # Remove empty modules\n        course.modules = [m for m in course.modules if len(m.lessons) > 0]\n        \n        # Update module order\n        for idx, module in enumerate(course.modules):\n            module.order = idx\n        \n        # Update course duration\n        course.total_duration_hours = sum(m.duration_hours for m in course.modules)\n        \n        # Update difficulty distribution\n        course.difficulty_distribution = self._calculate_difficulty_distribution(course)\n        \n        logger.info(f\"Removed {len(archived_ids)} archived lessons from course\")\n        \n        return course\n    \n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Dictionary mapping difficulty levels to counts\n        \"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n        \n        for module in course.modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n        \n        return distribution\n    \n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n        \n        Args:\n            course: Course outline\n            \n        Returns:\n            Total number of lessons\n        \"\"\"\n        return sum(len(module.lessons) for module in course.modules)\n    \n    def _generate_change_summary(\n        self,\n        file_changes: List[FileChange],\n        lesson_updates: List[LessonUpdate]\n    ) -> str:\n        \"\"\"Generate a human-readable summary of changes.\n        \n        Args:\n            file_changes: List of file changes\n            lesson_updates: List of lesson updates\n            \n        Returns:\n            Change summary string\n        \"\"\"\n        parts = []\n        \n        # Count change types\n        added = len([c for c in file_changes if c.change_type == 'added'])\n        modified = len([c for c in file_changes if c.change_type == 'modified'])\n        deleted = len([c for c in file_changes if c.change_type == 'deleted'])\n        \n        if added > 0:\n            parts.append(f\"{added} file(s) added\")\n        if modified > 0:\n            parts.append(f\"{modified} file(s) modified\")\n        if deleted > 0:\n            parts.append(f\"{deleted} file(s) deleted\")\n        \n        # Count update types\n        content_updates = len([u for u in lesson_updates if u.update_type == 'content'])\n        archived = len([u for u in lesson_updates if u.update_type == 'archived'])\n        \n        if content_updates > 0:\n            parts.append(f\"{content_updates} lesson(s) updated\")\n        if archived > 0:\n            parts.append(f\"{archived} lesson(s) archived\")\n        \n        return \", \".join(parts) if parts else \"No changes\"\n    \n    async def check_for_updates(\n        self,\n        course_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> Tuple[bool, List[FileChange]]:\n        \"\"\"Check if course needs updates.\n        \n        Args:\n            course_id: Course identifier\n            current_files: List of current file paths\n            analysis: Current codebase analysis\n            \n        Returns:\n            Tuple of (needs_update, file_changes)\n        \"\"\"\n        file_changes = await self.detect_file_changes(\n            course_id,\n            current_files,\n            analysis\n        )\n        \n        needs_update = len(file_changes) > 0\n        \n        return needs_update, file_changes\n    \n    def get_update_statistics(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics about course updates.\n        \n        Args:\n            course_id: Course identifier\n            \n        Returns:\n            Dictionary with update statistics\n        \"\"\"\n        history = self.get_version_history(course_id)\n        \n        if not history:\n            return {\n                \"total_versions\": 0,\n                \"total_updates\": 0,\n                \"total_archived\": 0,\n                \"latest_version\": None,\n                \"last_updated\": None\n            }\n        \n        total_updates = sum(v.updated_lessons for v in history)\n        total_archived = sum(v.archived_lessons for v in history)\n        latest = history[0]\n        \n        return {\n            \"total_versions\": len(history),\n            \"total_updates\": total_updates,\n            \"total_archived\": total_archived,\n            \"latest_version\": latest.version,\n            \"last_updated\": latest.updated_at.isoformat(),\n            \"manual_edits\": len(self.manual_edits),\n            \"archived_lessons\": len(self.archived_lessons.get(course_id, []))\n        }\n",
      "purpose": "Defines the class class",
      "key_concepts": [
        "Context Managers",
        "Dunder Methods",
        "List Comprehensions",
        "Object-Oriented Programming",
        "Class Initialization",
        "Asynchronous Programming",
        "Error Handling",
        "Module Imports",
        "Decorators",
        "Conditional Logic",
        "Iteration",
        "Lists/Arrays",
        "Dictionaries",
        "Database Operations"
      ],
      "explanation_approach": [
        "Start by explaining what the class represents and its role in the system",
        "Describe the class attributes and their purposes",
        "Walk through the main methods in order of typical usage",
        "Explain the asynchronous nature and why it's needed",
        "Discuss error handling strategy and what errors are caught",
        "Explain the decorator/annotation and what it adds to the function",
        "Walk through the conditional logic and different code paths",
        "Explain the iteration logic and what's being processed",
        "Show how this code fits into the larger application",
        "Mention common use cases and when this code is called",
        "Point out edge cases and how they're handled",
        "Highlight best practices demonstrated in the code"
      ],
      "related_code": [
        {
          "path": "hashlib",
          "context": "Provides functionality from hashlib",
          "relationship": "imports"
        },
        {
          "path": "json",
          "context": "Provides functionality from json",
          "relationship": "imports"
        },
        {
          "path": "logging",
          "context": "Logging functionality",
          "relationship": "imports"
        },
        {
          "path": "os",
          "context": "Provides functionality from os",
          "relationship": "imports"
        },
        {
          "path": "time",
          "context": "Provides functionality from time",
          "relationship": "imports"
        },
        {
          "path": "datetime",
          "context": "Provides functionality from datetime",
          "relationship": "imports"
        },
        {
          "path": "CourseCacheManager",
          "context": "Provides functionality from CourseCacheManager",
          "relationship": "imports"
        },
        {
          "path": "CodebaseAnalysis",
          "context": "Provides functionality from CodebaseAnalysis",
          "relationship": "imports"
        }
      ],
      "test_evidence": [],
      "git_evidence": [],
      "common_mistakes": [
        "Opening files without 'finally' block for cleanup"
      ]
    }
  ],
  "architecture_context": {
    "component_role": "High-level orchestrator (imports 2 files, imported by 0 files)",
    "data_flow": "Data enters from imported modules: hashlib, json, logging, os, time",
    "interaction_diagram": "```mermaid\\ngraph TD\\n    CURRENT[incremental_updater]\\n    style CURRENT fill:#f9f,stroke:#333,stroke-width:4px\\n\\n    %% Dependencies (imports)\\n    DEP0[LessonContent]\\n    DEP0 --> CURRENT\\n    DEP1[CourseCacheManager]\\n    DEP1 --> CURRENT\\n\\n    %% External dependencies\\n    EXT0[hashlib]\\n    style EXT0 fill:#bbf,stroke:#333,stroke-width:2px\\n    EXT0 --> CURRENT\\n    EXT1[json]\\n    style EXT1 fill:#bbf,stroke:#333,stroke-width:2px\\n    EXT1 --> CURRENT\\n    EXT2[logging]\\n    style EXT2 fill:#bbf,stroke:#333,stroke-width:2px\\n    EXT2 --> CURRENT\\n    EXTMORE[... 6 more external]\\n    style EXTMORE fill:#bbf,stroke:#333,stroke-width:2px\\n    EXTMORE -.-> CURRENT\\n```",
    "dependencies": [
      {
        "name": "hashlib",
        "reason": "Provides functionality from hashlib",
        "evidence": "Line 12: imports hashlib"
      },
      {
        "name": "json",
        "reason": "Provides functionality from json",
        "evidence": "Line 13: imports json"
      },
      {
        "name": "logging",
        "reason": "Logging and diagnostics",
        "evidence": "Line 14: imports logging"
      },
      {
        "name": "os",
        "reason": "Provides functionality from os",
        "evidence": "Line 15: imports os"
      },
      {
        "name": "time",
        "reason": "Provides functionality from time",
        "evidence": "Line 16: imports time"
      },
      {
        "name": "Any",
        "reason": "Provides functionality from Any",
        "evidence": "Line 17: imports Any"
      },
      {
        "name": "datetime",
        "reason": "Provides functionality from datetime",
        "evidence": "Line 18: imports datetime"
      },
      {
        "name": "field",
        "reason": "Provides functionality from field",
        "evidence": "Line 19: imports field"
      },
      {
        "name": "LessonContent",
        "reason": "Provides functionality from LessonContent",
        "evidence": "Line 21: imports LessonContent"
      },
      {
        "name": "CourseCacheManager",
        "reason": "Caching functionality",
        "evidence": "Line 22: imports CourseCacheManager"
      },
      {
        "name": "CodebaseAnalysis",
        "reason": "Provides functionality from CodebaseAnalysis",
        "evidence": "Line 23: imports CodebaseAnalysis"
      }
    ],
    "dependents": [],
    "design_patterns": [
      {
        "pattern": "Strategy Pattern",
        "evidence": "Class IncrementalUpdateManager with multiple _* methods: __init__, _compute_file_hash, _get_file_mtime",
        "explanation": "Defines family of algorithms with interchangeable implementations"
      },
      {
        "pattern": "Dependency Injection",
        "evidence": "Class IncrementalUpdateManager.__init__() accepts dependencies: cache_manager, output_dir (line 74)",
        "explanation": "Dependencies are injected through constructor"
      }
    ]
  },
  "real_world_context": {
    "practical_use_cases": [
      "Manages incremental updates to course content.\r. Provides functionality for:. Implements Requirement 15.4: Provides access to course version history."
    ],
    "analogies": [
      "Like ordering food delivery - you place the order and do other things while waiting",
      "Similar to washing machine - you start it and do other tasks while it runs",
      "Like an assembly line - data moves through 3 steps, each adding or transforming something",
      "Like a single door to a building - one way in, controlled access"
    ],
    "industry_patterns": [
      "Async/await pattern for non-blocking operations"
    ],
    "best_practices": [
      "Document code with clear comments and docstrings",
      "Use docstrings to explain function purpose and parameters",
      "Manage dependencies explicitly and keep them up to date",
      "Reuse code through imports rather than duplication",
      "Handle errors gracefully with try-except blocks",
      "Validate inputs before processing to prevent errors"
    ],
    "anti_patterns": [
      "Avoid deep nesting - use early returns or extract functions",
      "Avoid code duplication - extract common logic into reusable functions"
    ]
  },
  "exercise_generation": {
    "hands_on_tasks": [
      {
        "title": "Implement Incremental Updater: Python Async Await",
        "description": "Complete the implementation of Incremental Updater: Python Async Await following the requirements and passing all tests.",
        "difficulty": "medium"
      },
      {
        "title": "Optimize Performance",
        "description": "Analyze and improve the performance of your implementation for large inputs.",
        "difficulty": "hard"
      }
    ],
    "starter_code": "\"\"\"Incremental Course Update Manager.\n\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Dict, List, Optional, Set, Tuple, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\n\nfrom .models import CourseOutline, Module, Lesson, LessonContent\nfrom .course_cache import CourseCacheManager\nfrom src.models import CodebaseAnalysis\n\nclass FileChange:\n    \"\"\"Represents a change to a source file.\"\"\"\n\nclass LessonUpdate:\n    \"\"\"Represents an update to a lesson.\"\"\"\n\nclass CourseVersion:\n    \"\"\"Represents a version of the course.\"\"\"\n\nclass IncrementalUpdateManager:\n    \"\"\"Manages incremental updates to course content.\n\n    \"\"\"\n\n    def __init__(self, cache_manager: CourseCacheManager, output_dir: str = \"output/courses\"):\n        \"\"\"Initialize the incremental update manager.\n\n        # TODO: Implement this\n        pass\n        \"\"\"\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n    def _compute_file_hash(self, file_path: str) -> str:\n        \"\"\"Compute SHA256 hash of file content.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n    def _get_file_mtime(self, file_path: str) -> float:\n        \"\"\"Get file modification time.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n        \"\"\"Detect changes to source files since last course generation.\n\n        \"\"\"\n\n        # Get cached course structure to find previous files\n\n            # No previous course, all files are new\n\n        # Detect added files\n\n        # Detect deleted files\n\n        # Detect modified files\n\n            # Check if file has changed using cache\n\n            # Update hash tracking\n\n    def identify_lessons_to_update(\n        # TODO: Implement this\n        pass\n        \"\"\"Identify which lessons need updates based on file changes.\n\n        \"\"\"\n\n        # Build map of file_path -> lesson\n\n        # Match file changes to lessons\n\n                # Check if lesson has manual edits that should be preserved\n\n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n        \"\"\"\n\n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n    def preserve_manual_edits(\n        # TODO: Implement this\n        pass\n        \"\"\"Preserve manually edited sections when updating lesson content.\n\n        \"\"\"\n\n        # Create a copy of new content\n\n        # Preserve manually edited sections\n\n        # Note: code_example is always regenerated from source\n\n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n    def create_version(\n        # TODO: Implement this\n        pass\n        \"\"\"Create a new course version entry.\n\n        \"\"\"\n\n        # Add to version history\n\n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n        \"\"\"\n\n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n\n        # TODO: Implement this\n        pass\n        \"\"\"\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n\n        # TODO: Implement this\n        pass\n        \"\"\"\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"Update course incrementally based on file changes.\n\n        \"\"\"\n\n        # Identify lessons to update\n\n        # Track updates\n\n        # Process each lesson update\n                # Archive the lesson\n\n                # Update lesson content\n\n        # Remove archived lessons from course\n\n        # Update course metadata\n\n        # Create version entry\n\n        # Save version history\n\n        # Verify performance requirement (Req 15.5)\n\n        \"\"\"Update content for a single lesson.\n\n        \"\"\"\n\n        # Get file analysis\n\n        # Store old content if it exists\n\n        # Generate new content\n\n        # Preserve manual edits if any\n\n        # Update lesson metadata\n\n        # Update learning objectives if patterns changed\n\n        # Update complexity-based difficulty\n\n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n    def _remove_archived_lessons(\n        # TODO: Implement this\n        pass\n        \"\"\"Remove archived lessons from course structure.\n\n        \"\"\"\n\n        # Remove archived lessons from modules\n\n            # Update lesson order after removal\n\n            # Update module duration\n\n        # Remove empty modules\n\n        # Update module order\n\n        # Update course duration\n\n        # Update difficulty distribution\n\n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n\n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n    def _generate_change_summary(\n        # TODO: Implement this\n        pass\n        \"\"\"Generate a human-readable summary of changes.\n\n        \"\"\"\n\n        # Count change types\n\n        # Count update types\n\n        \"\"\"Check if course needs updates.\n\n        \"\"\"\n\n    def get_update_statistics(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics about course updates.\n\n        # TODO: Implement this\n        pass\n\n        \"\"\"\n        # TODO: Implement this\n        pass\n\n        # TODO: Implement this\n        pass\n",
    "solution_code": "\"\"\"Incremental Course Update Manager.\n\nThis module provides incremental update functionality for courses.\nImplements Requirements 15.1, 15.2, 15.3, 15.4, 15.5:\n- Detects which lessons need updates based on file changes\n- Tracks course version history\n- Preserves manual edits to lesson content\n- Archives deleted lessons\n- Completes updates in <3s for <5 changes\n\"\"\"\n\nimport hashlib\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Dict, List, Optional, Set, Tuple, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\n\nfrom .models import CourseOutline, Module, Lesson, LessonContent\nfrom .course_cache import CourseCacheManager\nfrom src.models import CodebaseAnalysis\n\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass FileChange:\n    \"\"\"Represents a change to a source file.\"\"\"\n    file_path: str\n    change_type: str  # 'added', 'modified', 'deleted'\n    old_hash: Optional[str] = None\n    new_hash: Optional[str] = None\n    detected_at: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass LessonUpdate:\n    \"\"\"Represents an update to a lesson.\"\"\"\n    lesson_id: str\n    file_path: str\n    update_type: str  # 'content', 'structure', 'archived'\n    changes: List[str] = field(default_factory=list)\n    timestamp: datetime = field(default_factory=datetime.now)\n\n\n@dataclass\nclass CourseVersion:\n    \"\"\"Represents a version of the course.\"\"\"\n    version: str\n    created_at: datetime\n    updated_at: datetime\n    change_summary: str\n    lesson_updates: List[LessonUpdate] = field(default_factory=list)\n    file_changes: List[FileChange] = field(default_factory=list)\n    total_lessons: int = 0\n    updated_lessons: int = 0\n    archived_lessons: int = 0\n\n\nclass IncrementalUpdateManager:\n    \"\"\"Manages incremental updates to course content.\n\n    Provides functionality for:\n    - Detecting file changes\n    - Identifying lessons that need updates\n    - Preserving manual edits\n    - Tracking version history\n    - Archiving deleted lessons\n    \"\"\"\n\n    def __init__(self, cache_manager: CourseCacheManager, output_dir: str = \"output/courses\"):\n        \"\"\"Initialize the incremental update manager.\n\n        Args:\n            cache_manager: Course cache manager instance\n            output_dir: Directory where course files are stored\n        \"\"\"\n        self.cache = cache_manager\n        self.output_dir = output_dir\n\n        # Version history storage\n        self.version_history: Dict[str, List[CourseVersion]] = {}\n\n        # Manual edit tracking\n        self.manual_edits: Dict[str, Set[str]] = {}  # lesson_id -> set of edited sections\n\n        # File hash tracking for change detection\n        self.file_hashes: Dict[str, str] = {}\n\n        # Archived lessons\n        self.archived_lessons: Dict[str, List[Lesson]] = {}  # course_id -> archived lessons\n\n    def _compute_file_hash(self, file_path: str) -> str:\n        \"\"\"Compute SHA256 hash of file content.\n\n        Args:\n            file_path: Path to file\n\n        Returns:\n            SHA256 hash of file content\n        \"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                return hashlib.sha256(f.read()).hexdigest()\n        except Exception as e:\n            logger.warning(f\"Failed to hash file {file_path}: {e}\")\n            return \"\"\n\n    def _get_file_mtime(self, file_path: str) -> float:\n        \"\"\"Get file modification time.\n\n        Args:\n            file_path: Path to file\n\n        Returns:\n            Modification time as timestamp\n        \"\"\"\n        try:\n            return os.path.getmtime(file_path)\n        except Exception as e:\n            logger.warning(f\"Failed to get mtime for {file_path}: {e}\")\n            return 0.0\n\n    async def detect_file_changes(\n        self,\n        codebase_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> List[FileChange]:\n        \"\"\"Detect changes to source files since last course generation.\n\n        Implements Requirement 15.1: Detects which lessons need updates based on file changes.\n\n        Args:\n            codebase_id: Unique codebase identifier\n            current_files: List of current file paths in the codebase\n            analysis: Current codebase analysis\n\n        Returns:\n            List of FileChange objects representing detected changes\n        \"\"\"\n        changes = []\n\n        # Get cached course structure to find previous files\n        cached_course = await self.cache.get_course_structure(codebase_id)\n\n        if not cached_course or \"file_paths\" not in cached_course:\n            # No previous course, all files are new\n            for file_path in current_files:\n                file_hash = self._compute_file_hash(file_path)\n                changes.append(FileChange(\n                    file_path=file_path,\n                    change_type='added',\n                    new_hash=file_hash\n                ))\n            return changes\n\n        previous_files = set(cached_course[\"file_paths\"])\n        current_files_set = set(current_files)\n\n        # Detect added files\n        added_files = current_files_set - previous_files\n        for file_path in added_files:\n            file_hash = self._compute_file_hash(file_path)\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='added',\n                new_hash=file_hash\n            ))\n            logger.info(f\"Detected added file: {file_path}\")\n\n        # Detect deleted files\n        deleted_files = previous_files - current_files_set\n        for file_path in deleted_files:\n            old_hash = self.file_hashes.get(file_path, \"\")\n            changes.append(FileChange(\n                file_path=file_path,\n                change_type='deleted',\n                old_hash=old_hash\n            ))\n            logger.info(f\"Detected deleted file: {file_path}\")\n\n        # Detect modified files\n        for file_path in current_files_set & previous_files:\n            current_hash = self._compute_file_hash(file_path)\n\n            # Check if file has changed using cache\n            if await self.cache._is_file_changed(file_path):\n                old_hash = self.file_hashes.get(file_path, \"\")\n                if current_hash != old_hash:\n                    changes.append(FileChange(\n                        file_path=file_path,\n                        change_type='modified',\n                        old_hash=old_hash,\n                        new_hash=current_hash\n                    ))\n                    logger.info(f\"Detected modified file: {file_path}\")\n\n            # Update hash tracking\n            self.file_hashes[file_path] = current_hash\n\n        logger.info(\n            f\"Detected {len(changes)} file changes: \"\n            f\"{len(added_files)} added, {len(deleted_files)} deleted, \"\n            f\"{len([c for c in changes if c.change_type == 'modified'])} modified\"\n        )\n\n        return changes\n\n    def identify_lessons_to_update(\n        self,\n        course: CourseOutline,\n        file_changes: List[FileChange]\n    ) -> List[Tuple[Lesson, FileChange]]:\n        \"\"\"Identify which lessons need updates based on file changes.\n\n        Implements Requirement 15.1: Detects which lessons need updates.\n\n        Args:\n            course: Current course outline\n            file_changes: List of detected file changes\n\n        Returns:\n            List of (Lesson, FileChange) tuples for lessons that need updates\n        \"\"\"\n        lessons_to_update = []\n\n        # Build map of file_path -> lesson\n        file_to_lesson: Dict[str, Lesson] = {}\n        for module in course.modules:\n            for lesson in module.lessons:\n                file_to_lesson[lesson.file_path] = lesson\n\n        # Match file changes to lessons\n        for change in file_changes:\n            if change.file_path in file_to_lesson:\n                lesson = file_to_lesson[change.file_path]\n\n                # Check if lesson has manual edits that should be preserved\n                if self._has_manual_edits(lesson.lesson_id):\n                    logger.info(\n                        f\"Lesson {lesson.lesson_id} has manual edits, \"\n                        f\"will preserve during update\"\n                    )\n\n                lessons_to_update.append((lesson, change))\n\n        logger.info(f\"Identified {len(lessons_to_update)} lessons to update\")\n        return lessons_to_update\n\n    def _has_manual_edits(self, lesson_id: str) -> bool:\n        \"\"\"Check if a lesson has manual edits.\n\n        Implements Requirement 15.2: Preserves manual edits.\n\n        Args:\n            lesson_id: Lesson identifier\n\n        Returns:\n            True if lesson has manual edits, False otherwise\n        \"\"\"\n        return lesson_id in self.manual_edits and len(self.manual_edits[lesson_id]) > 0\n\n    def mark_manual_edit(self, lesson_id: str, section: str):\n        \"\"\"Mark a section of a lesson as manually edited.\n\n        Implements Requirement 15.2: Tracks manual edits to preserve them.\n\n        Args:\n            lesson_id: Lesson identifier\n            section: Section name that was edited (e.g., 'introduction', 'explanation')\n        \"\"\"\n        if lesson_id not in self.manual_edits:\n            self.manual_edits[lesson_id] = set()\n\n        self.manual_edits[lesson_id].add(section)\n        logger.info(f\"Marked manual edit: {lesson_id}.{section}\")\n\n    def preserve_manual_edits(\n        self,\n        lesson_id: str,\n        old_content: LessonContent,\n        new_content: LessonContent\n    ) -> LessonContent:\n        \"\"\"Preserve manually edited sections when updating lesson content.\n\n        Implements Requirement 15.2: Preserves manual edits to lesson content.\n\n        Args:\n            lesson_id: Lesson identifier\n            old_content: Previous lesson content (may have manual edits)\n            new_content: Newly generated lesson content\n\n        Returns:\n            Merged lesson content with manual edits preserved\n        \"\"\"\n        if not self._has_manual_edits(lesson_id):\n            return new_content\n\n        edited_sections = self.manual_edits[lesson_id]\n\n        # Create a copy of new content\n        merged_content = LessonContent(\n            introduction=new_content.introduction,\n            explanation=new_content.explanation,\n            code_example=new_content.code_example,\n            walkthrough=new_content.walkthrough,\n            summary=new_content.summary,\n            further_reading=new_content.further_reading\n        )\n\n        # Preserve manually edited sections\n        if 'introduction' in edited_sections:\n            merged_content.introduction = old_content.introduction\n            logger.info(f\"Preserved manual edit: {lesson_id}.introduction\")\n\n        if 'explanation' in edited_sections:\n            merged_content.explanation = old_content.explanation\n            logger.info(f\"Preserved manual edit: {lesson_id}.explanation\")\n\n        if 'walkthrough' in edited_sections:\n            merged_content.walkthrough = old_content.walkthrough\n            logger.info(f\"Preserved manual edit: {lesson_id}.walkthrough\")\n\n        if 'summary' in edited_sections:\n            merged_content.summary = old_content.summary\n            logger.info(f\"Preserved manual edit: {lesson_id}.summary\")\n\n        if 'further_reading' in edited_sections:\n            merged_content.further_reading = old_content.further_reading\n            logger.info(f\"Preserved manual edit: {lesson_id}.further_reading\")\n\n        # Note: code_example is always regenerated from source\n\n        return merged_content\n\n    def archive_lesson(self, course_id: str, lesson: Lesson, reason: str = \"file_deleted\"):\n        \"\"\"Archive a lesson instead of deleting it.\n\n        Implements Requirement 15.3: Archives deleted lessons rather than deleting them.\n\n        Args:\n            course_id: Course identifier\n            lesson: Lesson to archive\n            reason: Reason for archiving\n        \"\"\"\n        if course_id not in self.archived_lessons:\n            self.archived_lessons[course_id] = []\n\n        # Add archive metadata\n        lesson.tags.append(f\"archived:{reason}\")\n        lesson.tags.append(f\"archived_at:{datetime.now().isoformat()}\")\n\n        self.archived_lessons[course_id].append(lesson)\n\n        logger.info(\n            f\"Archived lesson {lesson.lesson_id} ({lesson.title}) \"\n            f\"from course {course_id}: {reason}\"\n        )\n\n    def get_archived_lessons(self, course_id: str) -> List[Lesson]:\n        \"\"\"Get archived lessons for a course.\n\n        Args:\n            course_id: Course identifier\n\n        Returns:\n            List of archived lessons\n        \"\"\"\n        return self.archived_lessons.get(course_id, [])\n\n    def create_version(\n        self,\n        course_id: str,\n        version: str,\n        change_summary: str,\n        lesson_updates: List[LessonUpdate],\n        file_changes: List[FileChange],\n        total_lessons: int\n    ) -> CourseVersion:\n        \"\"\"Create a new course version entry.\n\n        Implements Requirement 15.4: Tracks course version history.\n\n        Args:\n            course_id: Course identifier\n            version: Version string (e.g., \"1.0.1\")\n            change_summary: Summary of changes\n            lesson_updates: List of lesson updates\n            file_changes: List of file changes\n            total_lessons: Total number of lessons in course\n\n        Returns:\n            CourseVersion object\n        \"\"\"\n        now = datetime.now()\n\n        course_version = CourseVersion(\n            version=version,\n            created_at=now,\n            updated_at=now,\n            change_summary=change_summary,\n            lesson_updates=lesson_updates,\n            file_changes=file_changes,\n            total_lessons=total_lessons,\n            updated_lessons=len(lesson_updates),\n            archived_lessons=len([u for u in lesson_updates if u.update_type == 'archived'])\n        )\n\n        # Add to version history\n        if course_id not in self.version_history:\n            self.version_history[course_id] = []\n\n        self.version_history[course_id].append(course_version)\n\n        logger.info(\n            f\"Created course version {version} for {course_id}: \"\n            f\"{course_version.updated_lessons} lessons updated, \"\n            f\"{course_version.archived_lessons} lessons archived\"\n        )\n\n        return course_version\n\n    def get_version_history(self, course_id: str) -> List[CourseVersion]:\n        \"\"\"Get version history for a course.\n\n        Implements Requirement 15.4: Provides access to course version history.\n\n        Args:\n            course_id: Course identifier\n\n        Returns:\n            List of CourseVersion objects, newest first (in reverse order of creation)\n        \"\"\"\n        history = self.version_history.get(course_id, [])\n        # Return in reverse order (newest first) since versions are appended chronologically\n        return list(reversed(history))\n\n    def get_latest_version(self, course_id: str) -> Optional[CourseVersion]:\n        \"\"\"Get the latest version for a course.\n\n        Args:\n            course_id: Course identifier\n\n        Returns:\n            Latest CourseVersion or None if no versions exist\n        \"\"\"\n        history = self.get_version_history(course_id)\n        return history[0] if history else None\n\n    def increment_version(self, current_version: str, change_type: str = \"minor\") -> str:\n        \"\"\"Increment version number based on change type.\n\n        Args:\n            current_version: Current version string (e.g., \"1.0.0\")\n            change_type: Type of change ('major', 'minor', 'patch')\n\n        Returns:\n            New version string\n        \"\"\"\n        try:\n            parts = current_version.split('.')\n            major, minor, patch = int(parts[0]), int(parts[1]), int(parts[2])\n\n            if change_type == 'major':\n                major += 1\n                minor = 0\n                patch = 0\n            elif change_type == 'minor':\n                minor += 1\n                patch = 0\n            else:  # patch\n                patch += 1\n\n            return f\"{major}.{minor}.{patch}\"\n        except Exception as e:\n            logger.warning(f\"Failed to increment version {current_version}: {e}\")\n            return current_version\n\n    def save_version_history(self, course_id: str, output_path: Optional[str] = None):\n        \"\"\"Save version history to disk.\n\n        Args:\n            course_id: Course identifier\n            output_path: Optional custom output path\n        \"\"\"\n        if output_path is None:\n            output_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n\n        history = self.get_version_history(course_id)\n\n        # Serialize to JSON\n        history_data = []\n        for version in history:\n            history_data.append({\n                \"version\": version.version,\n                \"created_at\": version.created_at.isoformat(),\n                \"updated_at\": version.updated_at.isoformat(),\n                \"change_summary\": version.change_summary,\n                \"total_lessons\": version.total_lessons,\n                \"updated_lessons\": version.updated_lessons,\n                \"archived_lessons\": version.archived_lessons,\n                \"lesson_updates\": [\n                    {\n                        \"lesson_id\": u.lesson_id,\n                        \"file_path\": u.file_path,\n                        \"update_type\": u.update_type,\n                        \"changes\": u.changes,\n                        \"timestamp\": u.timestamp.isoformat()\n                    }\n                    for u in version.lesson_updates\n                ],\n                \"file_changes\": [\n                    {\n                        \"file_path\": c.file_path,\n                        \"change_type\": c.change_type,\n                        \"old_hash\": c.old_hash,\n                        \"new_hash\": c.new_hash,\n                        \"detected_at\": c.detected_at.isoformat()\n                    }\n                    for c in version.file_changes\n                ]\n            })\n\n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(history_data, f, indent=2)\n\n        logger.info(f\"Saved version history to {output_path}\")\n\n    def load_version_history(self, course_id: str, input_path: Optional[str] = None):\n        \"\"\"Load version history from disk.\n\n        Args:\n            course_id: Course identifier\n            input_path: Optional custom input path\n        \"\"\"\n        if input_path is None:\n            input_path = os.path.join(\n                self.output_dir,\n                course_id,\n                \"version_history.json\"\n            )\n\n        if not os.path.exists(input_path):\n            logger.debug(f\"No version history file found at {input_path}\")\n            return\n\n        try:\n            with open(input_path, 'r', encoding='utf-8') as f:\n                history_data = json.load(f)\n\n            # Deserialize from JSON\n            versions = []\n            for data in history_data:\n                version = CourseVersion(\n                    version=data[\"version\"],\n                    created_at=datetime.fromisoformat(data[\"created_at\"]),\n                    updated_at=datetime.fromisoformat(data[\"updated_at\"]),\n                    change_summary=data[\"change_summary\"],\n                    total_lessons=data[\"total_lessons\"],\n                    updated_lessons=data[\"updated_lessons\"],\n                    archived_lessons=data[\"archived_lessons\"],\n                    lesson_updates=[\n                        LessonUpdate(\n                            lesson_id=u[\"lesson_id\"],\n                            file_path=u[\"file_path\"],\n                            update_type=u[\"update_type\"],\n                            changes=u[\"changes\"],\n                            timestamp=datetime.fromisoformat(u[\"timestamp\"])\n                        )\n                        for u in data[\"lesson_updates\"]\n                    ],\n                    file_changes=[\n                        FileChange(\n                            file_path=c[\"file_path\"],\n                            change_type=c[\"change_type\"],\n                            old_hash=c.get(\"old_hash\"),\n                            new_hash=c.get(\"new_hash\"),\n                            detected_at=datetime.fromisoformat(c[\"detected_at\"])\n                        )\n                        for c in data[\"file_changes\"]\n                    ]\n                )\n                versions.append(version)\n\n            self.version_history[course_id] = versions\n            logger.info(f\"Loaded {len(versions)} versions from {input_path}\")\n\n        except Exception as e:\n            logger.error(f\"Failed to load version history from {input_path}: {e}\")\n\n\n    async def update_course_incrementally(\n        self,\n        course: CourseOutline,\n        analysis: CodebaseAnalysis,\n        file_changes: List[FileChange],\n        content_generator,\n        structure_generator\n    ) -> Tuple[CourseOutline, CourseVersion]:\n        \"\"\"Update course incrementally based on file changes.\n\n        Implements Requirements 15.1, 15.2, 15.3, 15.5:\n        - Updates only changed lessons\n        - Preserves manual edits\n        - Archives deleted lessons\n        - Completes updates in <3s for <5 changes\n\n        Args:\n            course: Current course outline\n            analysis: Current codebase analysis\n            file_changes: List of detected file changes\n            content_generator: LessonContentGenerator instance\n            structure_generator: CourseStructureGenerator instance\n\n        Returns:\n            Tuple of (updated CourseOutline, CourseVersion)\n        \"\"\"\n        start_time = time.time()\n\n        logger.info(\n            f\"Starting incremental update for course {course.course_id} \"\n            f\"with {len(file_changes)} file changes\"\n        )\n\n        # Identify lessons to update\n        lessons_to_update = self.identify_lessons_to_update(course, file_changes)\n\n        # Track updates\n        lesson_updates: List[LessonUpdate] = []\n\n        # Process each lesson update\n        for lesson, change in lessons_to_update:\n            if change.change_type == 'deleted':\n                # Archive the lesson\n                self.archive_lesson(course.course_id, lesson, \"file_deleted\")\n                lesson_updates.append(LessonUpdate(\n                    lesson_id=lesson.lesson_id,\n                    file_path=lesson.file_path,\n                    update_type='archived',\n                    changes=['File deleted, lesson archived']\n                ))\n\n            elif change.change_type in ['added', 'modified']:\n                # Update lesson content\n                update = await self._update_lesson_content(\n                    lesson,\n                    analysis,\n                    content_generator\n                )\n                lesson_updates.append(update)\n\n        # Remove archived lessons from course\n        course = self._remove_archived_lessons(course, lesson_updates)\n\n        # Update course metadata\n        course.version = self.increment_version(\n            course.version,\n            'minor' if len(file_changes) > 5 else 'patch'\n        )\n        course.created_at = datetime.now()  # Update timestamp\n\n        # Create version entry\n        change_summary = self._generate_change_summary(file_changes, lesson_updates)\n        version = self.create_version(\n            course.course_id,\n            course.version,\n            change_summary,\n            lesson_updates,\n            file_changes,\n            self._count_total_lessons(course)\n        )\n\n        # Save version history\n        self.save_version_history(course.course_id)\n\n        elapsed_time = time.time() - start_time\n        logger.info(\n            f\"Incremental update completed in {elapsed_time:.2f}s: \"\n            f\"{len(lesson_updates)} lessons updated\"\n        )\n\n        # Verify performance requirement (Req 15.5)\n        if len(file_changes) < 5 and elapsed_time > 3.0:\n            logger.warning(\n                f\"Update took {elapsed_time:.2f}s for {len(file_changes)} changes, \"\n                f\"exceeding 3s target\"\n            )\n\n        return course, version\n\n    async def _update_lesson_content(\n        self,\n        lesson: Lesson,\n        analysis: CodebaseAnalysis,\n        content_generator\n    ) -> LessonUpdate:\n        \"\"\"Update content for a single lesson.\n\n        Implements Requirement 15.2: Preserves manual edits during update.\n\n        Args:\n            lesson: Lesson to update\n            analysis: Current codebase analysis\n            content_generator: LessonContentGenerator instance\n\n        Returns:\n            LessonUpdate describing the changes\n        \"\"\"\n        changes = []\n\n        # Get file analysis\n        file_analysis = analysis.file_analyses.get(lesson.file_path)\n        if not file_analysis:\n            logger.warning(f\"No analysis found for {lesson.file_path}\")\n            return LessonUpdate(\n                lesson_id=lesson.lesson_id,\n                file_path=lesson.file_path,\n                update_type='content',\n                changes=['No analysis available']\n            )\n\n        # Store old content if it exists\n        old_content = lesson.content\n\n        # Generate new content\n        new_content = await content_generator.generate_lesson_content(file_analysis)\n\n        # Preserve manual edits if any\n        if old_content and self._has_manual_edits(lesson.lesson_id):\n            merged_content = self.preserve_manual_edits(\n                lesson.lesson_id,\n                old_content,\n                new_content\n            )\n            lesson.content = merged_content\n            changes.append(\"Preserved manual edits\")\n        else:\n            lesson.content = new_content\n            changes.append(\"Regenerated content\")\n\n        # Update lesson metadata\n        lesson.teaching_value = file_analysis.teaching_value.score\n\n        # Update learning objectives if patterns changed\n        old_patterns = set(lesson.concepts)\n        new_patterns = set(p.pattern_type for p in file_analysis.patterns)\n\n        if old_patterns != new_patterns:\n            lesson.concepts = list(new_patterns)\n            lesson.tags = list(new_patterns)\n            changes.append(f\"Updated patterns: {new_patterns - old_patterns}\")\n\n        # Update complexity-based difficulty\n        new_difficulty = self._calculate_difficulty(file_analysis)\n        if new_difficulty != lesson.difficulty:\n            old_diff = lesson.difficulty\n            lesson.difficulty = new_difficulty\n            changes.append(f\"Difficulty changed: {old_diff} -> {new_difficulty}\")\n\n        return LessonUpdate(\n            lesson_id=lesson.lesson_id,\n            file_path=lesson.file_path,\n            update_type='content',\n            changes=changes\n        )\n\n    def _calculate_difficulty(self, file_analysis) -> str:\n        \"\"\"Calculate lesson difficulty from file analysis.\n\n        Args:\n            file_analysis: FileAnalysis object\n\n        Returns:\n            Difficulty level string\n        \"\"\"\n        avg_complexity = file_analysis.complexity_metrics.avg_complexity\n\n        if avg_complexity <= 5:\n            return \"beginner\"\n        elif avg_complexity <= 10:\n            return \"intermediate\"\n        else:\n            return \"advanced\"\n\n    def _remove_archived_lessons(\n        self,\n        course: CourseOutline,\n        lesson_updates: List[LessonUpdate]\n    ) -> CourseOutline:\n        \"\"\"Remove archived lessons from course structure.\n\n        Args:\n            course: Course outline\n            lesson_updates: List of lesson updates\n\n        Returns:\n            Updated course outline\n        \"\"\"\n        archived_ids = {\n            u.lesson_id for u in lesson_updates\n            if u.update_type == 'archived'\n        }\n\n        if not archived_ids:\n            return course\n\n        # Remove archived lessons from modules\n        for module in course.modules:\n            module.lessons = [\n                lesson for lesson in module.lessons\n                if lesson.lesson_id not in archived_ids\n            ]\n\n            # Update lesson order after removal\n            for idx, lesson in enumerate(module.lessons):\n                lesson.order = idx\n\n            # Update module duration\n            module.duration_hours = sum(l.duration_minutes for l in module.lessons) / 60.0\n\n        # Remove empty modules\n        course.modules = [m for m in course.modules if len(m.lessons) > 0]\n\n        # Update module order\n        for idx, module in enumerate(course.modules):\n            module.order = idx\n\n        # Update course duration\n        course.total_duration_hours = sum(m.duration_hours for m in course.modules)\n\n        # Update difficulty distribution\n        course.difficulty_distribution = self._calculate_difficulty_distribution(course)\n\n        logger.info(f\"Removed {len(archived_ids)} archived lessons from course\")\n\n        return course\n\n    def _calculate_difficulty_distribution(self, course: CourseOutline) -> Dict[str, int]:\n        \"\"\"Calculate difficulty distribution across all lessons.\n\n        Args:\n            course: Course outline\n\n        Returns:\n            Dictionary mapping difficulty levels to counts\n        \"\"\"\n        distribution = {\"beginner\": 0, \"intermediate\": 0, \"advanced\": 0}\n\n        for module in course.modules:\n            for lesson in module.lessons:\n                distribution[lesson.difficulty] += 1\n\n        return distribution\n\n    def _count_total_lessons(self, course: CourseOutline) -> int:\n        \"\"\"Count total lessons in course.\n\n        Args:\n            course: Course outline\n\n        Returns:\n            Total number of lessons\n        \"\"\"\n        return sum(len(module.lessons) for module in course.modules)\n\n    def _generate_change_summary(\n        self,\n        file_changes: List[FileChange],\n        lesson_updates: List[LessonUpdate]\n    ) -> str:\n        \"\"\"Generate a human-readable summary of changes.\n\n        Args:\n            file_changes: List of file changes\n            lesson_updates: List of lesson updates\n\n        Returns:\n            Change summary string\n        \"\"\"\n        parts = []\n\n        # Count change types\n        added = len([c for c in file_changes if c.change_type == 'added'])\n        modified = len([c for c in file_changes if c.change_type == 'modified'])\n        deleted = len([c for c in file_changes if c.change_type == 'deleted'])\n\n        if added > 0:\n            parts.append(f\"{added} file(s) added\")\n        if modified > 0:\n            parts.append(f\"{modified} file(s) modified\")\n        if deleted > 0:\n            parts.append(f\"{deleted} file(s) deleted\")\n\n        # Count update types\n        content_updates = len([u for u in lesson_updates if u.update_type == 'content'])\n        archived = len([u for u in lesson_updates if u.update_type == 'archived'])\n\n        if content_updates > 0:\n            parts.append(f\"{content_updates} lesson(s) updated\")\n        if archived > 0:\n            parts.append(f\"{archived} lesson(s) archived\")\n\n        return \", \".join(parts) if parts else \"No changes\"\n\n    async def check_for_updates(\n        self,\n        course_id: str,\n        current_files: List[str],\n        analysis: CodebaseAnalysis\n    ) -> Tuple[bool, List[FileChange]]:\n        \"\"\"Check if course needs updates.\n\n        Args:\n            course_id: Course identifier\n            current_files: List of current file paths\n            analysis: Current codebase analysis\n\n        Returns:\n            Tuple of (needs_update, file_changes)\n        \"\"\"\n        file_changes = await self.detect_file_changes(\n            course_id,\n            current_files,\n            analysis\n        )\n\n        needs_update = len(file_changes) > 0\n\n        return needs_update, file_changes\n\n    def get_update_statistics(self, course_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics about course updates.\n\n        Args:\n            course_id: Course identifier\n\n        Returns:\n            Dictionary with update statistics\n        \"\"\"\n        history = self.get_version_history(course_id)\n\n        if not history:\n            return {\n                \"total_versions\": 0,\n                \"total_updates\": 0,\n                \"total_archived\": 0,\n                \"latest_version\": None,\n                \"last_updated\": None\n            }\n\n        total_updates = sum(v.updated_lessons for v in history)\n        total_archived = sum(v.archived_lessons for v in history)\n        latest = history[0]\n\n        return {\n            \"total_versions\": len(history),\n            \"total_updates\": total_updates,\n            \"total_archived\": total_archived,\n            \"latest_version\": latest.version,\n            \"last_updated\": latest.updated_at.isoformat(),\n            \"manual_edits\": len(self.manual_edits),\n            \"archived_lessons\": len(self.archived_lessons.get(course_id, []))\n        }",
    "test_cases": [],
    "progressive_hints": [
      "Think about iterating through the data and checking conditions for each item.",
      "A dictionary/object might be useful for storing key-value relationships.",
      "You'll need about 25 functions to organize the logic properly.",
      "Regular expressions can help with pattern matching in strings.",
      "Test your solution with edge cases: empty inputs, single items, and large datasets."
    ],
    "self_assessment": [
      "What is the main purpose of Incremental Updater: Python Async Await and why is it important?",
      "What approach does this python implementation use and why is it effective?",
      "Why does this code depend on hashlib, json, logging and what do they provide?",
      "How would you apply the concepts from Incremental Updater: Python Async Await to a different problem?",
      "What improvements or optimizations could be made to this implementation?"
    ]
  },
  "anti_hallucination_rules": {
    "always_cite": "Never explain code behavior without citing specific evidence from code, tests, or documentation",
    "distinguish_fact_inference": "Clearly mark inferences and assumptions as such, distinguishing them from verified facts",
    "validate_against_tests": "Always check test files to verify expected behavior before explaining functionality",
    "cross_reference": "Verify consistency across multiple evidence sources (code, tests, docs, git) before making claims",
    "avoid_assumptions": "Don't guess the 'why' behind code - cite git commits or documentation for rationale"
  },
  "enrichment_instructions": {
    "tone": "casual",
    "depth": "detailed",
    "focus_areas": [
      "Emphasize best practices and why they matter",
      "Explain fundamental concepts thoroughly for beginners",
      "Make content accessible for junior developers",
      "Explain unique or interesting aspects of the implementation"
    ],
    "avoid_topics": [
      "Overly academic theory without practical application",
      "Framework-specific implementation details that may change",
      "Advanced optimization techniques for beginner content",
      "Deprecated patterns or outdated practices"
    ],
    "evidence_requirements": "Cite evidence for every claim - include file paths, line numbers, test names, or commit hashes"
  }
}